{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "OjE4Wpchh6c8",
    "outputId": "bc07395e-bc5c-4a29-d204-7279e6e064b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive locally\n",
    "# Run the cell, click the link, copy the code on the page, paste it in the box, hit enter\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXiOU9ihIHvX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/NER\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8542ZPSnM_d"
   },
   "outputs": [],
   "source": [
    "# download flair library #\n",
    "! pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32142
    },
    "colab_type": "code",
    "id": "jmj6vZ_AmD4c",
    "outputId": "081e8cfb-6cef-41b5-c9be-827826060a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "2019-04-22 19:42:03,687 Reading data from /content/gdrive/My Drive/NER\n",
      "2019-04-22 19:42:03,688 Train: /content/gdrive/My Drive/NER/train.txt\n",
      "2019-04-22 19:42:03,693 Dev: None\n",
      "2019-04-22 19:42:03,696 Test: /content/gdrive/My Drive/NER/test.txt\n",
      "TaggedCorpus: 2737 train + 304 dev + 726 test sentences\n",
      "[b'<unk>', b'O', b'B-Name', b'L-Name', b'U-Location', b'U-Email', b'B-Companies', b'L-Companies', b'B-Degree', b'I-Degree', b'L-Degree', b'I-Skills', b'U-Links', b'B-Skills', b'L-Skills', b'U-Companies', b'B-Years', b'L-Years', b'B-College', b'I-College', b'L-College', b'-', b'U-Graduation', b'B-Designation', b'I-Designation', b'L-Designation', b'I-Companies', b'U-Degree', b'U-Address', b'I-Name', b'B-Rewards', b'I-Rewards', b'B-University', b'I-University', b'L-University', b'B-Location', b'L-Location', b'U-Skills', b'I-Location', b'L-Email', b'U-Designation', b'B-Email', b'I-Email', b'I-Years', b'U-College', b'B-UNKNOWN', b'L-UNKNOWN', b'U-abc', b'U-Can', b'B-des', b'L-des', b'B-state', b'L-state', b'U-state', b'B-Can', b'L-Can', b'<START>', b'<STOP>']\n",
      "2019-04-22 19:42:06,616 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpmo779q1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000128/160000128 [00:07<00:00, 21476511.30B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 19:42:14,617 copying /tmp/tmpmo779q1s to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 19:42:15,067 removing temp file /tmp/tmpmo779q1s\n",
      "2019-04-22 19:42:15,584 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpkngqndet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21494764/21494764 [00:01<00:00, 11679520.64B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 19:42:17,973 copying /tmp/tmpkngqndet to cache at /root/.flair/embeddings/glove.gensim\n",
      "2019-04-22 19:42:18,007 removing temp file /tmp/tmpkngqndet\n",
      "2019-04-22 19:42:18,008 this function is deprecated, use smart_open.open instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-22 19:42:26,853 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:42:26,859 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-22 19:42:28,158 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:42:28,380 epoch 1 - iter 0/86 - loss 46.72546387\n",
      "2019-04-22 19:42:29,456 epoch 1 - iter 8/86 - loss 19.11299207\n",
      "2019-04-22 19:42:30,484 epoch 1 - iter 16/86 - loss 13.46895371\n",
      "2019-04-22 19:42:31,558 epoch 1 - iter 24/86 - loss 11.81832028\n",
      "2019-04-22 19:42:32,563 epoch 1 - iter 32/86 - loss 10.23644788\n",
      "2019-04-22 19:42:33,615 epoch 1 - iter 40/86 - loss 9.41592607\n",
      "2019-04-22 19:42:34,694 epoch 1 - iter 48/86 - loss 8.91690063\n",
      "2019-04-22 19:42:35,729 epoch 1 - iter 56/86 - loss 8.50651696\n",
      "2019-04-22 19:42:36,734 epoch 1 - iter 64/86 - loss 8.06562680\n",
      "2019-04-22 19:42:37,806 epoch 1 - iter 72/86 - loss 7.69527094\n",
      "2019-04-22 19:42:38,821 epoch 1 - iter 80/86 - loss 7.41203293\n",
      "2019-04-22 19:42:39,506 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:42:39,510 EPOCH 1 done: loss 7.2509 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:42:40,252 DEV  : loss 3.79670930 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:42:42,699 TEST : loss 3.37036633 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:42:49,036 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:42:49,201 epoch 2 - iter 0/86 - loss 9.09100151\n",
      "2019-04-22 19:42:50,419 epoch 2 - iter 8/86 - loss 4.62039232\n",
      "2019-04-22 19:42:51,608 epoch 2 - iter 16/86 - loss 4.64299195\n",
      "2019-04-22 19:42:52,803 epoch 2 - iter 24/86 - loss 4.66542215\n",
      "2019-04-22 19:42:53,976 epoch 2 - iter 32/86 - loss 4.47066841\n",
      "2019-04-22 19:42:55,153 epoch 2 - iter 40/86 - loss 4.34377383\n",
      "2019-04-22 19:42:56,211 epoch 2 - iter 48/86 - loss 4.30609840\n",
      "2019-04-22 19:42:57,176 epoch 2 - iter 56/86 - loss 4.13915655\n",
      "2019-04-22 19:42:58,422 epoch 2 - iter 64/86 - loss 4.13852133\n",
      "2019-04-22 19:42:59,604 epoch 2 - iter 72/86 - loss 4.04715232\n",
      "2019-04-22 19:43:00,646 epoch 2 - iter 80/86 - loss 4.03202850\n",
      "2019-04-22 19:43:01,334 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:01,338 EPOCH 2 done: loss 4.0156 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:43:02,156 DEV  : loss 3.27302074 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:04,193 TEST : loss 3.16729379 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:08,212 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:08,342 epoch 3 - iter 0/86 - loss 4.93514824\n",
      "2019-04-22 19:43:09,548 epoch 3 - iter 8/86 - loss 3.79753277\n",
      "2019-04-22 19:43:10,703 epoch 3 - iter 16/86 - loss 3.19451737\n",
      "2019-04-22 19:43:11,828 epoch 3 - iter 24/86 - loss 3.26646645\n",
      "2019-04-22 19:43:12,834 epoch 3 - iter 32/86 - loss 3.37205273\n",
      "2019-04-22 19:43:13,880 epoch 3 - iter 40/86 - loss 3.51065134\n",
      "2019-04-22 19:43:15,000 epoch 3 - iter 48/86 - loss 3.63602132\n",
      "2019-04-22 19:43:16,157 epoch 3 - iter 56/86 - loss 3.53159535\n",
      "2019-04-22 19:43:17,305 epoch 3 - iter 64/86 - loss 3.56916820\n",
      "2019-04-22 19:43:18,313 epoch 3 - iter 72/86 - loss 3.54965250\n",
      "2019-04-22 19:43:19,336 epoch 3 - iter 80/86 - loss 3.54346815\n",
      "2019-04-22 19:43:20,007 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:20,009 EPOCH 3 done: loss 3.5494 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:43:20,740 DEV  : loss 2.88337779 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:22,530 TEST : loss 2.89253473 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:26,073 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:26,196 epoch 4 - iter 0/86 - loss 1.68555892\n",
      "2019-04-22 19:43:27,286 epoch 4 - iter 8/86 - loss 2.79138467\n",
      "2019-04-22 19:43:28,310 epoch 4 - iter 16/86 - loss 2.74111518\n",
      "2019-04-22 19:43:29,279 epoch 4 - iter 24/86 - loss 2.90711000\n",
      "2019-04-22 19:43:30,366 epoch 4 - iter 32/86 - loss 3.14025702\n",
      "2019-04-22 19:43:31,386 epoch 4 - iter 40/86 - loss 3.05726903\n",
      "2019-04-22 19:43:32,405 epoch 4 - iter 48/86 - loss 3.14984846\n",
      "2019-04-22 19:43:33,427 epoch 4 - iter 56/86 - loss 3.11207854\n",
      "2019-04-22 19:43:34,511 epoch 4 - iter 64/86 - loss 3.23795707\n",
      "2019-04-22 19:43:35,681 epoch 4 - iter 72/86 - loss 3.22099099\n",
      "2019-04-22 19:43:36,839 epoch 4 - iter 80/86 - loss 3.19733374\n",
      "2019-04-22 19:43:37,587 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:37,589 EPOCH 4 done: loss 3.2113 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:43:38,322 DEV  : loss 2.65478802 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:40,108 TEST : loss 2.75778389 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:43:43,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:43,804 epoch 5 - iter 0/86 - loss 3.87507892\n",
      "2019-04-22 19:43:44,834 epoch 5 - iter 8/86 - loss 3.10457473\n",
      "2019-04-22 19:43:45,836 epoch 5 - iter 16/86 - loss 2.95354742\n",
      "2019-04-22 19:43:46,863 epoch 5 - iter 24/86 - loss 3.03441485\n",
      "2019-04-22 19:43:47,902 epoch 5 - iter 32/86 - loss 3.00395295\n",
      "2019-04-22 19:43:48,933 epoch 5 - iter 40/86 - loss 3.18091029\n",
      "2019-04-22 19:43:50,063 epoch 5 - iter 48/86 - loss 3.13241594\n",
      "2019-04-22 19:43:51,139 epoch 5 - iter 56/86 - loss 3.14540545\n",
      "2019-04-22 19:43:52,332 epoch 5 - iter 64/86 - loss 3.04114332\n",
      "2019-04-22 19:43:53,403 epoch 5 - iter 72/86 - loss 3.03257794\n",
      "2019-04-22 19:43:54,417 epoch 5 - iter 80/86 - loss 3.00195047\n",
      "2019-04-22 19:43:55,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:43:55,103 EPOCH 5 done: loss 2.9772 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:43:55,831 DEV  : loss 2.84813643 - f-score 0.0122 - acc 0.0062\n",
      "2019-04-22 19:43:57,625 TEST : loss 2.97737169 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-22 19:44:01,186 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:01,295 epoch 6 - iter 0/86 - loss 3.47954106\n",
      "2019-04-22 19:44:02,341 epoch 6 - iter 8/86 - loss 3.25524194\n",
      "2019-04-22 19:44:03,371 epoch 6 - iter 16/86 - loss 3.10212051\n",
      "2019-04-22 19:44:04,383 epoch 6 - iter 24/86 - loss 3.25211786\n",
      "2019-04-22 19:44:05,397 epoch 6 - iter 32/86 - loss 3.18345325\n",
      "2019-04-22 19:44:06,428 epoch 6 - iter 40/86 - loss 3.18823999\n",
      "2019-04-22 19:44:07,398 epoch 6 - iter 48/86 - loss 3.05260165\n",
      "2019-04-22 19:44:08,417 epoch 6 - iter 56/86 - loss 2.90314110\n",
      "2019-04-22 19:44:09,511 epoch 6 - iter 64/86 - loss 2.86163055\n",
      "2019-04-22 19:44:10,643 epoch 6 - iter 72/86 - loss 2.80169776\n",
      "2019-04-22 19:44:11,854 epoch 6 - iter 80/86 - loss 2.80926659\n",
      "2019-04-22 19:44:12,597 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:12,605 EPOCH 6 done: loss 2.7959 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:44:13,335 DEV  : loss 2.13118601 - f-score 0.0099 - acc 0.0050\n",
      "2019-04-22 19:44:15,226 TEST : loss 2.60182357 - f-score 0.0062 - acc 0.0031\n",
      "2019-04-22 19:44:19,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:19,511 epoch 7 - iter 0/86 - loss 1.57679808\n",
      "2019-04-22 19:44:20,599 epoch 7 - iter 8/86 - loss 2.53864198\n",
      "2019-04-22 19:44:21,621 epoch 7 - iter 16/86 - loss 2.39498223\n",
      "2019-04-22 19:44:22,752 epoch 7 - iter 24/86 - loss 2.59330850\n",
      "2019-04-22 19:44:23,935 epoch 7 - iter 32/86 - loss 2.78433379\n",
      "2019-04-22 19:44:25,117 epoch 7 - iter 40/86 - loss 2.82096517\n",
      "2019-04-22 19:44:26,315 epoch 7 - iter 48/86 - loss 2.82709558\n",
      "2019-04-22 19:44:27,517 epoch 7 - iter 56/86 - loss 2.79647064\n",
      "2019-04-22 19:44:28,886 epoch 7 - iter 64/86 - loss 2.74910612\n",
      "2019-04-22 19:44:30,228 epoch 7 - iter 72/86 - loss 2.72759151\n",
      "2019-04-22 19:44:31,390 epoch 7 - iter 80/86 - loss 2.66019120\n",
      "2019-04-22 19:44:32,197 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:32,201 EPOCH 7 done: loss 2.6718 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:44:32,929 DEV  : loss 2.06442952 - f-score 0.0456 - acc 0.0234\n",
      "2019-04-22 19:44:34,723 TEST : loss 2.55508852 - f-score 0.0787 - acc 0.0410\n",
      "2019-04-22 19:44:38,296 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:38,406 epoch 8 - iter 0/86 - loss 1.98292911\n",
      "2019-04-22 19:44:39,457 epoch 8 - iter 8/86 - loss 2.18340153\n",
      "2019-04-22 19:44:40,487 epoch 8 - iter 16/86 - loss 2.36148308\n",
      "2019-04-22 19:44:41,527 epoch 8 - iter 24/86 - loss 2.48361316\n",
      "2019-04-22 19:44:42,544 epoch 8 - iter 32/86 - loss 2.52716668\n",
      "2019-04-22 19:44:43,593 epoch 8 - iter 40/86 - loss 2.59045507\n",
      "2019-04-22 19:44:44,744 epoch 8 - iter 48/86 - loss 2.54953483\n",
      "2019-04-22 19:44:45,909 epoch 8 - iter 56/86 - loss 2.53313483\n",
      "2019-04-22 19:44:47,059 epoch 8 - iter 64/86 - loss 2.53015823\n",
      "2019-04-22 19:44:48,045 epoch 8 - iter 72/86 - loss 2.56971490\n",
      "2019-04-22 19:44:49,042 epoch 8 - iter 80/86 - loss 2.57049048\n",
      "2019-04-22 19:44:49,744 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:49,746 EPOCH 8 done: loss 2.5560 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:44:50,471 DEV  : loss 2.12542963 - f-score 0.0322 - acc 0.0164\n",
      "2019-04-22 19:44:52,275 TEST : loss 2.36950254 - f-score 0.0590 - acc 0.0304\n",
      "2019-04-22 19:44:55,838 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:44:55,945 epoch 9 - iter 0/86 - loss 2.31613708\n",
      "2019-04-22 19:44:57,026 epoch 9 - iter 8/86 - loss 2.71417683\n",
      "2019-04-22 19:44:58,058 epoch 9 - iter 16/86 - loss 2.37042967\n",
      "2019-04-22 19:44:59,079 epoch 9 - iter 24/86 - loss 2.44554755\n",
      "2019-04-22 19:45:00,086 epoch 9 - iter 32/86 - loss 2.56229121\n",
      "2019-04-22 19:45:01,100 epoch 9 - iter 40/86 - loss 2.55809077\n",
      "2019-04-22 19:45:02,087 epoch 9 - iter 48/86 - loss 2.55388108\n",
      "2019-04-22 19:45:03,145 epoch 9 - iter 56/86 - loss 2.51198411\n",
      "2019-04-22 19:45:04,194 epoch 9 - iter 64/86 - loss 2.49853254\n",
      "2019-04-22 19:45:05,297 epoch 9 - iter 72/86 - loss 2.50551407\n",
      "2019-04-22 19:45:06,389 epoch 9 - iter 80/86 - loss 2.50183414\n",
      "2019-04-22 19:45:07,148 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:07,149 EPOCH 9 done: loss 2.4951 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:45:07,915 DEV  : loss 2.06217694 - f-score 0.0671 - acc 0.0347\n",
      "2019-04-22 19:45:09,716 TEST : loss 2.20359540 - f-score 0.1553 - acc 0.0842\n",
      "2019-04-22 19:45:13,540 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:13,681 epoch 10 - iter 0/86 - loss 2.39700317\n",
      "2019-04-22 19:45:14,738 epoch 10 - iter 8/86 - loss 2.90870708\n",
      "2019-04-22 19:45:15,713 epoch 10 - iter 16/86 - loss 2.83106689\n",
      "2019-04-22 19:45:16,726 epoch 10 - iter 24/86 - loss 2.61259607\n",
      "2019-04-22 19:45:17,758 epoch 10 - iter 32/86 - loss 2.54284506\n",
      "2019-04-22 19:45:18,734 epoch 10 - iter 40/86 - loss 2.42439982\n",
      "2019-04-22 19:45:19,838 epoch 10 - iter 48/86 - loss 2.40404182\n",
      "2019-04-22 19:45:20,998 epoch 10 - iter 56/86 - loss 2.42020045\n",
      "2019-04-22 19:45:22,064 epoch 10 - iter 64/86 - loss 2.45510818\n",
      "2019-04-22 19:45:23,153 epoch 10 - iter 72/86 - loss 2.41695684\n",
      "2019-04-22 19:45:24,166 epoch 10 - iter 80/86 - loss 2.40029354\n",
      "2019-04-22 19:45:24,836 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:24,839 EPOCH 10 done: loss 2.4085 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:45:25,565 DEV  : loss 2.10324049 - f-score 0.0419 - acc 0.0214\n",
      "2019-04-22 19:45:27,362 TEST : loss 2.21665025 - f-score 0.0742 - acc 0.0386\n",
      "2019-04-22 19:45:30,933 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:31,041 epoch 11 - iter 0/86 - loss 0.77326250\n",
      "2019-04-22 19:45:32,053 epoch 11 - iter 8/86 - loss 2.66277035\n",
      "2019-04-22 19:45:33,054 epoch 11 - iter 16/86 - loss 2.55776814\n",
      "2019-04-22 19:45:34,134 epoch 11 - iter 24/86 - loss 2.48875799\n",
      "2019-04-22 19:45:35,129 epoch 11 - iter 32/86 - loss 2.34179851\n",
      "2019-04-22 19:45:36,147 epoch 11 - iter 40/86 - loss 2.28667490\n",
      "2019-04-22 19:45:37,146 epoch 11 - iter 48/86 - loss 2.27607325\n",
      "2019-04-22 19:45:38,177 epoch 11 - iter 56/86 - loss 2.23192792\n",
      "2019-04-22 19:45:39,193 epoch 11 - iter 64/86 - loss 2.29710809\n",
      "2019-04-22 19:45:40,352 epoch 11 - iter 72/86 - loss 2.25073995\n",
      "2019-04-22 19:45:41,468 epoch 11 - iter 80/86 - loss 2.28234049\n",
      "2019-04-22 19:45:42,244 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:42,248 EPOCH 11 done: loss 2.2742 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:45:43,084 DEV  : loss 1.86620831 - f-score 0.1221 - acc 0.0650\n",
      "2019-04-22 19:45:45,143 TEST : loss 2.06909752 - f-score 0.1542 - acc 0.0836\n",
      "2019-04-22 19:45:49,235 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:45:49,363 epoch 12 - iter 0/86 - loss 1.19722092\n",
      "2019-04-22 19:45:50,597 epoch 12 - iter 8/86 - loss 1.88181958\n",
      "2019-04-22 19:45:51,782 epoch 12 - iter 16/86 - loss 1.92801182\n",
      "2019-04-22 19:45:52,842 epoch 12 - iter 24/86 - loss 2.12499621\n",
      "2019-04-22 19:45:53,887 epoch 12 - iter 32/86 - loss 2.19536227\n",
      "2019-04-22 19:45:54,954 epoch 12 - iter 40/86 - loss 2.34032772\n",
      "2019-04-22 19:45:55,997 epoch 12 - iter 48/86 - loss 2.36034637\n",
      "2019-04-22 19:45:57,001 epoch 12 - iter 56/86 - loss 2.34886235\n",
      "2019-04-22 19:45:58,109 epoch 12 - iter 64/86 - loss 2.35278676\n",
      "2019-04-22 19:45:59,251 epoch 12 - iter 72/86 - loss 2.28999495\n",
      "2019-04-22 19:46:00,346 epoch 12 - iter 80/86 - loss 2.28489567\n",
      "2019-04-22 19:46:01,025 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:01,026 EPOCH 12 done: loss 2.2736 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:46:01,756 DEV  : loss 1.82970607 - f-score 0.1309 - acc 0.0701\n",
      "2019-04-22 19:46:03,557 TEST : loss 2.31175494 - f-score 0.0670 - acc 0.0347\n",
      "2019-04-22 19:46:07,116 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:07,232 epoch 13 - iter 0/86 - loss 1.42997265\n",
      "2019-04-22 19:46:08,282 epoch 13 - iter 8/86 - loss 1.94691753\n",
      "2019-04-22 19:46:09,295 epoch 13 - iter 16/86 - loss 2.01462091\n",
      "2019-04-22 19:46:10,284 epoch 13 - iter 24/86 - loss 2.10994201\n",
      "2019-04-22 19:46:11,278 epoch 13 - iter 32/86 - loss 2.07972324\n",
      "2019-04-22 19:46:12,332 epoch 13 - iter 40/86 - loss 2.12130030\n",
      "2019-04-22 19:46:13,400 epoch 13 - iter 48/86 - loss 2.11120958\n",
      "2019-04-22 19:46:14,487 epoch 13 - iter 56/86 - loss 2.12982153\n",
      "2019-04-22 19:46:15,616 epoch 13 - iter 64/86 - loss 2.11179916\n",
      "2019-04-22 19:46:16,754 epoch 13 - iter 72/86 - loss 2.10438395\n",
      "2019-04-22 19:46:17,872 epoch 13 - iter 80/86 - loss 2.11764418\n",
      "2019-04-22 19:46:18,572 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:18,577 EPOCH 13 done: loss 2.1422 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:46:19,310 DEV  : loss 1.85449922 - f-score 0.2109 - acc 0.1179\n",
      "2019-04-22 19:46:21,110 TEST : loss 2.19481468 - f-score 0.0860 - acc 0.0449\n",
      "2019-04-22 19:46:24,690 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:24,827 epoch 14 - iter 0/86 - loss 3.14694595\n",
      "2019-04-22 19:46:25,848 epoch 14 - iter 8/86 - loss 2.07076075\n",
      "2019-04-22 19:46:26,824 epoch 14 - iter 16/86 - loss 2.01134105\n",
      "2019-04-22 19:46:27,856 epoch 14 - iter 24/86 - loss 2.08833620\n",
      "2019-04-22 19:46:28,859 epoch 14 - iter 32/86 - loss 2.15125257\n",
      "2019-04-22 19:46:29,881 epoch 14 - iter 40/86 - loss 2.10440297\n",
      "2019-04-22 19:46:30,832 epoch 14 - iter 48/86 - loss 2.07660859\n",
      "2019-04-22 19:46:31,858 epoch 14 - iter 56/86 - loss 2.11776883\n",
      "2019-04-22 19:46:32,978 epoch 14 - iter 64/86 - loss 2.08344632\n",
      "2019-04-22 19:46:34,098 epoch 14 - iter 72/86 - loss 2.10913721\n",
      "2019-04-22 19:46:35,269 epoch 14 - iter 80/86 - loss 2.18796748\n",
      "2019-04-22 19:46:36,000 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:36,001 EPOCH 14 done: loss 2.1729 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:46:36,726 DEV  : loss 1.67338240 - f-score 0.1044 - acc 0.0551\n",
      "2019-04-22 19:46:38,519 TEST : loss 2.07026219 - f-score 0.0826 - acc 0.0431\n",
      "2019-04-22 19:46:38,529 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:38,644 epoch 15 - iter 0/86 - loss 1.48331344\n",
      "2019-04-22 19:46:39,674 epoch 15 - iter 8/86 - loss 2.52204079\n",
      "2019-04-22 19:46:40,695 epoch 15 - iter 16/86 - loss 2.39376592\n",
      "2019-04-22 19:46:41,744 epoch 15 - iter 24/86 - loss 2.26891874\n",
      "2019-04-22 19:46:42,784 epoch 15 - iter 32/86 - loss 2.33965685\n",
      "2019-04-22 19:46:43,776 epoch 15 - iter 40/86 - loss 2.31792810\n",
      "2019-04-22 19:46:44,764 epoch 15 - iter 48/86 - loss 2.22112161\n",
      "2019-04-22 19:46:45,763 epoch 15 - iter 56/86 - loss 2.15773195\n",
      "2019-04-22 19:46:46,755 epoch 15 - iter 64/86 - loss 2.09779282\n",
      "2019-04-22 19:46:47,775 epoch 15 - iter 72/86 - loss 2.06127939\n",
      "2019-04-22 19:46:48,799 epoch 15 - iter 80/86 - loss 2.07864864\n",
      "2019-04-22 19:46:49,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:49,501 EPOCH 15 done: loss 2.0725 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:46:50,222 DEV  : loss 1.81052661 - f-score 0.1675 - acc 0.0914\n",
      "2019-04-22 19:46:52,020 TEST : loss 1.94984424 - f-score 0.1592 - acc 0.0865\n",
      "2019-04-22 19:46:55,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:46:55,755 epoch 16 - iter 0/86 - loss 1.79950082\n",
      "2019-04-22 19:46:56,768 epoch 16 - iter 8/86 - loss 1.73182237\n",
      "2019-04-22 19:46:57,763 epoch 16 - iter 16/86 - loss 2.09571810\n",
      "2019-04-22 19:46:58,784 epoch 16 - iter 24/86 - loss 2.18962533\n",
      "2019-04-22 19:46:59,859 epoch 16 - iter 32/86 - loss 2.24037799\n",
      "2019-04-22 19:47:00,858 epoch 16 - iter 40/86 - loss 2.16736137\n",
      "2019-04-22 19:47:01,842 epoch 16 - iter 48/86 - loss 2.13742402\n",
      "2019-04-22 19:47:02,908 epoch 16 - iter 56/86 - loss 2.06254360\n",
      "2019-04-22 19:47:04,065 epoch 16 - iter 64/86 - loss 2.13378321\n",
      "2019-04-22 19:47:05,420 epoch 16 - iter 72/86 - loss 2.15693113\n",
      "2019-04-22 19:47:06,702 epoch 16 - iter 80/86 - loss 2.13556293\n",
      "2019-04-22 19:47:07,530 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:07,532 EPOCH 16 done: loss 2.1106 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:47:08,370 DEV  : loss 1.61035180 - f-score 0.1419 - acc 0.0763\n",
      "2019-04-22 19:47:10,420 TEST : loss 1.88160968 - f-score 0.1228 - acc 0.0654\n",
      "2019-04-22 19:47:10,431 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:10,541 epoch 17 - iter 0/86 - loss 2.35376668\n",
      "2019-04-22 19:47:11,697 epoch 17 - iter 8/86 - loss 2.12576267\n",
      "2019-04-22 19:47:12,883 epoch 17 - iter 16/86 - loss 2.08428468\n",
      "2019-04-22 19:47:13,892 epoch 17 - iter 24/86 - loss 2.07686322\n",
      "2019-04-22 19:47:14,899 epoch 17 - iter 32/86 - loss 2.11283334\n",
      "2019-04-22 19:47:15,870 epoch 17 - iter 40/86 - loss 2.05044474\n",
      "2019-04-22 19:47:16,921 epoch 17 - iter 48/86 - loss 2.01460153\n",
      "2019-04-22 19:47:17,975 epoch 17 - iter 56/86 - loss 2.02879517\n",
      "2019-04-22 19:47:19,046 epoch 17 - iter 64/86 - loss 2.07036198\n",
      "2019-04-22 19:47:20,033 epoch 17 - iter 72/86 - loss 2.01568735\n",
      "2019-04-22 19:47:21,033 epoch 17 - iter 80/86 - loss 1.97620008\n",
      "2019-04-22 19:47:21,769 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:21,772 EPOCH 17 done: loss 2.0001 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:47:22,505 DEV  : loss 1.69638789 - f-score 0.1204 - acc 0.0640\n",
      "2019-04-22 19:47:24,310 TEST : loss 1.97934628 - f-score 0.1562 - acc 0.0847\n",
      "2019-04-22 19:47:27,856 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:27,976 epoch 18 - iter 0/86 - loss 1.97932804\n",
      "2019-04-22 19:47:29,020 epoch 18 - iter 8/86 - loss 1.83547227\n",
      "2019-04-22 19:47:30,072 epoch 18 - iter 16/86 - loss 1.93961082\n",
      "2019-04-22 19:47:31,070 epoch 18 - iter 24/86 - loss 1.96255343\n",
      "2019-04-22 19:47:32,169 epoch 18 - iter 32/86 - loss 2.04124253\n",
      "2019-04-22 19:47:33,203 epoch 18 - iter 40/86 - loss 2.05345699\n",
      "2019-04-22 19:47:34,264 epoch 18 - iter 48/86 - loss 2.08273658\n",
      "2019-04-22 19:47:35,310 epoch 18 - iter 56/86 - loss 2.03995934\n",
      "2019-04-22 19:47:36,400 epoch 18 - iter 64/86 - loss 1.97122191\n",
      "2019-04-22 19:47:37,485 epoch 18 - iter 72/86 - loss 1.96636961\n",
      "2019-04-22 19:47:38,575 epoch 18 - iter 80/86 - loss 1.99013497\n",
      "2019-04-22 19:47:39,313 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:39,317 EPOCH 18 done: loss 1.9836 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:47:40,045 DEV  : loss 1.60469031 - f-score 0.1383 - acc 0.0743\n",
      "2019-04-22 19:47:41,846 TEST : loss 2.10984731 - f-score 0.1627 - acc 0.0885\n",
      "2019-04-22 19:47:45,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:45,529 epoch 19 - iter 0/86 - loss 0.97964239\n",
      "2019-04-22 19:47:46,631 epoch 19 - iter 8/86 - loss 1.88396716\n",
      "2019-04-22 19:47:47,643 epoch 19 - iter 16/86 - loss 1.93505354\n",
      "2019-04-22 19:47:48,661 epoch 19 - iter 24/86 - loss 1.94009645\n",
      "2019-04-22 19:47:49,688 epoch 19 - iter 32/86 - loss 1.83822301\n",
      "2019-04-22 19:47:50,680 epoch 19 - iter 40/86 - loss 1.88237402\n",
      "2019-04-22 19:47:51,719 epoch 19 - iter 48/86 - loss 1.86102845\n",
      "2019-04-22 19:47:52,790 epoch 19 - iter 56/86 - loss 1.79315729\n",
      "2019-04-22 19:47:53,911 epoch 19 - iter 64/86 - loss 1.87566836\n",
      "2019-04-22 19:47:55,104 epoch 19 - iter 72/86 - loss 1.90466532\n",
      "2019-04-22 19:47:56,318 epoch 19 - iter 80/86 - loss 1.92704570\n",
      "2019-04-22 19:47:57,107 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:47:57,111 EPOCH 19 done: loss 1.9135 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:47:57,961 DEV  : loss 1.62272024 - f-score 0.1926 - acc 0.1066\n",
      "2019-04-22 19:48:00,055 TEST : loss 1.87969351 - f-score 0.1773 - acc 0.0973\n",
      "2019-04-22 19:48:04,233 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:04,370 epoch 20 - iter 0/86 - loss 2.88187838\n",
      "2019-04-22 19:48:05,532 epoch 20 - iter 8/86 - loss 2.34837157\n",
      "2019-04-22 19:48:06,572 epoch 20 - iter 16/86 - loss 2.13168372\n",
      "2019-04-22 19:48:07,581 epoch 20 - iter 24/86 - loss 2.11734032\n",
      "2019-04-22 19:48:08,583 epoch 20 - iter 32/86 - loss 2.01533745\n",
      "2019-04-22 19:48:09,576 epoch 20 - iter 40/86 - loss 1.99607813\n",
      "2019-04-22 19:48:10,637 epoch 20 - iter 48/86 - loss 2.00875244\n",
      "2019-04-22 19:48:11,667 epoch 20 - iter 56/86 - loss 1.97724899\n",
      "2019-04-22 19:48:12,715 epoch 20 - iter 64/86 - loss 1.91677488\n",
      "2019-04-22 19:48:13,822 epoch 20 - iter 72/86 - loss 1.88325110\n",
      "2019-04-22 19:48:15,025 epoch 20 - iter 80/86 - loss 1.96074213\n",
      "2019-04-22 19:48:15,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:15,754 EPOCH 20 done: loss 1.9342 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:48:16,490 DEV  : loss 1.76386583 - f-score 0.1363 - acc 0.0732\n",
      "2019-04-22 19:48:18,295 TEST : loss 1.91748035 - f-score 0.1775 - acc 0.0974\n",
      "2019-04-22 19:48:18,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:18,410 epoch 21 - iter 0/86 - loss 0.46058172\n",
      "2019-04-22 19:48:19,402 epoch 21 - iter 8/86 - loss 1.62033996\n",
      "2019-04-22 19:48:20,371 epoch 21 - iter 16/86 - loss 1.72922790\n",
      "2019-04-22 19:48:21,439 epoch 21 - iter 24/86 - loss 1.84903718\n",
      "2019-04-22 19:48:22,472 epoch 21 - iter 32/86 - loss 2.03080859\n",
      "2019-04-22 19:48:23,533 epoch 21 - iter 40/86 - loss 2.00049825\n",
      "2019-04-22 19:48:24,676 epoch 21 - iter 48/86 - loss 1.97469513\n",
      "2019-04-22 19:48:25,845 epoch 21 - iter 56/86 - loss 1.98307426\n",
      "2019-04-22 19:48:26,961 epoch 21 - iter 64/86 - loss 1.98593894\n",
      "2019-04-22 19:48:28,161 epoch 21 - iter 72/86 - loss 1.99289732\n",
      "2019-04-22 19:48:29,313 epoch 21 - iter 80/86 - loss 2.02982236\n",
      "2019-04-22 19:48:30,105 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:30,106 EPOCH 21 done: loss 1.9967 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:48:30,941 DEV  : loss 1.78994536 - f-score 0.1546 - acc 0.0838\n",
      "2019-04-22 19:48:32,997 TEST : loss 1.96657360 - f-score 0.1611 - acc 0.0876\n",
      "2019-04-22 19:48:33,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:33,154 epoch 22 - iter 0/86 - loss 2.84839535\n",
      "2019-04-22 19:48:34,235 epoch 22 - iter 8/86 - loss 2.07205881\n",
      "2019-04-22 19:48:35,259 epoch 22 - iter 16/86 - loss 1.80388496\n",
      "2019-04-22 19:48:36,283 epoch 22 - iter 24/86 - loss 1.89960442\n",
      "2019-04-22 19:48:37,284 epoch 22 - iter 32/86 - loss 1.76899223\n",
      "2019-04-22 19:48:38,296 epoch 22 - iter 40/86 - loss 1.81660324\n",
      "2019-04-22 19:48:39,266 epoch 22 - iter 48/86 - loss 1.83588640\n",
      "2019-04-22 19:48:40,278 epoch 22 - iter 56/86 - loss 1.93365483\n",
      "2019-04-22 19:48:41,288 epoch 22 - iter 64/86 - loss 1.90984792\n",
      "2019-04-22 19:48:42,274 epoch 22 - iter 72/86 - loss 1.86323083\n",
      "2019-04-22 19:48:43,261 epoch 22 - iter 80/86 - loss 1.84244187\n",
      "2019-04-22 19:48:43,944 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:43,945 EPOCH 22 done: loss 1.8350 - lr 0.1000 - bad epochs 2\n",
      "2019-04-22 19:48:44,670 DEV  : loss 1.47558105 - f-score 0.1962 - acc 0.1088\n",
      "2019-04-22 19:48:46,460 TEST : loss 2.01380849 - f-score 0.1856 - acc 0.1023\n",
      "2019-04-22 19:48:50,003 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:48:50,132 epoch 23 - iter 0/86 - loss 1.66954267\n",
      "2019-04-22 19:48:51,184 epoch 23 - iter 8/86 - loss 2.05768528\n",
      "2019-04-22 19:48:52,192 epoch 23 - iter 16/86 - loss 1.79240935\n",
      "2019-04-22 19:48:53,189 epoch 23 - iter 24/86 - loss 1.81460622\n",
      "2019-04-22 19:48:54,214 epoch 23 - iter 32/86 - loss 1.86677361\n",
      "2019-04-22 19:48:55,275 epoch 23 - iter 40/86 - loss 1.85720401\n",
      "2019-04-22 19:48:56,289 epoch 23 - iter 48/86 - loss 1.87597651\n",
      "2019-04-22 19:48:57,286 epoch 23 - iter 56/86 - loss 1.89480421\n",
      "2019-04-22 19:48:58,433 epoch 23 - iter 64/86 - loss 1.88965452\n",
      "2019-04-22 19:48:59,569 epoch 23 - iter 72/86 - loss 1.84768926\n",
      "2019-04-22 19:49:00,668 epoch 23 - iter 80/86 - loss 1.82788988\n",
      "2019-04-22 19:49:01,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:01,380 EPOCH 23 done: loss 1.8263 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:49:02,103 DEV  : loss 1.47486079 - f-score 0.2206 - acc 0.1240\n",
      "2019-04-22 19:49:03,904 TEST : loss 1.79857790 - f-score 0.1287 - acc 0.0688\n",
      "2019-04-22 19:49:07,442 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:07,580 epoch 24 - iter 0/86 - loss 1.95340121\n",
      "2019-04-22 19:49:08,784 epoch 24 - iter 8/86 - loss 1.55916334\n",
      "2019-04-22 19:49:09,822 epoch 24 - iter 16/86 - loss 1.68305721\n",
      "2019-04-22 19:49:10,832 epoch 24 - iter 24/86 - loss 1.69060890\n",
      "2019-04-22 19:49:11,820 epoch 24 - iter 32/86 - loss 1.69325663\n",
      "2019-04-22 19:49:12,836 epoch 24 - iter 40/86 - loss 1.83080596\n",
      "2019-04-22 19:49:13,808 epoch 24 - iter 48/86 - loss 1.79212432\n",
      "2019-04-22 19:49:14,989 epoch 24 - iter 56/86 - loss 1.84236563\n",
      "2019-04-22 19:49:16,085 epoch 24 - iter 64/86 - loss 1.80906667\n",
      "2019-04-22 19:49:17,215 epoch 24 - iter 72/86 - loss 1.81328098\n",
      "2019-04-22 19:49:18,256 epoch 24 - iter 80/86 - loss 1.79001688\n",
      "2019-04-22 19:49:18,961 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:18,965 EPOCH 24 done: loss 1.7764 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:49:19,699 DEV  : loss 1.82524848 - f-score 0.1747 - acc 0.0957\n",
      "2019-04-22 19:49:21,758 TEST : loss 1.85098445 - f-score 0.1885 - acc 0.1041\n",
      "2019-04-22 19:49:25,783 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:25,906 epoch 25 - iter 0/86 - loss 1.62259793\n",
      "2019-04-22 19:49:26,930 epoch 25 - iter 8/86 - loss 1.71041279\n",
      "2019-04-22 19:49:27,928 epoch 25 - iter 16/86 - loss 2.01902484\n",
      "2019-04-22 19:49:28,997 epoch 25 - iter 24/86 - loss 1.82901480\n",
      "2019-04-22 19:49:29,968 epoch 25 - iter 32/86 - loss 1.89680440\n",
      "2019-04-22 19:49:31,059 epoch 25 - iter 40/86 - loss 1.96134920\n",
      "2019-04-22 19:49:32,044 epoch 25 - iter 48/86 - loss 1.90572320\n",
      "2019-04-22 19:49:33,185 epoch 25 - iter 56/86 - loss 1.90522636\n",
      "2019-04-22 19:49:34,381 epoch 25 - iter 64/86 - loss 1.84563631\n",
      "2019-04-22 19:49:35,514 epoch 25 - iter 72/86 - loss 1.78498080\n",
      "2019-04-22 19:49:36,537 epoch 25 - iter 80/86 - loss 1.76983500\n",
      "2019-04-22 19:49:37,217 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:37,222 EPOCH 25 done: loss 1.7420 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:49:37,943 DEV  : loss 1.66177821 - f-score 0.1990 - acc 0.1105\n",
      "2019-04-22 19:49:39,749 TEST : loss 2.02031612 - f-score 0.1382 - acc 0.0742\n",
      "2019-04-22 19:49:43,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:43,442 epoch 26 - iter 0/86 - loss 2.42814112\n",
      "2019-04-22 19:49:44,585 epoch 26 - iter 8/86 - loss 1.81558145\n",
      "2019-04-22 19:49:45,715 epoch 26 - iter 16/86 - loss 1.81017220\n",
      "2019-04-22 19:49:46,824 epoch 26 - iter 24/86 - loss 1.84013224\n",
      "2019-04-22 19:49:47,979 epoch 26 - iter 32/86 - loss 1.79300313\n",
      "2019-04-22 19:49:49,163 epoch 26 - iter 40/86 - loss 1.70363962\n",
      "2019-04-22 19:49:50,540 epoch 26 - iter 48/86 - loss 1.74517936\n",
      "2019-04-22 19:49:51,870 epoch 26 - iter 56/86 - loss 1.71838289\n",
      "2019-04-22 19:49:53,197 epoch 26 - iter 64/86 - loss 1.71665828\n",
      "2019-04-22 19:49:54,255 epoch 26 - iter 72/86 - loss 1.73097256\n",
      "2019-04-22 19:49:55,286 epoch 26 - iter 80/86 - loss 1.74578053\n",
      "2019-04-22 19:49:56,025 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:56,028 EPOCH 26 done: loss 1.7782 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:49:56,758 DEV  : loss 1.47111619 - f-score 0.1697 - acc 0.0927\n",
      "2019-04-22 19:49:58,564 TEST : loss 2.00255752 - f-score 0.2611 - acc 0.1502\n",
      "2019-04-22 19:49:58,573 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:49:58,674 epoch 27 - iter 0/86 - loss 0.89652747\n",
      "2019-04-22 19:49:59,649 epoch 27 - iter 8/86 - loss 1.63954241\n",
      "2019-04-22 19:50:00,628 epoch 27 - iter 16/86 - loss 1.48959993\n",
      "2019-04-22 19:50:01,595 epoch 27 - iter 24/86 - loss 1.50659774\n",
      "2019-04-22 19:50:02,581 epoch 27 - iter 32/86 - loss 1.47042905\n",
      "2019-04-22 19:50:03,598 epoch 27 - iter 40/86 - loss 1.57053003\n",
      "2019-04-22 19:50:04,622 epoch 27 - iter 48/86 - loss 1.57098495\n",
      "2019-04-22 19:50:05,587 epoch 27 - iter 56/86 - loss 1.55875019\n",
      "2019-04-22 19:50:06,684 epoch 27 - iter 64/86 - loss 1.56851620\n",
      "2019-04-22 19:50:07,736 epoch 27 - iter 72/86 - loss 1.57910397\n",
      "2019-04-22 19:50:08,754 epoch 27 - iter 80/86 - loss 1.67468851\n",
      "2019-04-22 19:50:09,472 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:09,477 EPOCH 27 done: loss 1.6767 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:50:10,204 DEV  : loss 1.50691128 - f-score 0.2519 - acc 0.1441\n",
      "2019-04-22 19:50:12,002 TEST : loss 1.87059939 - f-score 0.2235 - acc 0.1258\n",
      "2019-04-22 19:50:15,612 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:15,741 epoch 28 - iter 0/86 - loss 1.77092588\n",
      "2019-04-22 19:50:16,771 epoch 28 - iter 8/86 - loss 1.58147779\n",
      "2019-04-22 19:50:17,858 epoch 28 - iter 16/86 - loss 1.60489874\n",
      "2019-04-22 19:50:18,872 epoch 28 - iter 24/86 - loss 1.63332591\n",
      "2019-04-22 19:50:19,900 epoch 28 - iter 32/86 - loss 1.66891494\n",
      "2019-04-22 19:50:20,930 epoch 28 - iter 40/86 - loss 1.72799751\n",
      "2019-04-22 19:50:22,023 epoch 28 - iter 48/86 - loss 1.77552516\n",
      "2019-04-22 19:50:23,192 epoch 28 - iter 56/86 - loss 1.76927926\n",
      "2019-04-22 19:50:24,340 epoch 28 - iter 64/86 - loss 1.74884439\n",
      "2019-04-22 19:50:25,402 epoch 28 - iter 72/86 - loss 1.73584877\n",
      "2019-04-22 19:50:26,479 epoch 28 - iter 80/86 - loss 1.74528071\n",
      "2019-04-22 19:50:27,180 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:27,184 EPOCH 28 done: loss 1.7477 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:50:27,915 DEV  : loss 1.64800680 - f-score 0.1283 - acc 0.0686\n",
      "2019-04-22 19:50:29,716 TEST : loss 1.75970972 - f-score 0.0891 - acc 0.0467\n",
      "2019-04-22 19:50:29,727 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:29,840 epoch 29 - iter 0/86 - loss 1.19101417\n",
      "2019-04-22 19:50:30,851 epoch 29 - iter 8/86 - loss 1.72721635\n",
      "2019-04-22 19:50:31,872 epoch 29 - iter 16/86 - loss 1.70117013\n",
      "2019-04-22 19:50:32,873 epoch 29 - iter 24/86 - loss 1.71078834\n",
      "2019-04-22 19:50:33,902 epoch 29 - iter 32/86 - loss 1.66120770\n",
      "2019-04-22 19:50:34,926 epoch 29 - iter 40/86 - loss 1.64654823\n",
      "2019-04-22 19:50:35,980 epoch 29 - iter 48/86 - loss 1.71686256\n",
      "2019-04-22 19:50:37,004 epoch 29 - iter 56/86 - loss 1.68091870\n",
      "2019-04-22 19:50:38,016 epoch 29 - iter 64/86 - loss 1.65104760\n",
      "2019-04-22 19:50:39,043 epoch 29 - iter 72/86 - loss 1.64098963\n",
      "2019-04-22 19:50:40,042 epoch 29 - iter 80/86 - loss 1.63068153\n",
      "2019-04-22 19:50:40,717 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:40,721 EPOCH 29 done: loss 1.6424 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:50:41,449 DEV  : loss 1.79769278 - f-score 0.1700 - acc 0.0929\n",
      "2019-04-22 19:50:43,242 TEST : loss 1.75691319 - f-score 0.2230 - acc 0.1254\n",
      "2019-04-22 19:50:46,785 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:46,905 epoch 30 - iter 0/86 - loss 2.10093546\n",
      "2019-04-22 19:50:47,961 epoch 30 - iter 8/86 - loss 1.61097742\n",
      "2019-04-22 19:50:48,972 epoch 30 - iter 16/86 - loss 1.56024617\n",
      "2019-04-22 19:50:49,985 epoch 30 - iter 24/86 - loss 1.58077377\n",
      "2019-04-22 19:50:50,973 epoch 30 - iter 32/86 - loss 1.56527640\n",
      "2019-04-22 19:50:51,963 epoch 30 - iter 40/86 - loss 1.54829719\n",
      "2019-04-22 19:50:53,010 epoch 30 - iter 48/86 - loss 1.62354897\n",
      "2019-04-22 19:50:54,057 epoch 30 - iter 56/86 - loss 1.62667142\n",
      "2019-04-22 19:50:55,185 epoch 30 - iter 64/86 - loss 1.64155608\n",
      "2019-04-22 19:50:56,320 epoch 30 - iter 72/86 - loss 1.64757170\n",
      "2019-04-22 19:50:57,480 epoch 30 - iter 80/86 - loss 1.67200148\n",
      "2019-04-22 19:50:58,175 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:50:58,176 EPOCH 30 done: loss 1.6720 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:50:58,908 DEV  : loss 1.44719934 - f-score 0.1797 - acc 0.0987\n",
      "2019-04-22 19:51:00,700 TEST : loss 1.75041294 - f-score 0.2144 - acc 0.1201\n",
      "2019-04-22 19:51:00,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:00,806 epoch 31 - iter 0/86 - loss 1.70087934\n",
      "2019-04-22 19:51:01,859 epoch 31 - iter 8/86 - loss 1.66295365\n",
      "2019-04-22 19:51:02,888 epoch 31 - iter 16/86 - loss 1.76182831\n",
      "2019-04-22 19:51:03,901 epoch 31 - iter 24/86 - loss 1.63604375\n",
      "2019-04-22 19:51:04,976 epoch 31 - iter 32/86 - loss 1.58878801\n",
      "2019-04-22 19:51:06,187 epoch 31 - iter 40/86 - loss 1.63566772\n",
      "2019-04-22 19:51:07,379 epoch 31 - iter 48/86 - loss 1.70642325\n",
      "2019-04-22 19:51:08,500 epoch 31 - iter 56/86 - loss 1.68171666\n",
      "2019-04-22 19:51:09,646 epoch 31 - iter 64/86 - loss 1.67259850\n",
      "2019-04-22 19:51:10,848 epoch 31 - iter 72/86 - loss 1.68008736\n",
      "2019-04-22 19:51:12,015 epoch 31 - iter 80/86 - loss 1.68412438\n",
      "2019-04-22 19:51:12,852 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:12,853 EPOCH 31 done: loss 1.6648 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:51:13,694 DEV  : loss 1.69632757 - f-score 0.1362 - acc 0.0731\n",
      "2019-04-22 19:51:15,550 TEST : loss 1.91680288 - f-score 0.1724 - acc 0.0943\n",
      "2019-04-22 19:51:15,559 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:15,666 epoch 32 - iter 0/86 - loss 1.99002576\n",
      "2019-04-22 19:51:16,704 epoch 32 - iter 8/86 - loss 1.59261033\n",
      "2019-04-22 19:51:17,680 epoch 32 - iter 16/86 - loss 1.59770888\n",
      "2019-04-22 19:51:18,708 epoch 32 - iter 24/86 - loss 1.48582616\n",
      "2019-04-22 19:51:19,759 epoch 32 - iter 32/86 - loss 1.48393263\n",
      "2019-04-22 19:51:20,743 epoch 32 - iter 40/86 - loss 1.53125338\n",
      "2019-04-22 19:51:21,746 epoch 32 - iter 48/86 - loss 1.52248649\n",
      "2019-04-22 19:51:22,747 epoch 32 - iter 56/86 - loss 1.51365811\n",
      "2019-04-22 19:51:23,798 epoch 32 - iter 64/86 - loss 1.58025330\n",
      "2019-04-22 19:51:24,853 epoch 32 - iter 72/86 - loss 1.63858604\n",
      "2019-04-22 19:51:25,825 epoch 32 - iter 80/86 - loss 1.62711042\n",
      "2019-04-22 19:51:26,544 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:26,548 EPOCH 32 done: loss 1.6288 - lr 0.1000 - bad epochs 2\n",
      "2019-04-22 19:51:27,271 DEV  : loss 1.58423519 - f-score 0.2090 - acc 0.1167\n",
      "2019-04-22 19:51:29,075 TEST : loss 1.85327637 - f-score 0.1686 - acc 0.0920\n",
      "2019-04-22 19:51:32,627 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:32,735 epoch 33 - iter 0/86 - loss 2.30050993\n",
      "2019-04-22 19:51:33,793 epoch 33 - iter 8/86 - loss 1.57153939\n",
      "2019-04-22 19:51:34,820 epoch 33 - iter 16/86 - loss 1.61080605\n",
      "2019-04-22 19:51:35,872 epoch 33 - iter 24/86 - loss 1.64100111\n",
      "2019-04-22 19:51:36,873 epoch 33 - iter 32/86 - loss 1.68254094\n",
      "2019-04-22 19:51:37,848 epoch 33 - iter 40/86 - loss 1.62056042\n",
      "2019-04-22 19:51:38,846 epoch 33 - iter 48/86 - loss 1.63273876\n",
      "2019-04-22 19:51:39,951 epoch 33 - iter 56/86 - loss 1.57084127\n",
      "2019-04-22 19:51:41,120 epoch 33 - iter 64/86 - loss 1.58718147\n",
      "2019-04-22 19:51:42,250 epoch 33 - iter 72/86 - loss 1.60931537\n",
      "2019-04-22 19:51:43,348 epoch 33 - iter 80/86 - loss 1.61432746\n",
      "2019-04-22 19:51:44,008 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:44,011 EPOCH 33 done: loss 1.6112 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:51:44,735 DEV  : loss 1.59297276 - f-score 0.2283 - acc 0.1289\n",
      "2019-04-22 19:51:46,537 TEST : loss 1.73219025 - f-score 0.2199 - acc 0.1235\n",
      "2019-04-22 19:51:50,078 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:51:50,197 epoch 34 - iter 0/86 - loss 1.19479036\n",
      "2019-04-22 19:51:51,250 epoch 34 - iter 8/86 - loss 1.27385145\n",
      "2019-04-22 19:51:52,269 epoch 34 - iter 16/86 - loss 1.33424344\n",
      "2019-04-22 19:51:53,310 epoch 34 - iter 24/86 - loss 1.48756557\n",
      "2019-04-22 19:51:54,306 epoch 34 - iter 32/86 - loss 1.53743413\n",
      "2019-04-22 19:51:55,319 epoch 34 - iter 40/86 - loss 1.52286646\n",
      "2019-04-22 19:51:56,334 epoch 34 - iter 48/86 - loss 1.52316567\n",
      "2019-04-22 19:51:57,345 epoch 34 - iter 56/86 - loss 1.52264058\n",
      "2019-04-22 19:51:58,552 epoch 34 - iter 64/86 - loss 1.52696716\n",
      "2019-04-22 19:51:59,727 epoch 34 - iter 72/86 - loss 1.52811770\n",
      "2019-04-22 19:52:00,769 epoch 34 - iter 80/86 - loss 1.54601103\n",
      "2019-04-22 19:52:01,484 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:01,485 EPOCH 34 done: loss 1.5809 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:52:02,222 DEV  : loss 1.55066466 - f-score 0.1800 - acc 0.0989\n",
      "2019-04-22 19:52:04,009 TEST : loss 1.82749248 - f-score 0.2663 - acc 0.1536\n",
      "2019-04-22 19:52:07,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:07,684 epoch 35 - iter 0/86 - loss 0.76481056\n",
      "2019-04-22 19:52:08,711 epoch 35 - iter 8/86 - loss 1.57356693\n",
      "2019-04-22 19:52:09,714 epoch 35 - iter 16/86 - loss 1.53889979\n",
      "2019-04-22 19:52:10,744 epoch 35 - iter 24/86 - loss 1.43852374\n",
      "2019-04-22 19:52:11,792 epoch 35 - iter 32/86 - loss 1.44727582\n",
      "2019-04-22 19:52:12,807 epoch 35 - iter 40/86 - loss 1.39190826\n",
      "2019-04-22 19:52:13,811 epoch 35 - iter 48/86 - loss 1.44476634\n",
      "2019-04-22 19:52:14,935 epoch 35 - iter 56/86 - loss 1.50601145\n",
      "2019-04-22 19:52:16,065 epoch 35 - iter 64/86 - loss 1.53511942\n",
      "2019-04-22 19:52:17,232 epoch 35 - iter 72/86 - loss 1.49617042\n",
      "2019-04-22 19:52:18,304 epoch 35 - iter 80/86 - loss 1.49356265\n",
      "2019-04-22 19:52:18,985 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:18,989 EPOCH 35 done: loss 1.5300 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:52:19,718 DEV  : loss 1.45845199 - f-score 0.2124 - acc 0.1189\n",
      "2019-04-22 19:52:21,509 TEST : loss 1.75562227 - f-score 0.2524 - acc 0.1444\n",
      "2019-04-22 19:52:25,150 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:25,271 epoch 36 - iter 0/86 - loss 1.61266208\n",
      "2019-04-22 19:52:26,470 epoch 36 - iter 8/86 - loss 1.29307007\n",
      "2019-04-22 19:52:27,636 epoch 36 - iter 16/86 - loss 1.37828076\n",
      "2019-04-22 19:52:28,848 epoch 36 - iter 24/86 - loss 1.41917974\n",
      "2019-04-22 19:52:30,069 epoch 36 - iter 32/86 - loss 1.45923991\n",
      "2019-04-22 19:52:31,161 epoch 36 - iter 40/86 - loss 1.42456424\n",
      "2019-04-22 19:52:32,369 epoch 36 - iter 48/86 - loss 1.47738090\n",
      "2019-04-22 19:52:33,770 epoch 36 - iter 56/86 - loss 1.52363355\n",
      "2019-04-22 19:52:34,969 epoch 36 - iter 64/86 - loss 1.52070676\n",
      "2019-04-22 19:52:36,077 epoch 36 - iter 72/86 - loss 1.54899427\n",
      "2019-04-22 19:52:37,073 epoch 36 - iter 80/86 - loss 1.57488924\n",
      "2019-04-22 19:52:37,735 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:37,739 EPOCH 36 done: loss 1.5629 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:52:38,464 DEV  : loss 1.51537883 - f-score 0.2140 - acc 0.1198\n",
      "2019-04-22 19:52:40,260 TEST : loss 1.65158617 - f-score 0.2112 - acc 0.1181\n",
      "2019-04-22 19:52:40,269 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:40,368 epoch 37 - iter 0/86 - loss 0.95036882\n",
      "2019-04-22 19:52:41,372 epoch 37 - iter 8/86 - loss 1.37458232\n",
      "2019-04-22 19:52:42,403 epoch 37 - iter 16/86 - loss 1.33172405\n",
      "2019-04-22 19:52:43,410 epoch 37 - iter 24/86 - loss 1.32630004\n",
      "2019-04-22 19:52:44,454 epoch 37 - iter 32/86 - loss 1.48167516\n",
      "2019-04-22 19:52:45,487 epoch 37 - iter 40/86 - loss 1.48553702\n",
      "2019-04-22 19:52:46,480 epoch 37 - iter 48/86 - loss 1.54476282\n",
      "2019-04-22 19:52:47,525 epoch 37 - iter 56/86 - loss 1.55190997\n",
      "2019-04-22 19:52:48,522 epoch 37 - iter 64/86 - loss 1.57870418\n",
      "2019-04-22 19:52:49,488 epoch 37 - iter 72/86 - loss 1.59896417\n",
      "2019-04-22 19:52:50,483 epoch 37 - iter 80/86 - loss 1.57817355\n",
      "2019-04-22 19:52:51,195 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:51,197 EPOCH 37 done: loss 1.5693 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:52:51,927 DEV  : loss 1.40678608 - f-score 0.1875 - acc 0.1034\n",
      "2019-04-22 19:52:53,731 TEST : loss 1.79934537 - f-score 0.1965 - acc 0.1089\n",
      "2019-04-22 19:52:53,740 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:52:53,840 epoch 38 - iter 0/86 - loss 0.80298179\n",
      "2019-04-22 19:52:54,848 epoch 38 - iter 8/86 - loss 1.32963987\n",
      "2019-04-22 19:52:55,903 epoch 38 - iter 16/86 - loss 1.55433176\n",
      "2019-04-22 19:52:56,980 epoch 38 - iter 24/86 - loss 1.65935495\n",
      "2019-04-22 19:52:58,041 epoch 38 - iter 32/86 - loss 1.57002385\n",
      "2019-04-22 19:52:59,057 epoch 38 - iter 40/86 - loss 1.57944399\n",
      "2019-04-22 19:53:00,053 epoch 38 - iter 48/86 - loss 1.61019040\n",
      "2019-04-22 19:53:01,063 epoch 38 - iter 56/86 - loss 1.56325649\n",
      "2019-04-22 19:53:02,099 epoch 38 - iter 64/86 - loss 1.57082687\n",
      "2019-04-22 19:53:03,062 epoch 38 - iter 72/86 - loss 1.53949000\n",
      "2019-04-22 19:53:04,048 epoch 38 - iter 80/86 - loss 1.51149222\n",
      "2019-04-22 19:53:04,706 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:04,707 EPOCH 38 done: loss 1.5007 - lr 0.1000 - bad epochs 2\n",
      "2019-04-22 19:53:05,429 DEV  : loss 1.55647457 - f-score 0.1728 - acc 0.0946\n",
      "2019-04-22 19:53:07,492 TEST : loss 1.73697770 - f-score 0.2650 - acc 0.1528\n",
      "2019-04-22 19:53:11,667 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:11,797 epoch 39 - iter 0/86 - loss 1.01010573\n",
      "2019-04-22 19:53:12,990 epoch 39 - iter 8/86 - loss 1.15306802\n",
      "2019-04-22 19:53:14,175 epoch 39 - iter 16/86 - loss 1.26525414\n",
      "2019-04-22 19:53:15,348 epoch 39 - iter 24/86 - loss 1.31564963\n",
      "2019-04-22 19:53:16,447 epoch 39 - iter 32/86 - loss 1.27418458\n",
      "2019-04-22 19:53:17,485 epoch 39 - iter 40/86 - loss 1.28382046\n",
      "2019-04-22 19:53:18,523 epoch 39 - iter 48/86 - loss 1.39373767\n",
      "2019-04-22 19:53:19,627 epoch 39 - iter 56/86 - loss 1.39857968\n",
      "2019-04-22 19:53:20,799 epoch 39 - iter 64/86 - loss 1.41889624\n",
      "2019-04-22 19:53:21,976 epoch 39 - iter 72/86 - loss 1.45086190\n",
      "2019-04-22 19:53:22,944 epoch 39 - iter 80/86 - loss 1.44024575\n",
      "2019-04-22 19:53:23,671 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:23,672 EPOCH 39 done: loss 1.4489 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:53:24,411 DEV  : loss 1.49922585 - f-score 0.2256 - acc 0.1272\n",
      "2019-04-22 19:53:26,209 TEST : loss 1.86003399 - f-score 0.1769 - acc 0.0970\n",
      "2019-04-22 19:53:29,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:29,876 epoch 40 - iter 0/86 - loss 0.88682675\n",
      "2019-04-22 19:53:30,880 epoch 40 - iter 8/86 - loss 1.35641825\n",
      "2019-04-22 19:53:31,919 epoch 40 - iter 16/86 - loss 1.50530972\n",
      "2019-04-22 19:53:32,949 epoch 40 - iter 24/86 - loss 1.50393875\n",
      "2019-04-22 19:53:33,942 epoch 40 - iter 32/86 - loss 1.42917393\n",
      "2019-04-22 19:53:34,934 epoch 40 - iter 40/86 - loss 1.39380779\n",
      "2019-04-22 19:53:35,904 epoch 40 - iter 48/86 - loss 1.41197612\n",
      "2019-04-22 19:53:36,902 epoch 40 - iter 56/86 - loss 1.42937213\n",
      "2019-04-22 19:53:38,042 epoch 40 - iter 64/86 - loss 1.45160926\n",
      "2019-04-22 19:53:39,216 epoch 40 - iter 72/86 - loss 1.46064699\n",
      "2019-04-22 19:53:40,342 epoch 40 - iter 80/86 - loss 1.44981670\n",
      "2019-04-22 19:53:41,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:41,044 EPOCH 40 done: loss 1.4599 - lr 0.1000 - bad epochs 0\n",
      "2019-04-22 19:53:41,776 DEV  : loss 1.65607202 - f-score 0.2115 - acc 0.1183\n",
      "2019-04-22 19:53:43,581 TEST : loss 1.81936610 - f-score 0.2265 - acc 0.1277\n",
      "2019-04-22 19:53:43,591 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:43,699 epoch 41 - iter 0/86 - loss 1.85019612\n",
      "2019-04-22 19:53:44,698 epoch 41 - iter 8/86 - loss 1.51131563\n",
      "2019-04-22 19:53:45,844 epoch 41 - iter 16/86 - loss 1.69410715\n",
      "2019-04-22 19:53:46,953 epoch 41 - iter 24/86 - loss 1.54195194\n",
      "2019-04-22 19:53:48,103 epoch 41 - iter 32/86 - loss 1.54189324\n",
      "2019-04-22 19:53:49,273 epoch 41 - iter 40/86 - loss 1.51223257\n",
      "2019-04-22 19:53:50,410 epoch 41 - iter 48/86 - loss 1.52912186\n",
      "2019-04-22 19:53:51,572 epoch 41 - iter 56/86 - loss 1.51188387\n",
      "2019-04-22 19:53:52,780 epoch 41 - iter 64/86 - loss 1.48902737\n",
      "2019-04-22 19:53:53,883 epoch 41 - iter 72/86 - loss 1.48760780\n",
      "2019-04-22 19:53:55,063 epoch 41 - iter 80/86 - loss 1.52760232\n",
      "2019-04-22 19:53:55,764 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:55,765 EPOCH 41 done: loss 1.5456 - lr 0.1000 - bad epochs 1\n",
      "2019-04-22 19:53:56,490 DEV  : loss 1.61704612 - f-score 0.2134 - acc 0.1195\n",
      "2019-04-22 19:53:58,289 TEST : loss 1.70611000 - f-score 0.2993 - acc 0.1760\n",
      "2019-04-22 19:53:58,298 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:53:58,407 epoch 42 - iter 0/86 - loss 1.81839681\n",
      "2019-04-22 19:53:59,455 epoch 42 - iter 8/86 - loss 1.51706002\n",
      "2019-04-22 19:54:00,483 epoch 42 - iter 16/86 - loss 1.43546565\n",
      "2019-04-22 19:54:01,474 epoch 42 - iter 24/86 - loss 1.37783839\n",
      "2019-04-22 19:54:02,473 epoch 42 - iter 32/86 - loss 1.45588853\n",
      "2019-04-22 19:54:03,498 epoch 42 - iter 40/86 - loss 1.54848213\n",
      "2019-04-22 19:54:04,503 epoch 42 - iter 48/86 - loss 1.55583061\n",
      "2019-04-22 19:54:05,513 epoch 42 - iter 56/86 - loss 1.52860732\n",
      "2019-04-22 19:54:06,491 epoch 42 - iter 64/86 - loss 1.49131908\n",
      "2019-04-22 19:54:07,538 epoch 42 - iter 72/86 - loss 1.55687723\n",
      "2019-04-22 19:54:08,543 epoch 42 - iter 80/86 - loss 1.55929467\n",
      "2019-04-22 19:54:09,285 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:09,287 EPOCH 42 done: loss 1.5553 - lr 0.1000 - bad epochs 2\n",
      "2019-04-22 19:54:10,014 DEV  : loss 1.43997288 - f-score 0.1329 - acc 0.0712\n",
      "2019-04-22 19:54:11,808 TEST : loss 1.93364334 - f-score 0.1958 - acc 0.1086\n",
      "2019-04-22 19:54:11,818 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:11,928 epoch 43 - iter 0/86 - loss 2.10330749\n",
      "2019-04-22 19:54:12,908 epoch 43 - iter 8/86 - loss 1.36751377\n",
      "2019-04-22 19:54:13,942 epoch 43 - iter 16/86 - loss 1.38852415\n",
      "2019-04-22 19:54:14,985 epoch 43 - iter 24/86 - loss 1.42195970\n",
      "2019-04-22 19:54:15,986 epoch 43 - iter 32/86 - loss 1.42105447\n",
      "2019-04-22 19:54:16,979 epoch 43 - iter 40/86 - loss 1.43534987\n",
      "2019-04-22 19:54:18,053 epoch 43 - iter 48/86 - loss 1.37046830\n",
      "2019-04-22 19:54:19,072 epoch 43 - iter 56/86 - loss 1.41753717\n",
      "2019-04-22 19:54:20,103 epoch 43 - iter 64/86 - loss 1.42843305\n",
      "2019-04-22 19:54:21,103 epoch 43 - iter 72/86 - loss 1.43204975\n",
      "2019-04-22 19:54:22,081 epoch 43 - iter 80/86 - loss 1.44830613\n",
      "2019-04-22 19:54:22,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:22,809 EPOCH 43 done: loss 1.4524 - lr 0.1000 - bad epochs 3\n",
      "2019-04-22 19:54:23,540 DEV  : loss 1.41340876 - f-score 0.2409 - acc 0.1369\n",
      "2019-04-22 19:54:25,385 TEST : loss 1.85503912 - f-score 0.2987 - acc 0.1756\n",
      "Epoch    42: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-04-22 19:54:25,397 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:25,507 epoch 44 - iter 0/86 - loss 1.42175865\n",
      "2019-04-22 19:54:26,663 epoch 44 - iter 8/86 - loss 1.23255879\n",
      "2019-04-22 19:54:27,804 epoch 44 - iter 16/86 - loss 1.35335078\n",
      "2019-04-22 19:54:29,000 epoch 44 - iter 24/86 - loss 1.30947996\n",
      "2019-04-22 19:54:30,169 epoch 44 - iter 32/86 - loss 1.33786338\n",
      "2019-04-22 19:54:31,191 epoch 44 - iter 40/86 - loss 1.29789185\n",
      "2019-04-22 19:54:32,160 epoch 44 - iter 48/86 - loss 1.33418105\n",
      "2019-04-22 19:54:33,202 epoch 44 - iter 56/86 - loss 1.31571204\n",
      "2019-04-22 19:54:34,212 epoch 44 - iter 64/86 - loss 1.30534535\n",
      "2019-04-22 19:54:35,268 epoch 44 - iter 72/86 - loss 1.34360585\n",
      "2019-04-22 19:54:36,325 epoch 44 - iter 80/86 - loss 1.35268218\n",
      "2019-04-22 19:54:37,024 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:37,026 EPOCH 44 done: loss 1.3420 - lr 0.0500 - bad epochs 0\n",
      "2019-04-22 19:54:37,757 DEV  : loss 1.36811340 - f-score 0.2048 - acc 0.1141\n",
      "2019-04-22 19:54:39,546 TEST : loss 1.81345069 - f-score 0.2054 - acc 0.1144\n",
      "2019-04-22 19:54:43,127 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:43,241 epoch 45 - iter 0/86 - loss 0.71793544\n",
      "2019-04-22 19:54:44,240 epoch 45 - iter 8/86 - loss 1.32287815\n",
      "2019-04-22 19:54:45,224 epoch 45 - iter 16/86 - loss 1.25071228\n",
      "2019-04-22 19:54:46,252 epoch 45 - iter 24/86 - loss 1.29067261\n",
      "2019-04-22 19:54:47,257 epoch 45 - iter 32/86 - loss 1.34587825\n",
      "2019-04-22 19:54:48,298 epoch 45 - iter 40/86 - loss 1.35052000\n",
      "2019-04-22 19:54:49,326 epoch 45 - iter 48/86 - loss 1.31098669\n",
      "2019-04-22 19:54:50,504 epoch 45 - iter 56/86 - loss 1.32602154\n",
      "2019-04-22 19:54:51,675 epoch 45 - iter 64/86 - loss 1.31395332\n",
      "2019-04-22 19:54:52,767 epoch 45 - iter 72/86 - loss 1.33691138\n",
      "2019-04-22 19:54:53,782 epoch 45 - iter 80/86 - loss 1.31522210\n",
      "2019-04-22 19:54:54,514 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:54:54,515 EPOCH 45 done: loss 1.2934 - lr 0.0500 - bad epochs 0\n",
      "2019-04-22 19:54:55,241 DEV  : loss 1.37911832 - f-score 0.1960 - acc 0.1087\n",
      "2019-04-22 19:54:57,030 TEST : loss 1.73534870 - f-score 0.2180 - acc 0.1223\n",
      "2019-04-22 19:55:00,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:00,700 epoch 46 - iter 0/86 - loss 1.49970722\n",
      "2019-04-22 19:55:01,726 epoch 46 - iter 8/86 - loss 1.21156328\n",
      "2019-04-22 19:55:02,747 epoch 46 - iter 16/86 - loss 1.32814450\n",
      "2019-04-22 19:55:03,785 epoch 46 - iter 24/86 - loss 1.25411336\n",
      "2019-04-22 19:55:04,808 epoch 46 - iter 32/86 - loss 1.23366254\n",
      "2019-04-22 19:55:05,861 epoch 46 - iter 40/86 - loss 1.22904246\n",
      "2019-04-22 19:55:06,995 epoch 46 - iter 48/86 - loss 1.23977848\n",
      "2019-04-22 19:55:08,321 epoch 46 - iter 56/86 - loss 1.21276474\n",
      "2019-04-22 19:55:09,762 epoch 46 - iter 64/86 - loss 1.22292762\n",
      "2019-04-22 19:55:10,937 epoch 46 - iter 72/86 - loss 1.21303700\n",
      "2019-04-22 19:55:12,103 epoch 46 - iter 80/86 - loss 1.21196904\n",
      "2019-04-22 19:55:12,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:12,942 EPOCH 46 done: loss 1.2187 - lr 0.0500 - bad epochs 0\n",
      "2019-04-22 19:55:13,772 DEV  : loss 1.37417507 - f-score 0.2684 - acc 0.1550\n",
      "2019-04-22 19:55:15,783 TEST : loss 1.71591282 - f-score 0.2719 - acc 0.1573\n",
      "2019-04-22 19:55:19,313 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:19,450 epoch 47 - iter 0/86 - loss 0.98398322\n",
      "2019-04-22 19:55:20,521 epoch 47 - iter 8/86 - loss 1.18102994\n",
      "2019-04-22 19:55:21,612 epoch 47 - iter 16/86 - loss 1.23338575\n",
      "2019-04-22 19:55:22,637 epoch 47 - iter 24/86 - loss 1.23635401\n",
      "2019-04-22 19:55:23,637 epoch 47 - iter 32/86 - loss 1.27436570\n",
      "2019-04-22 19:55:24,607 epoch 47 - iter 40/86 - loss 1.23213493\n",
      "2019-04-22 19:55:25,622 epoch 47 - iter 48/86 - loss 1.23470404\n",
      "2019-04-22 19:55:26,615 epoch 47 - iter 56/86 - loss 1.24281433\n",
      "2019-04-22 19:55:27,596 epoch 47 - iter 64/86 - loss 1.26475676\n",
      "2019-04-22 19:55:28,796 epoch 47 - iter 72/86 - loss 1.25802534\n",
      "2019-04-22 19:55:29,940 epoch 47 - iter 80/86 - loss 1.24951550\n",
      "2019-04-22 19:55:30,695 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:30,697 EPOCH 47 done: loss 1.2454 - lr 0.0500 - bad epochs 0\n",
      "2019-04-22 19:55:31,427 DEV  : loss 1.39766741 - f-score 0.1374 - acc 0.0737\n",
      "2019-04-22 19:55:33,223 TEST : loss 1.80795479 - f-score 0.2021 - acc 0.1124\n",
      "2019-04-22 19:55:33,233 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:33,349 epoch 48 - iter 0/86 - loss 1.78113985\n",
      "2019-04-22 19:55:34,344 epoch 48 - iter 8/86 - loss 1.32880568\n",
      "2019-04-22 19:55:35,343 epoch 48 - iter 16/86 - loss 1.38300692\n",
      "2019-04-22 19:55:36,385 epoch 48 - iter 24/86 - loss 1.44395186\n",
      "2019-04-22 19:55:37,362 epoch 48 - iter 32/86 - loss 1.35389781\n",
      "2019-04-22 19:55:38,369 epoch 48 - iter 40/86 - loss 1.36385446\n",
      "2019-04-22 19:55:39,338 epoch 48 - iter 48/86 - loss 1.30047038\n",
      "2019-04-22 19:55:40,311 epoch 48 - iter 56/86 - loss 1.29848417\n",
      "2019-04-22 19:55:41,342 epoch 48 - iter 64/86 - loss 1.30267914\n",
      "2019-04-22 19:55:42,344 epoch 48 - iter 72/86 - loss 1.26942885\n",
      "2019-04-22 19:55:43,363 epoch 48 - iter 80/86 - loss 1.28025347\n",
      "2019-04-22 19:55:44,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:44,090 EPOCH 48 done: loss 1.2891 - lr 0.0500 - bad epochs 1\n",
      "2019-04-22 19:55:44,824 DEV  : loss 1.28544128 - f-score 0.2290 - acc 0.1293\n",
      "2019-04-22 19:55:46,626 TEST : loss 1.85830283 - f-score 0.2823 - acc 0.1643\n",
      "2019-04-22 19:55:46,636 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:46,731 epoch 49 - iter 0/86 - loss 1.27808011\n",
      "2019-04-22 19:55:47,698 epoch 49 - iter 8/86 - loss 1.08772173\n",
      "2019-04-22 19:55:48,774 epoch 49 - iter 16/86 - loss 1.30453509\n",
      "2019-04-22 19:55:49,798 epoch 49 - iter 24/86 - loss 1.22935124\n",
      "2019-04-22 19:55:50,829 epoch 49 - iter 32/86 - loss 1.29916002\n",
      "2019-04-22 19:55:51,796 epoch 49 - iter 40/86 - loss 1.25509383\n",
      "2019-04-22 19:55:52,823 epoch 49 - iter 48/86 - loss 1.21731851\n",
      "2019-04-22 19:55:53,821 epoch 49 - iter 56/86 - loss 1.24725991\n",
      "2019-04-22 19:55:54,851 epoch 49 - iter 64/86 - loss 1.24074479\n",
      "2019-04-22 19:55:55,850 epoch 49 - iter 72/86 - loss 1.20290760\n",
      "2019-04-22 19:55:56,854 epoch 49 - iter 80/86 - loss 1.23282681\n",
      "2019-04-22 19:55:57,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:55:57,565 EPOCH 49 done: loss 1.2234 - lr 0.0500 - bad epochs 2\n",
      "2019-04-22 19:55:58,285 DEV  : loss 1.29397082 - f-score 0.2418 - acc 0.1375\n",
      "2019-04-22 19:56:00,080 TEST : loss 1.73971939 - f-score 0.3125 - acc 0.1852\n",
      "2019-04-22 19:56:00,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:00,182 epoch 50 - iter 0/86 - loss 0.50770199\n",
      "2019-04-22 19:56:01,181 epoch 50 - iter 8/86 - loss 1.12995237\n",
      "2019-04-22 19:56:02,215 epoch 50 - iter 16/86 - loss 1.11413650\n",
      "2019-04-22 19:56:03,227 epoch 50 - iter 24/86 - loss 1.13621077\n",
      "2019-04-22 19:56:04,248 epoch 50 - iter 32/86 - loss 1.17587966\n",
      "2019-04-22 19:56:05,226 epoch 50 - iter 40/86 - loss 1.21647906\n",
      "2019-04-22 19:56:06,260 epoch 50 - iter 48/86 - loss 1.17885548\n",
      "2019-04-22 19:56:07,271 epoch 50 - iter 56/86 - loss 1.21441032\n",
      "2019-04-22 19:56:08,268 epoch 50 - iter 64/86 - loss 1.23665899\n",
      "2019-04-22 19:56:09,304 epoch 50 - iter 72/86 - loss 1.24347796\n",
      "2019-04-22 19:56:10,322 epoch 50 - iter 80/86 - loss 1.23307002\n",
      "2019-04-22 19:56:11,016 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:11,020 EPOCH 50 done: loss 1.2204 - lr 0.0500 - bad epochs 3\n",
      "2019-04-22 19:56:11,740 DEV  : loss 1.35157394 - f-score 0.2037 - acc 0.1134\n",
      "2019-04-22 19:56:13,531 TEST : loss 1.73112273 - f-score 0.3229 - acc 0.1925\n",
      "Epoch    49: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-04-22 19:56:13,542 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:13,648 epoch 51 - iter 0/86 - loss 1.41396153\n",
      "2019-04-22 19:56:14,695 epoch 51 - iter 8/86 - loss 1.22053819\n",
      "2019-04-22 19:56:15,729 epoch 51 - iter 16/86 - loss 1.14447732\n",
      "2019-04-22 19:56:16,717 epoch 51 - iter 24/86 - loss 1.09976259\n",
      "2019-04-22 19:56:17,745 epoch 51 - iter 32/86 - loss 1.04614428\n",
      "2019-04-22 19:56:18,776 epoch 51 - iter 40/86 - loss 1.08938163\n",
      "2019-04-22 19:56:19,804 epoch 51 - iter 48/86 - loss 1.16550484\n",
      "2019-04-22 19:56:20,790 epoch 51 - iter 56/86 - loss 1.12148060\n",
      "2019-04-22 19:56:21,800 epoch 51 - iter 64/86 - loss 1.10820770\n",
      "2019-04-22 19:56:22,844 epoch 51 - iter 72/86 - loss 1.14946199\n",
      "2019-04-22 19:56:23,882 epoch 51 - iter 80/86 - loss 1.15267521\n",
      "2019-04-22 19:56:24,625 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:24,628 EPOCH 51 done: loss 1.1620 - lr 0.0250 - bad epochs 0\n",
      "2019-04-22 19:56:25,361 DEV  : loss 1.27147043 - f-score 0.2296 - acc 0.1297\n",
      "2019-04-22 19:56:27,356 TEST : loss 1.77373207 - f-score 0.2138 - acc 0.1197\n",
      "2019-04-22 19:56:31,407 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:31,553 epoch 52 - iter 0/86 - loss 2.32942915\n",
      "2019-04-22 19:56:32,781 epoch 52 - iter 8/86 - loss 1.19719512\n",
      "2019-04-22 19:56:33,919 epoch 52 - iter 16/86 - loss 1.16397274\n",
      "2019-04-22 19:56:35,068 epoch 52 - iter 24/86 - loss 1.15308165\n",
      "2019-04-22 19:56:36,245 epoch 52 - iter 32/86 - loss 1.16931114\n",
      "2019-04-22 19:56:37,274 epoch 52 - iter 40/86 - loss 1.13016038\n",
      "2019-04-22 19:56:38,238 epoch 52 - iter 48/86 - loss 1.12481353\n",
      "2019-04-22 19:56:39,227 epoch 52 - iter 56/86 - loss 1.14677793\n",
      "2019-04-22 19:56:40,440 epoch 52 - iter 64/86 - loss 1.17829688\n",
      "2019-04-22 19:56:41,573 epoch 52 - iter 72/86 - loss 1.15913655\n",
      "2019-04-22 19:56:42,706 epoch 52 - iter 80/86 - loss 1.14421576\n",
      "2019-04-22 19:56:43,401 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:43,405 EPOCH 52 done: loss 1.1229 - lr 0.0250 - bad epochs 0\n",
      "2019-04-22 19:56:44,133 DEV  : loss 1.31919587 - f-score 0.1868 - acc 0.1030\n",
      "2019-04-22 19:56:45,929 TEST : loss 1.77903831 - f-score 0.2343 - acc 0.1327\n",
      "2019-04-22 19:56:49,486 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:56:49,599 epoch 53 - iter 0/86 - loss 0.48120242\n",
      "2019-04-22 19:56:50,679 epoch 53 - iter 8/86 - loss 1.07367280\n",
      "2019-04-22 19:56:51,731 epoch 53 - iter 16/86 - loss 1.19215400\n",
      "2019-04-22 19:56:52,754 epoch 53 - iter 24/86 - loss 1.29647817\n",
      "2019-04-22 19:56:53,699 epoch 53 - iter 32/86 - loss 1.25281432\n",
      "2019-04-22 19:56:54,729 epoch 53 - iter 40/86 - loss 1.22584569\n",
      "2019-04-22 19:56:55,696 epoch 53 - iter 48/86 - loss 1.22870624\n",
      "2019-04-22 19:56:56,711 epoch 53 - iter 56/86 - loss 1.19288197\n",
      "2019-04-22 19:56:57,782 epoch 53 - iter 64/86 - loss 1.22562173\n",
      "2019-04-22 19:56:59,000 epoch 53 - iter 72/86 - loss 1.21598192\n",
      "2019-04-22 19:57:00,139 epoch 53 - iter 80/86 - loss 1.19660793\n",
      "2019-04-22 19:57:00,833 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:00,835 EPOCH 53 done: loss 1.1920 - lr 0.0250 - bad epochs 0\n",
      "2019-04-22 19:57:01,563 DEV  : loss 1.26283383 - f-score 0.2035 - acc 0.1133\n",
      "2019-04-22 19:57:03,376 TEST : loss 1.76169133 - f-score 0.2117 - acc 0.1184\n",
      "2019-04-22 19:57:03,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:03,484 epoch 54 - iter 0/86 - loss 0.82451314\n",
      "2019-04-22 19:57:04,523 epoch 54 - iter 8/86 - loss 1.05852852\n",
      "2019-04-22 19:57:05,556 epoch 54 - iter 16/86 - loss 1.07115564\n",
      "2019-04-22 19:57:06,561 epoch 54 - iter 24/86 - loss 1.10197267\n",
      "2019-04-22 19:57:07,584 epoch 54 - iter 32/86 - loss 1.06979313\n",
      "2019-04-22 19:57:08,593 epoch 54 - iter 40/86 - loss 1.07385463\n",
      "2019-04-22 19:57:09,575 epoch 54 - iter 48/86 - loss 1.09665293\n",
      "2019-04-22 19:57:10,543 epoch 54 - iter 56/86 - loss 1.08113691\n",
      "2019-04-22 19:57:11,549 epoch 54 - iter 64/86 - loss 1.09884639\n",
      "2019-04-22 19:57:12,498 epoch 54 - iter 72/86 - loss 1.07460056\n",
      "2019-04-22 19:57:13,535 epoch 54 - iter 80/86 - loss 1.09237174\n",
      "2019-04-22 19:57:14,216 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:14,218 EPOCH 54 done: loss 1.1041 - lr 0.0250 - bad epochs 1\n",
      "2019-04-22 19:57:14,953 DEV  : loss 1.25854504 - f-score 0.2000 - acc 0.1111\n",
      "2019-04-22 19:57:16,761 TEST : loss 1.74750376 - f-score 0.2121 - acc 0.1186\n",
      "2019-04-22 19:57:20,315 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:20,436 epoch 55 - iter 0/86 - loss 0.57548535\n",
      "2019-04-22 19:57:21,471 epoch 55 - iter 8/86 - loss 1.13066411\n",
      "2019-04-22 19:57:22,468 epoch 55 - iter 16/86 - loss 1.13713303\n",
      "2019-04-22 19:57:23,442 epoch 55 - iter 24/86 - loss 1.08231450\n",
      "2019-04-22 19:57:24,461 epoch 55 - iter 32/86 - loss 1.12992533\n",
      "2019-04-22 19:57:25,456 epoch 55 - iter 40/86 - loss 1.12101730\n",
      "2019-04-22 19:57:26,464 epoch 55 - iter 48/86 - loss 1.09571719\n",
      "2019-04-22 19:57:27,500 epoch 55 - iter 56/86 - loss 1.12484764\n",
      "2019-04-22 19:57:28,680 epoch 55 - iter 64/86 - loss 1.14115875\n",
      "2019-04-22 19:57:29,824 epoch 55 - iter 72/86 - loss 1.14927174\n",
      "2019-04-22 19:57:30,943 epoch 55 - iter 80/86 - loss 1.15192564\n",
      "2019-04-22 19:57:31,638 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:31,643 EPOCH 55 done: loss 1.1400 - lr 0.0250 - bad epochs 0\n",
      "2019-04-22 19:57:32,363 DEV  : loss 1.29987717 - f-score 0.2543 - acc 0.1456\n",
      "2019-04-22 19:57:34,159 TEST : loss 1.66081703 - f-score 0.3088 - acc 0.1826\n",
      "2019-04-22 19:57:34,169 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:34,278 epoch 56 - iter 0/86 - loss 0.63058859\n",
      "2019-04-22 19:57:35,277 epoch 56 - iter 8/86 - loss 0.95960506\n",
      "2019-04-22 19:57:36,335 epoch 56 - iter 16/86 - loss 1.06421396\n",
      "2019-04-22 19:57:37,350 epoch 56 - iter 24/86 - loss 1.07936833\n",
      "2019-04-22 19:57:38,334 epoch 56 - iter 32/86 - loss 1.13753324\n",
      "2019-04-22 19:57:39,382 epoch 56 - iter 40/86 - loss 1.13505331\n",
      "2019-04-22 19:57:40,381 epoch 56 - iter 48/86 - loss 1.12507374\n",
      "2019-04-22 19:57:41,395 epoch 56 - iter 56/86 - loss 1.17611439\n",
      "2019-04-22 19:57:42,394 epoch 56 - iter 64/86 - loss 1.12392282\n",
      "2019-04-22 19:57:43,397 epoch 56 - iter 72/86 - loss 1.13331546\n",
      "2019-04-22 19:57:44,403 epoch 56 - iter 80/86 - loss 1.12057718\n",
      "2019-04-22 19:57:45,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:45,134 EPOCH 56 done: loss 1.1116 - lr 0.0250 - bad epochs 1\n",
      "2019-04-22 19:57:45,862 DEV  : loss 1.25703406 - f-score 0.2491 - acc 0.1423\n",
      "2019-04-22 19:57:47,822 TEST : loss 1.75138116 - f-score 0.2452 - acc 0.1398\n",
      "2019-04-22 19:57:47,833 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:47,950 epoch 57 - iter 0/86 - loss 1.64052701\n",
      "2019-04-22 19:57:49,092 epoch 57 - iter 8/86 - loss 1.24319889\n",
      "2019-04-22 19:57:50,216 epoch 57 - iter 16/86 - loss 1.15592130\n",
      "2019-04-22 19:57:51,451 epoch 57 - iter 24/86 - loss 1.15717957\n",
      "2019-04-22 19:57:52,589 epoch 57 - iter 32/86 - loss 1.15578772\n",
      "2019-04-22 19:57:53,784 epoch 57 - iter 40/86 - loss 1.14439702\n",
      "2019-04-22 19:57:54,977 epoch 57 - iter 48/86 - loss 1.11846403\n",
      "2019-04-22 19:57:56,112 epoch 57 - iter 56/86 - loss 1.10185271\n",
      "2019-04-22 19:57:57,173 epoch 57 - iter 64/86 - loss 1.06306209\n",
      "2019-04-22 19:57:58,150 epoch 57 - iter 72/86 - loss 1.04811888\n",
      "2019-04-22 19:57:59,126 epoch 57 - iter 80/86 - loss 1.06162131\n",
      "2019-04-22 19:57:59,871 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:57:59,874 EPOCH 57 done: loss 1.0819 - lr 0.0250 - bad epochs 2\n",
      "2019-04-22 19:58:00,602 DEV  : loss 1.29484880 - f-score 0.2400 - acc 0.1364\n",
      "2019-04-22 19:58:02,404 TEST : loss 1.69201207 - f-score 0.2934 - acc 0.1719\n",
      "2019-04-22 19:58:05,972 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:06,079 epoch 58 - iter 0/86 - loss 1.24014723\n",
      "2019-04-22 19:58:07,132 epoch 58 - iter 8/86 - loss 1.21576622\n",
      "2019-04-22 19:58:08,227 epoch 58 - iter 16/86 - loss 1.01852191\n",
      "2019-04-22 19:58:09,250 epoch 58 - iter 24/86 - loss 1.05177536\n",
      "2019-04-22 19:58:10,283 epoch 58 - iter 32/86 - loss 1.08375169\n",
      "2019-04-22 19:58:11,256 epoch 58 - iter 40/86 - loss 1.13505383\n",
      "2019-04-22 19:58:12,289 epoch 58 - iter 48/86 - loss 1.07777980\n",
      "2019-04-22 19:58:13,318 epoch 58 - iter 56/86 - loss 1.08726104\n",
      "2019-04-22 19:58:14,293 epoch 58 - iter 64/86 - loss 1.04773106\n",
      "2019-04-22 19:58:15,388 epoch 58 - iter 72/86 - loss 1.03644371\n",
      "2019-04-22 19:58:16,587 epoch 58 - iter 80/86 - loss 1.07499482\n",
      "2019-04-22 19:58:17,550 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:17,555 EPOCH 58 done: loss 1.0906 - lr 0.0250 - bad epochs 0\n",
      "2019-04-22 19:58:18,405 DEV  : loss 1.25675142 - f-score 0.2588 - acc 0.1486\n",
      "2019-04-22 19:58:20,503 TEST : loss 1.71329772 - f-score 0.2461 - acc 0.1404\n",
      "2019-04-22 19:58:20,514 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:20,661 epoch 59 - iter 0/86 - loss 0.96826148\n",
      "2019-04-22 19:58:21,836 epoch 59 - iter 8/86 - loss 1.35845292\n",
      "2019-04-22 19:58:23,078 epoch 59 - iter 16/86 - loss 1.15842590\n",
      "2019-04-22 19:58:24,256 epoch 59 - iter 24/86 - loss 1.02347472\n",
      "2019-04-22 19:58:25,516 epoch 59 - iter 32/86 - loss 1.03599715\n",
      "2019-04-22 19:58:26,701 epoch 59 - iter 40/86 - loss 1.03947062\n",
      "2019-04-22 19:58:27,688 epoch 59 - iter 48/86 - loss 1.04984516\n",
      "2019-04-22 19:58:28,691 epoch 59 - iter 56/86 - loss 1.08428536\n",
      "2019-04-22 19:58:29,714 epoch 59 - iter 64/86 - loss 1.08227751\n",
      "2019-04-22 19:58:30,712 epoch 59 - iter 72/86 - loss 1.06726340\n",
      "2019-04-22 19:58:31,690 epoch 59 - iter 80/86 - loss 1.10320921\n",
      "2019-04-22 19:58:32,379 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:32,380 EPOCH 59 done: loss 1.0977 - lr 0.0250 - bad epochs 1\n",
      "2019-04-22 19:58:33,109 DEV  : loss 1.25891674 - f-score 0.2980 - acc 0.1751\n",
      "2019-04-22 19:58:34,894 TEST : loss 1.74777877 - f-score 0.3218 - acc 0.1917\n",
      "2019-04-22 19:58:34,904 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:35,006 epoch 60 - iter 0/86 - loss 0.97091174\n",
      "2019-04-22 19:58:36,055 epoch 60 - iter 8/86 - loss 0.93907505\n",
      "2019-04-22 19:58:37,083 epoch 60 - iter 16/86 - loss 0.95731252\n",
      "2019-04-22 19:58:38,097 epoch 60 - iter 24/86 - loss 1.07168677\n",
      "2019-04-22 19:58:39,146 epoch 60 - iter 32/86 - loss 1.10960913\n",
      "2019-04-22 19:58:40,148 epoch 60 - iter 40/86 - loss 1.10899827\n",
      "2019-04-22 19:58:41,145 epoch 60 - iter 48/86 - loss 1.11906188\n",
      "2019-04-22 19:58:42,181 epoch 60 - iter 56/86 - loss 1.10041115\n",
      "2019-04-22 19:58:43,195 epoch 60 - iter 64/86 - loss 1.12286878\n",
      "2019-04-22 19:58:44,258 epoch 60 - iter 72/86 - loss 1.12051719\n",
      "2019-04-22 19:58:45,316 epoch 60 - iter 80/86 - loss 1.10582645\n",
      "2019-04-22 19:58:46,017 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:46,018 EPOCH 60 done: loss 1.0966 - lr 0.0250 - bad epochs 2\n",
      "2019-04-22 19:58:46,759 DEV  : loss 1.34007263 - f-score 0.1878 - acc 0.1036\n",
      "2019-04-22 19:58:48,584 TEST : loss 1.70522428 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 19:58:48,593 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:48,703 epoch 61 - iter 0/86 - loss 0.73469234\n",
      "2019-04-22 19:58:49,720 epoch 61 - iter 8/86 - loss 1.02814482\n",
      "2019-04-22 19:58:50,712 epoch 61 - iter 16/86 - loss 1.04134909\n",
      "2019-04-22 19:58:51,751 epoch 61 - iter 24/86 - loss 1.05100772\n",
      "2019-04-22 19:58:52,749 epoch 61 - iter 32/86 - loss 1.09794090\n",
      "2019-04-22 19:58:53,771 epoch 61 - iter 40/86 - loss 1.11290522\n",
      "2019-04-22 19:58:54,828 epoch 61 - iter 48/86 - loss 1.11030297\n",
      "2019-04-22 19:58:55,887 epoch 61 - iter 56/86 - loss 1.12463968\n",
      "2019-04-22 19:58:56,920 epoch 61 - iter 64/86 - loss 1.11752430\n",
      "2019-04-22 19:58:57,926 epoch 61 - iter 72/86 - loss 1.10901644\n",
      "2019-04-22 19:58:58,946 epoch 61 - iter 80/86 - loss 1.10480256\n",
      "2019-04-22 19:58:59,641 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:58:59,645 EPOCH 61 done: loss 1.1089 - lr 0.0250 - bad epochs 3\n",
      "2019-04-22 19:59:00,373 DEV  : loss 1.24590516 - f-score 0.2941 - acc 0.1724\n",
      "2019-04-22 19:59:02,176 TEST : loss 1.75120258 - f-score 0.2330 - acc 0.1319\n",
      "Epoch    60: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-04-22 19:59:02,186 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:02,280 epoch 62 - iter 0/86 - loss 0.60481536\n",
      "2019-04-22 19:59:03,280 epoch 62 - iter 8/86 - loss 0.76513083\n",
      "2019-04-22 19:59:04,301 epoch 62 - iter 16/86 - loss 0.95911764\n",
      "2019-04-22 19:59:05,322 epoch 62 - iter 24/86 - loss 0.97617649\n",
      "2019-04-22 19:59:06,285 epoch 62 - iter 32/86 - loss 0.97083088\n",
      "2019-04-22 19:59:07,405 epoch 62 - iter 40/86 - loss 0.98229957\n",
      "2019-04-22 19:59:08,557 epoch 62 - iter 48/86 - loss 1.02888247\n",
      "2019-04-22 19:59:09,749 epoch 62 - iter 56/86 - loss 1.04952664\n",
      "2019-04-22 19:59:10,916 epoch 62 - iter 64/86 - loss 1.07268586\n",
      "2019-04-22 19:59:12,031 epoch 62 - iter 72/86 - loss 1.07638803\n",
      "2019-04-22 19:59:13,247 epoch 62 - iter 80/86 - loss 1.05681266\n",
      "2019-04-22 19:59:14,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:14,079 EPOCH 62 done: loss 1.0612 - lr 0.0125 - bad epochs 0\n",
      "2019-04-22 19:59:14,915 DEV  : loss 1.26075852 - f-score 0.2310 - acc 0.1306\n",
      "2019-04-22 19:59:16,973 TEST : loss 1.69045269 - f-score 0.2439 - acc 0.1389\n",
      "2019-04-22 19:59:20,588 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:20,706 epoch 63 - iter 0/86 - loss 0.74057579\n",
      "2019-04-22 19:59:21,783 epoch 63 - iter 8/86 - loss 1.07501282\n",
      "2019-04-22 19:59:22,761 epoch 63 - iter 16/86 - loss 1.03754480\n",
      "2019-04-22 19:59:23,757 epoch 63 - iter 24/86 - loss 0.99175454\n",
      "2019-04-22 19:59:24,792 epoch 63 - iter 32/86 - loss 1.02043155\n",
      "2019-04-22 19:59:25,833 epoch 63 - iter 40/86 - loss 1.04522650\n",
      "2019-04-22 19:59:26,891 epoch 63 - iter 48/86 - loss 1.04304197\n",
      "2019-04-22 19:59:28,025 epoch 63 - iter 56/86 - loss 1.08137944\n",
      "2019-04-22 19:59:29,207 epoch 63 - iter 64/86 - loss 1.09911375\n",
      "2019-04-22 19:59:30,354 epoch 63 - iter 72/86 - loss 1.09561737\n",
      "2019-04-22 19:59:31,535 epoch 63 - iter 80/86 - loss 1.09778547\n",
      "2019-04-22 19:59:32,386 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:32,388 EPOCH 63 done: loss 1.0869 - lr 0.0125 - bad epochs 0\n",
      "2019-04-22 19:59:33,234 DEV  : loss 1.24937677 - f-score 0.2465 - acc 0.1406\n",
      "2019-04-22 19:59:35,325 TEST : loss 1.68978679 - f-score 0.2510 - acc 0.1435\n",
      "2019-04-22 19:59:35,336 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:35,443 epoch 64 - iter 0/86 - loss 0.42717081\n",
      "2019-04-22 19:59:36,489 epoch 64 - iter 8/86 - loss 0.95134525\n",
      "2019-04-22 19:59:37,484 epoch 64 - iter 16/86 - loss 0.96844987\n",
      "2019-04-22 19:59:38,447 epoch 64 - iter 24/86 - loss 0.98318575\n",
      "2019-04-22 19:59:39,451 epoch 64 - iter 32/86 - loss 0.94725022\n",
      "2019-04-22 19:59:40,540 epoch 64 - iter 40/86 - loss 0.95325011\n",
      "2019-04-22 19:59:41,559 epoch 64 - iter 48/86 - loss 1.01346137\n",
      "2019-04-22 19:59:42,595 epoch 64 - iter 56/86 - loss 1.04351900\n",
      "2019-04-22 19:59:43,592 epoch 64 - iter 64/86 - loss 1.04524246\n",
      "2019-04-22 19:59:44,625 epoch 64 - iter 72/86 - loss 1.06887767\n",
      "2019-04-22 19:59:45,637 epoch 64 - iter 80/86 - loss 1.05473126\n",
      "2019-04-22 19:59:46,325 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:46,326 EPOCH 64 done: loss 1.0473 - lr 0.0125 - bad epochs 1\n",
      "2019-04-22 19:59:47,060 DEV  : loss 1.22447062 - f-score 0.2822 - acc 0.1643\n",
      "2019-04-22 19:59:48,862 TEST : loss 1.70716012 - f-score 0.2524 - acc 0.1444\n",
      "2019-04-22 19:59:52,471 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 19:59:52,582 epoch 65 - iter 0/86 - loss 1.37072027\n",
      "2019-04-22 19:59:53,610 epoch 65 - iter 8/86 - loss 1.11041702\n",
      "2019-04-22 19:59:54,664 epoch 65 - iter 16/86 - loss 1.05730544\n",
      "2019-04-22 19:59:55,668 epoch 65 - iter 24/86 - loss 1.04298359\n",
      "2019-04-22 19:59:56,674 epoch 65 - iter 32/86 - loss 1.08691921\n",
      "2019-04-22 19:59:57,678 epoch 65 - iter 40/86 - loss 1.11932644\n",
      "2019-04-22 19:59:58,705 epoch 65 - iter 48/86 - loss 1.11128438\n",
      "2019-04-22 19:59:59,699 epoch 65 - iter 56/86 - loss 1.10925491\n",
      "2019-04-22 20:00:00,703 epoch 65 - iter 64/86 - loss 1.10794934\n",
      "2019-04-22 20:00:01,667 epoch 65 - iter 72/86 - loss 1.08695093\n",
      "2019-04-22 20:00:02,733 epoch 65 - iter 80/86 - loss 1.05035005\n",
      "2019-04-22 20:00:03,572 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:03,575 EPOCH 65 done: loss 1.0489 - lr 0.0125 - bad epochs 0\n",
      "2019-04-22 20:00:04,399 DEV  : loss 1.24208581 - f-score 0.2322 - acc 0.1314\n",
      "2019-04-22 20:00:06,310 TEST : loss 1.70208693 - f-score 0.2412 - acc 0.1371\n",
      "2019-04-22 20:00:06,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:06,429 epoch 66 - iter 0/86 - loss 1.19625998\n",
      "2019-04-22 20:00:07,447 epoch 66 - iter 8/86 - loss 1.17520319\n",
      "2019-04-22 20:00:08,470 epoch 66 - iter 16/86 - loss 1.12294047\n",
      "2019-04-22 20:00:09,442 epoch 66 - iter 24/86 - loss 1.05356978\n",
      "2019-04-22 20:00:10,506 epoch 66 - iter 32/86 - loss 1.00850668\n",
      "2019-04-22 20:00:11,495 epoch 66 - iter 40/86 - loss 1.00935008\n",
      "2019-04-22 20:00:12,476 epoch 66 - iter 48/86 - loss 1.03876039\n",
      "2019-04-22 20:00:13,471 epoch 66 - iter 56/86 - loss 1.03193430\n",
      "2019-04-22 20:00:14,454 epoch 66 - iter 64/86 - loss 1.04736157\n",
      "2019-04-22 20:00:15,458 epoch 66 - iter 72/86 - loss 1.05880154\n",
      "2019-04-22 20:00:16,454 epoch 66 - iter 80/86 - loss 1.04250119\n",
      "2019-04-22 20:00:17,201 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:17,204 EPOCH 66 done: loss 1.0410 - lr 0.0125 - bad epochs 1\n",
      "2019-04-22 20:00:17,937 DEV  : loss 1.23161268 - f-score 0.2411 - acc 0.1371\n",
      "2019-04-22 20:00:19,743 TEST : loss 1.69677234 - f-score 0.2420 - acc 0.1377\n",
      "2019-04-22 20:00:23,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:23,546 epoch 67 - iter 0/86 - loss 1.03700471\n",
      "2019-04-22 20:00:24,609 epoch 67 - iter 8/86 - loss 0.80128580\n",
      "2019-04-22 20:00:25,593 epoch 67 - iter 16/86 - loss 0.88798738\n",
      "2019-04-22 20:00:26,633 epoch 67 - iter 24/86 - loss 0.96512725\n",
      "2019-04-22 20:00:27,667 epoch 67 - iter 32/86 - loss 0.93367170\n",
      "2019-04-22 20:00:28,841 epoch 67 - iter 40/86 - loss 0.93405428\n",
      "2019-04-22 20:00:30,162 epoch 67 - iter 48/86 - loss 0.92684671\n",
      "2019-04-22 20:00:31,575 epoch 67 - iter 56/86 - loss 0.93557611\n",
      "2019-04-22 20:00:32,820 epoch 67 - iter 64/86 - loss 0.97836707\n",
      "2019-04-22 20:00:33,919 epoch 67 - iter 72/86 - loss 0.98121645\n",
      "2019-04-22 20:00:35,156 epoch 67 - iter 80/86 - loss 1.02173579\n",
      "2019-04-22 20:00:35,928 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:35,930 EPOCH 67 done: loss 1.0177 - lr 0.0125 - bad epochs 0\n",
      "2019-04-22 20:00:36,763 DEV  : loss 1.24561787 - f-score 0.2857 - acc 0.1667\n",
      "2019-04-22 20:00:38,656 TEST : loss 1.67895508 - f-score 0.2975 - acc 0.1747\n",
      "2019-04-22 20:00:42,240 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:42,365 epoch 68 - iter 0/86 - loss 0.56216609\n",
      "2019-04-22 20:00:43,443 epoch 68 - iter 8/86 - loss 0.96542152\n",
      "2019-04-22 20:00:44,452 epoch 68 - iter 16/86 - loss 0.90991369\n",
      "2019-04-22 20:00:45,431 epoch 68 - iter 24/86 - loss 0.92264140\n",
      "2019-04-22 20:00:46,400 epoch 68 - iter 32/86 - loss 0.98019181\n",
      "2019-04-22 20:00:47,357 epoch 68 - iter 40/86 - loss 1.00373984\n",
      "2019-04-22 20:00:48,313 epoch 68 - iter 48/86 - loss 0.98596065\n",
      "2019-04-22 20:00:49,329 epoch 68 - iter 56/86 - loss 0.97385570\n",
      "2019-04-22 20:00:50,488 epoch 68 - iter 64/86 - loss 1.00285821\n",
      "2019-04-22 20:00:51,680 epoch 68 - iter 72/86 - loss 1.02972693\n",
      "2019-04-22 20:00:52,765 epoch 68 - iter 80/86 - loss 1.04200322\n",
      "2019-04-22 20:00:53,487 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:53,488 EPOCH 68 done: loss 1.0264 - lr 0.0125 - bad epochs 0\n",
      "2019-04-22 20:00:54,219 DEV  : loss 1.24474728 - f-score 0.2286 - acc 0.1290\n",
      "2019-04-22 20:00:56,015 TEST : loss 1.71835375 - f-score 0.2505 - acc 0.1432\n",
      "2019-04-22 20:00:56,025 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:00:56,131 epoch 69 - iter 0/86 - loss 0.69856513\n",
      "2019-04-22 20:00:57,174 epoch 69 - iter 8/86 - loss 0.95634152\n",
      "2019-04-22 20:00:58,192 epoch 69 - iter 16/86 - loss 0.85071890\n",
      "2019-04-22 20:00:59,157 epoch 69 - iter 24/86 - loss 0.93114817\n",
      "2019-04-22 20:01:00,154 epoch 69 - iter 32/86 - loss 1.08407026\n",
      "2019-04-22 20:01:01,212 epoch 69 - iter 40/86 - loss 1.11361460\n",
      "2019-04-22 20:01:02,178 epoch 69 - iter 48/86 - loss 1.08225167\n",
      "2019-04-22 20:01:03,211 epoch 69 - iter 56/86 - loss 1.05713873\n",
      "2019-04-22 20:01:04,222 epoch 69 - iter 64/86 - loss 1.05648836\n",
      "2019-04-22 20:01:05,225 epoch 69 - iter 72/86 - loss 1.05258542\n",
      "2019-04-22 20:01:06,212 epoch 69 - iter 80/86 - loss 1.04853087\n",
      "2019-04-22 20:01:06,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:06,969 EPOCH 69 done: loss 1.0368 - lr 0.0125 - bad epochs 1\n",
      "2019-04-22 20:01:07,705 DEV  : loss 1.26426470 - f-score 0.2290 - acc 0.1293\n",
      "2019-04-22 20:01:09,510 TEST : loss 1.76374269 - f-score 0.2234 - acc 0.1257\n",
      "2019-04-22 20:01:09,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:09,615 epoch 70 - iter 0/86 - loss 0.67127222\n",
      "2019-04-22 20:01:10,675 epoch 70 - iter 8/86 - loss 0.86468704\n",
      "2019-04-22 20:01:11,661 epoch 70 - iter 16/86 - loss 0.98757182\n",
      "2019-04-22 20:01:12,620 epoch 70 - iter 24/86 - loss 0.99154351\n",
      "2019-04-22 20:01:13,622 epoch 70 - iter 32/86 - loss 0.98879670\n",
      "2019-04-22 20:01:14,682 epoch 70 - iter 40/86 - loss 0.99482156\n",
      "2019-04-22 20:01:15,624 epoch 70 - iter 48/86 - loss 0.96405604\n",
      "2019-04-22 20:01:16,660 epoch 70 - iter 56/86 - loss 0.97941754\n",
      "2019-04-22 20:01:17,641 epoch 70 - iter 64/86 - loss 1.01470827\n",
      "2019-04-22 20:01:18,666 epoch 70 - iter 72/86 - loss 1.01511392\n",
      "2019-04-22 20:01:19,651 epoch 70 - iter 80/86 - loss 1.01924148\n",
      "2019-04-22 20:01:20,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:20,379 EPOCH 70 done: loss 1.0339 - lr 0.0125 - bad epochs 2\n",
      "2019-04-22 20:01:21,108 DEV  : loss 1.23652816 - f-score 0.2688 - acc 0.1553\n",
      "2019-04-22 20:01:22,900 TEST : loss 1.70804012 - f-score 0.2869 - acc 0.1675\n",
      "2019-04-22 20:01:22,910 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:23,006 epoch 71 - iter 0/86 - loss 2.69382215\n",
      "2019-04-22 20:01:24,044 epoch 71 - iter 8/86 - loss 1.06648562\n",
      "2019-04-22 20:01:25,021 epoch 71 - iter 16/86 - loss 0.96603846\n",
      "2019-04-22 20:01:26,055 epoch 71 - iter 24/86 - loss 1.01502800\n",
      "2019-04-22 20:01:27,017 epoch 71 - iter 32/86 - loss 1.03829414\n",
      "2019-04-22 20:01:27,995 epoch 71 - iter 40/86 - loss 0.98509544\n",
      "2019-04-22 20:01:29,066 epoch 71 - iter 48/86 - loss 1.03032345\n",
      "2019-04-22 20:01:30,126 epoch 71 - iter 56/86 - loss 1.03778928\n",
      "2019-04-22 20:01:31,152 epoch 71 - iter 64/86 - loss 1.06149096\n",
      "2019-04-22 20:01:32,156 epoch 71 - iter 72/86 - loss 1.03484802\n",
      "2019-04-22 20:01:33,176 epoch 71 - iter 80/86 - loss 1.02418361\n",
      "2019-04-22 20:01:33,901 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:33,905 EPOCH 71 done: loss 1.0240 - lr 0.0125 - bad epochs 3\n",
      "2019-04-22 20:01:34,639 DEV  : loss 1.21892464 - f-score 0.2914 - acc 0.1705\n",
      "2019-04-22 20:01:36,439 TEST : loss 1.73409843 - f-score 0.3040 - acc 0.1793\n",
      "Epoch    70: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-04-22 20:01:36,450 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:36,560 epoch 72 - iter 0/86 - loss 1.47235870\n",
      "2019-04-22 20:01:37,532 epoch 72 - iter 8/86 - loss 0.99063404\n",
      "2019-04-22 20:01:38,564 epoch 72 - iter 16/86 - loss 0.98998717\n",
      "2019-04-22 20:01:39,548 epoch 72 - iter 24/86 - loss 1.08696694\n",
      "2019-04-22 20:01:40,561 epoch 72 - iter 32/86 - loss 1.04684651\n",
      "2019-04-22 20:01:41,604 epoch 72 - iter 40/86 - loss 1.05496130\n",
      "2019-04-22 20:01:42,658 epoch 72 - iter 48/86 - loss 1.03736498\n",
      "2019-04-22 20:01:43,667 epoch 72 - iter 56/86 - loss 1.04398954\n",
      "2019-04-22 20:01:44,686 epoch 72 - iter 64/86 - loss 1.00717487\n",
      "2019-04-22 20:01:45,720 epoch 72 - iter 72/86 - loss 1.03613499\n",
      "2019-04-22 20:01:46,734 epoch 72 - iter 80/86 - loss 1.04775619\n",
      "2019-04-22 20:01:47,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:47,410 EPOCH 72 done: loss 1.0407 - lr 0.0063 - bad epochs 0\n",
      "2019-04-22 20:01:48,146 DEV  : loss 1.24106610 - f-score 0.2429 - acc 0.1382\n",
      "2019-04-22 20:01:50,204 TEST : loss 1.70252001 - f-score 0.2659 - acc 0.1533\n",
      "2019-04-22 20:01:50,216 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:01:50,354 epoch 73 - iter 0/86 - loss 0.78357249\n",
      "2019-04-22 20:01:51,539 epoch 73 - iter 8/86 - loss 0.92016252\n",
      "2019-04-22 20:01:52,726 epoch 73 - iter 16/86 - loss 0.89951915\n",
      "2019-04-22 20:01:53,919 epoch 73 - iter 24/86 - loss 0.89518776\n",
      "2019-04-22 20:01:55,046 epoch 73 - iter 32/86 - loss 0.91846361\n",
      "2019-04-22 20:01:56,265 epoch 73 - iter 40/86 - loss 0.93315954\n",
      "2019-04-22 20:01:57,367 epoch 73 - iter 48/86 - loss 0.92223138\n",
      "2019-04-22 20:01:58,483 epoch 73 - iter 56/86 - loss 0.92504659\n",
      "2019-04-22 20:01:59,497 epoch 73 - iter 64/86 - loss 0.92666783\n",
      "2019-04-22 20:02:00,537 epoch 73 - iter 72/86 - loss 0.97216805\n",
      "2019-04-22 20:02:01,552 epoch 73 - iter 80/86 - loss 0.99770722\n",
      "2019-04-22 20:02:02,244 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:02,246 EPOCH 73 done: loss 1.0101 - lr 0.0063 - bad epochs 1\n",
      "2019-04-22 20:02:02,975 DEV  : loss 1.22575057 - f-score 0.2535 - acc 0.1452\n",
      "2019-04-22 20:02:04,789 TEST : loss 1.73838353 - f-score 0.2644 - acc 0.1523\n",
      "2019-04-22 20:02:08,349 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:08,482 epoch 74 - iter 0/86 - loss 0.98438305\n",
      "2019-04-22 20:02:09,505 epoch 74 - iter 8/86 - loss 0.77856026\n",
      "2019-04-22 20:02:10,523 epoch 74 - iter 16/86 - loss 0.98620575\n",
      "2019-04-22 20:02:11,581 epoch 74 - iter 24/86 - loss 0.96403989\n",
      "2019-04-22 20:02:12,529 epoch 74 - iter 32/86 - loss 0.94843146\n",
      "2019-04-22 20:02:13,600 epoch 74 - iter 40/86 - loss 0.90779445\n",
      "2019-04-22 20:02:14,606 epoch 74 - iter 48/86 - loss 0.90964252\n",
      "2019-04-22 20:02:15,681 epoch 74 - iter 56/86 - loss 0.95121486\n",
      "2019-04-22 20:02:16,687 epoch 74 - iter 64/86 - loss 0.95554336\n",
      "2019-04-22 20:02:17,778 epoch 74 - iter 72/86 - loss 0.97262583\n",
      "2019-04-22 20:02:18,876 epoch 74 - iter 80/86 - loss 0.97136484\n",
      "2019-04-22 20:02:19,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:19,647 EPOCH 74 done: loss 0.9859 - lr 0.0063 - bad epochs 0\n",
      "2019-04-22 20:02:20,449 DEV  : loss 1.23730433 - f-score 0.2482 - acc 0.1417\n",
      "2019-04-22 20:02:22,252 TEST : loss 1.72436261 - f-score 0.2644 - acc 0.1523\n",
      "2019-04-22 20:02:25,853 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:25,987 epoch 75 - iter 0/86 - loss 1.54888606\n",
      "2019-04-22 20:02:27,035 epoch 75 - iter 8/86 - loss 0.93940179\n",
      "2019-04-22 20:02:28,055 epoch 75 - iter 16/86 - loss 0.98844361\n",
      "2019-04-22 20:02:29,039 epoch 75 - iter 24/86 - loss 0.95423280\n",
      "2019-04-22 20:02:30,064 epoch 75 - iter 32/86 - loss 1.00756068\n",
      "2019-04-22 20:02:31,087 epoch 75 - iter 40/86 - loss 1.04147345\n",
      "2019-04-22 20:02:32,136 epoch 75 - iter 48/86 - loss 1.05748898\n",
      "2019-04-22 20:02:33,277 epoch 75 - iter 56/86 - loss 1.05930241\n",
      "2019-04-22 20:02:34,427 epoch 75 - iter 64/86 - loss 1.05592159\n",
      "2019-04-22 20:02:35,621 epoch 75 - iter 72/86 - loss 1.03854817\n",
      "2019-04-22 20:02:36,592 epoch 75 - iter 80/86 - loss 1.02102217\n",
      "2019-04-22 20:02:37,302 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:37,303 EPOCH 75 done: loss 1.0213 - lr 0.0063 - bad epochs 0\n",
      "2019-04-22 20:02:38,037 DEV  : loss 1.22991514 - f-score 0.2596 - acc 0.1492\n",
      "2019-04-22 20:02:39,839 TEST : loss 1.74275160 - f-score 0.2447 - acc 0.1394\n",
      "2019-04-22 20:02:39,849 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:39,942 epoch 76 - iter 0/86 - loss 0.64169836\n",
      "2019-04-22 20:02:40,925 epoch 76 - iter 8/86 - loss 0.81621624\n",
      "2019-04-22 20:02:41,929 epoch 76 - iter 16/86 - loss 0.94608979\n",
      "2019-04-22 20:02:42,948 epoch 76 - iter 24/86 - loss 0.93543995\n",
      "2019-04-22 20:02:43,975 epoch 76 - iter 32/86 - loss 0.94515581\n",
      "2019-04-22 20:02:45,034 epoch 76 - iter 40/86 - loss 1.04921355\n",
      "2019-04-22 20:02:46,059 epoch 76 - iter 48/86 - loss 1.01145741\n",
      "2019-04-22 20:02:47,099 epoch 76 - iter 56/86 - loss 1.09670092\n",
      "2019-04-22 20:02:48,091 epoch 76 - iter 64/86 - loss 1.04481838\n",
      "2019-04-22 20:02:49,090 epoch 76 - iter 72/86 - loss 1.03332316\n",
      "2019-04-22 20:02:50,048 epoch 76 - iter 80/86 - loss 1.00208961\n",
      "2019-04-22 20:02:50,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:50,806 EPOCH 76 done: loss 1.0033 - lr 0.0063 - bad epochs 1\n",
      "2019-04-22 20:02:51,533 DEV  : loss 1.24958038 - f-score 0.2327 - acc 0.1317\n",
      "2019-04-22 20:02:53,334 TEST : loss 1.71547258 - f-score 0.2421 - acc 0.1377\n",
      "2019-04-22 20:02:53,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:02:53,437 epoch 77 - iter 0/86 - loss 1.07347834\n",
      "2019-04-22 20:02:54,452 epoch 77 - iter 8/86 - loss 0.99162534\n",
      "2019-04-22 20:02:55,468 epoch 77 - iter 16/86 - loss 0.96035256\n",
      "2019-04-22 20:02:56,446 epoch 77 - iter 24/86 - loss 0.95152865\n",
      "2019-04-22 20:02:57,447 epoch 77 - iter 32/86 - loss 0.95267400\n",
      "2019-04-22 20:02:58,544 epoch 77 - iter 40/86 - loss 0.94773470\n",
      "2019-04-22 20:02:59,543 epoch 77 - iter 48/86 - loss 0.90343887\n",
      "2019-04-22 20:03:00,569 epoch 77 - iter 56/86 - loss 0.94083214\n",
      "2019-04-22 20:03:01,584 epoch 77 - iter 64/86 - loss 0.96587839\n",
      "2019-04-22 20:03:02,570 epoch 77 - iter 72/86 - loss 0.97732185\n",
      "2019-04-22 20:03:03,601 epoch 77 - iter 80/86 - loss 0.96856078\n",
      "2019-04-22 20:03:04,334 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:04,337 EPOCH 77 done: loss 0.9838 - lr 0.0063 - bad epochs 2\n",
      "2019-04-22 20:03:05,067 DEV  : loss 1.24260330 - f-score 0.2392 - acc 0.1358\n",
      "2019-04-22 20:03:06,871 TEST : loss 1.72037208 - f-score 0.2500 - acc 0.1429\n",
      "2019-04-22 20:03:10,724 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:10,858 epoch 78 - iter 0/86 - loss 0.82594609\n",
      "2019-04-22 20:03:12,035 epoch 78 - iter 8/86 - loss 0.92094385\n",
      "2019-04-22 20:03:13,237 epoch 78 - iter 16/86 - loss 0.97181169\n",
      "2019-04-22 20:03:14,418 epoch 78 - iter 24/86 - loss 1.16057689\n",
      "2019-04-22 20:03:15,606 epoch 78 - iter 32/86 - loss 1.12793598\n",
      "2019-04-22 20:03:16,794 epoch 78 - iter 40/86 - loss 1.06235612\n",
      "2019-04-22 20:03:17,969 epoch 78 - iter 48/86 - loss 1.04118734\n",
      "2019-04-22 20:03:19,201 epoch 78 - iter 56/86 - loss 1.00923243\n",
      "2019-04-22 20:03:20,359 epoch 78 - iter 64/86 - loss 1.01684540\n",
      "2019-04-22 20:03:21,392 epoch 78 - iter 72/86 - loss 1.02241940\n",
      "2019-04-22 20:03:22,456 epoch 78 - iter 80/86 - loss 1.02507439\n",
      "2019-04-22 20:03:23,153 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:23,158 EPOCH 78 done: loss 1.0277 - lr 0.0063 - bad epochs 0\n",
      "2019-04-22 20:03:23,886 DEV  : loss 1.23457325 - f-score 0.2182 - acc 0.1224\n",
      "2019-04-22 20:03:25,694 TEST : loss 1.72966540 - f-score 0.2491 - acc 0.1423\n",
      "2019-04-22 20:03:25,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:25,801 epoch 79 - iter 0/86 - loss 1.17493987\n",
      "2019-04-22 20:03:26,829 epoch 79 - iter 8/86 - loss 0.95728265\n",
      "2019-04-22 20:03:28,043 epoch 79 - iter 16/86 - loss 1.00956012\n",
      "2019-04-22 20:03:29,225 epoch 79 - iter 24/86 - loss 0.94239835\n",
      "2019-04-22 20:03:30,429 epoch 79 - iter 32/86 - loss 0.99261975\n",
      "2019-04-22 20:03:31,591 epoch 79 - iter 40/86 - loss 1.00322493\n",
      "2019-04-22 20:03:32,804 epoch 79 - iter 48/86 - loss 1.01263738\n",
      "2019-04-22 20:03:33,961 epoch 79 - iter 56/86 - loss 0.99813860\n",
      "2019-04-22 20:03:35,154 epoch 79 - iter 64/86 - loss 1.00434506\n",
      "2019-04-22 20:03:36,307 epoch 79 - iter 72/86 - loss 1.00668132\n",
      "2019-04-22 20:03:37,418 epoch 79 - iter 80/86 - loss 1.00304049\n",
      "2019-04-22 20:03:38,161 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:38,163 EPOCH 79 done: loss 0.9944 - lr 0.0063 - bad epochs 1\n",
      "2019-04-22 20:03:38,895 DEV  : loss 1.24693108 - f-score 0.2263 - acc 0.1276\n",
      "2019-04-22 20:03:40,682 TEST : loss 1.74701214 - f-score 0.2298 - acc 0.1298\n",
      "2019-04-22 20:03:40,690 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:40,787 epoch 80 - iter 0/86 - loss 1.18446422\n",
      "2019-04-22 20:03:41,814 epoch 80 - iter 8/86 - loss 0.98884149\n",
      "2019-04-22 20:03:42,837 epoch 80 - iter 16/86 - loss 0.92741754\n",
      "2019-04-22 20:03:43,848 epoch 80 - iter 24/86 - loss 0.97650330\n",
      "2019-04-22 20:03:44,856 epoch 80 - iter 32/86 - loss 0.97983345\n",
      "2019-04-22 20:03:45,846 epoch 80 - iter 40/86 - loss 0.98086037\n",
      "2019-04-22 20:03:46,859 epoch 80 - iter 48/86 - loss 1.06869232\n",
      "2019-04-22 20:03:47,868 epoch 80 - iter 56/86 - loss 1.05762342\n",
      "2019-04-22 20:03:48,900 epoch 80 - iter 64/86 - loss 1.03235751\n",
      "2019-04-22 20:03:49,891 epoch 80 - iter 72/86 - loss 1.05756256\n",
      "2019-04-22 20:03:50,879 epoch 80 - iter 80/86 - loss 1.04436071\n",
      "2019-04-22 20:03:51,621 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:51,622 EPOCH 80 done: loss 1.0428 - lr 0.0063 - bad epochs 2\n",
      "2019-04-22 20:03:52,354 DEV  : loss 1.24702847 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:03:54,162 TEST : loss 1.71266234 - f-score 0.2564 - acc 0.1471\n",
      "2019-04-22 20:03:54,172 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:03:54,265 epoch 81 - iter 0/86 - loss 1.45940900\n",
      "2019-04-22 20:03:55,227 epoch 81 - iter 8/86 - loss 1.08176253\n",
      "2019-04-22 20:03:56,220 epoch 81 - iter 16/86 - loss 0.96631908\n",
      "2019-04-22 20:03:57,245 epoch 81 - iter 24/86 - loss 0.90550408\n",
      "2019-04-22 20:03:58,275 epoch 81 - iter 32/86 - loss 1.00020870\n",
      "2019-04-22 20:03:59,314 epoch 81 - iter 40/86 - loss 1.00221327\n",
      "2019-04-22 20:04:00,334 epoch 81 - iter 48/86 - loss 1.00320836\n",
      "2019-04-22 20:04:01,366 epoch 81 - iter 56/86 - loss 1.06915539\n",
      "2019-04-22 20:04:02,412 epoch 81 - iter 64/86 - loss 1.07325827\n",
      "2019-04-22 20:04:03,384 epoch 81 - iter 72/86 - loss 1.06541531\n",
      "2019-04-22 20:04:04,382 epoch 81 - iter 80/86 - loss 1.03535523\n",
      "2019-04-22 20:04:05,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:05,133 EPOCH 81 done: loss 1.0411 - lr 0.0063 - bad epochs 3\n",
      "2019-04-22 20:04:05,858 DEV  : loss 1.22620702 - f-score 0.2238 - acc 0.1260\n",
      "2019-04-22 20:04:07,659 TEST : loss 1.70161390 - f-score 0.2634 - acc 0.1516\n",
      "Epoch    80: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-04-22 20:04:07,668 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:07,765 epoch 82 - iter 0/86 - loss 1.29315853\n",
      "2019-04-22 20:04:08,781 epoch 82 - iter 8/86 - loss 0.87496228\n",
      "2019-04-22 20:04:09,803 epoch 82 - iter 16/86 - loss 1.04810495\n",
      "2019-04-22 20:04:10,760 epoch 82 - iter 24/86 - loss 1.03254181\n",
      "2019-04-22 20:04:11,784 epoch 82 - iter 32/86 - loss 1.07063963\n",
      "2019-04-22 20:04:12,804 epoch 82 - iter 40/86 - loss 1.02311589\n",
      "2019-04-22 20:04:13,820 epoch 82 - iter 48/86 - loss 1.01855414\n",
      "2019-04-22 20:04:14,871 epoch 82 - iter 56/86 - loss 1.02960735\n",
      "2019-04-22 20:04:15,910 epoch 82 - iter 64/86 - loss 1.00635695\n",
      "2019-04-22 20:04:16,894 epoch 82 - iter 72/86 - loss 0.99019279\n",
      "2019-04-22 20:04:17,893 epoch 82 - iter 80/86 - loss 1.00110424\n",
      "2019-04-22 20:04:18,590 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:18,594 EPOCH 82 done: loss 1.0133 - lr 0.0031 - bad epochs 0\n",
      "2019-04-22 20:04:19,329 DEV  : loss 1.24291706 - f-score 0.2271 - acc 0.1281\n",
      "2019-04-22 20:04:21,135 TEST : loss 1.70611572 - f-score 0.2472 - acc 0.1411\n",
      "2019-04-22 20:04:21,145 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:21,240 epoch 83 - iter 0/86 - loss 1.00170410\n",
      "2019-04-22 20:04:22,269 epoch 83 - iter 8/86 - loss 0.90734113\n",
      "2019-04-22 20:04:23,289 epoch 83 - iter 16/86 - loss 0.92411297\n",
      "2019-04-22 20:04:24,305 epoch 83 - iter 24/86 - loss 0.98508479\n",
      "2019-04-22 20:04:25,326 epoch 83 - iter 32/86 - loss 1.00043725\n",
      "2019-04-22 20:04:26,390 epoch 83 - iter 40/86 - loss 1.06143070\n",
      "2019-04-22 20:04:27,371 epoch 83 - iter 48/86 - loss 1.01081812\n",
      "2019-04-22 20:04:28,355 epoch 83 - iter 56/86 - loss 0.98234385\n",
      "2019-04-22 20:04:29,403 epoch 83 - iter 64/86 - loss 0.97181479\n",
      "2019-04-22 20:04:30,646 epoch 83 - iter 72/86 - loss 0.97733254\n",
      "2019-04-22 20:04:31,779 epoch 83 - iter 80/86 - loss 0.96154893\n",
      "2019-04-22 20:04:32,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:32,585 EPOCH 83 done: loss 0.9795 - lr 0.0031 - bad epochs 1\n",
      "2019-04-22 20:04:33,419 DEV  : loss 1.22774923 - f-score 0.2327 - acc 0.1317\n",
      "2019-04-22 20:04:35,482 TEST : loss 1.70929778 - f-score 0.2558 - acc 0.1467\n",
      "2019-04-22 20:04:39,693 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:39,808 epoch 84 - iter 0/86 - loss 0.81411254\n",
      "2019-04-22 20:04:40,972 epoch 84 - iter 8/86 - loss 0.89363305\n",
      "2019-04-22 20:04:42,020 epoch 84 - iter 16/86 - loss 0.97218602\n",
      "2019-04-22 20:04:43,029 epoch 84 - iter 24/86 - loss 0.98117471\n",
      "2019-04-22 20:04:44,050 epoch 84 - iter 32/86 - loss 0.96241295\n",
      "2019-04-22 20:04:45,078 epoch 84 - iter 40/86 - loss 0.93464937\n",
      "2019-04-22 20:04:46,123 epoch 84 - iter 48/86 - loss 0.91310795\n",
      "2019-04-22 20:04:47,151 epoch 84 - iter 56/86 - loss 0.91204972\n",
      "2019-04-22 20:04:48,234 epoch 84 - iter 64/86 - loss 0.89480772\n",
      "2019-04-22 20:04:49,382 epoch 84 - iter 72/86 - loss 0.94276586\n",
      "2019-04-22 20:04:50,540 epoch 84 - iter 80/86 - loss 0.98620131\n",
      "2019-04-22 20:04:51,232 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:51,236 EPOCH 84 done: loss 0.9738 - lr 0.0031 - bad epochs 0\n",
      "2019-04-22 20:04:51,968 DEV  : loss 1.23017097 - f-score 0.2336 - acc 0.1322\n",
      "2019-04-22 20:04:53,780 TEST : loss 1.70004785 - f-score 0.2529 - acc 0.1448\n",
      "2019-04-22 20:04:57,343 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:04:57,475 epoch 85 - iter 0/86 - loss 1.45155120\n",
      "2019-04-22 20:04:58,530 epoch 85 - iter 8/86 - loss 0.84880587\n",
      "2019-04-22 20:04:59,530 epoch 85 - iter 16/86 - loss 0.95855667\n",
      "2019-04-22 20:05:00,601 epoch 85 - iter 24/86 - loss 1.04770145\n",
      "2019-04-22 20:05:01,607 epoch 85 - iter 32/86 - loss 0.97945647\n",
      "2019-04-22 20:05:02,637 epoch 85 - iter 40/86 - loss 0.95135153\n",
      "2019-04-22 20:05:03,679 epoch 85 - iter 48/86 - loss 0.90763607\n",
      "2019-04-22 20:05:04,671 epoch 85 - iter 56/86 - loss 0.92559032\n",
      "2019-04-22 20:05:05,809 epoch 85 - iter 64/86 - loss 0.94020631\n",
      "2019-04-22 20:05:06,908 epoch 85 - iter 72/86 - loss 0.92930463\n",
      "2019-04-22 20:05:08,036 epoch 85 - iter 80/86 - loss 0.96033020\n",
      "2019-04-22 20:05:08,810 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:08,811 EPOCH 85 done: loss 0.9808 - lr 0.0031 - bad epochs 0\n",
      "2019-04-22 20:05:09,540 DEV  : loss 1.23044360 - f-score 0.2383 - acc 0.1352\n",
      "2019-04-22 20:05:11,355 TEST : loss 1.70655859 - f-score 0.2546 - acc 0.1458\n",
      "2019-04-22 20:05:11,364 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:11,472 epoch 86 - iter 0/86 - loss 2.45482779\n",
      "2019-04-22 20:05:12,494 epoch 86 - iter 8/86 - loss 1.07371089\n",
      "2019-04-22 20:05:13,511 epoch 86 - iter 16/86 - loss 1.05446917\n",
      "2019-04-22 20:05:14,502 epoch 86 - iter 24/86 - loss 1.02575023\n",
      "2019-04-22 20:05:15,505 epoch 86 - iter 32/86 - loss 0.98848092\n",
      "2019-04-22 20:05:16,490 epoch 86 - iter 40/86 - loss 0.96402761\n",
      "2019-04-22 20:05:17,533 epoch 86 - iter 48/86 - loss 1.00190075\n",
      "2019-04-22 20:05:18,584 epoch 86 - iter 56/86 - loss 0.99166933\n",
      "2019-04-22 20:05:19,550 epoch 86 - iter 64/86 - loss 0.97683137\n",
      "2019-04-22 20:05:20,533 epoch 86 - iter 72/86 - loss 0.99740148\n",
      "2019-04-22 20:05:21,564 epoch 86 - iter 80/86 - loss 0.99550130\n",
      "2019-04-22 20:05:22,282 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:22,284 EPOCH 86 done: loss 0.9996 - lr 0.0031 - bad epochs 1\n",
      "2019-04-22 20:05:23,009 DEV  : loss 1.23626745 - f-score 0.2383 - acc 0.1352\n",
      "2019-04-22 20:05:24,811 TEST : loss 1.70489204 - f-score 0.2440 - acc 0.1389\n",
      "2019-04-22 20:05:24,820 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:24,921 epoch 87 - iter 0/86 - loss 0.79298466\n",
      "2019-04-22 20:05:25,935 epoch 87 - iter 8/86 - loss 0.92989697\n",
      "2019-04-22 20:05:26,943 epoch 87 - iter 16/86 - loss 0.97444764\n",
      "2019-04-22 20:05:28,002 epoch 87 - iter 24/86 - loss 1.02075611\n",
      "2019-04-22 20:05:29,008 epoch 87 - iter 32/86 - loss 1.00596833\n",
      "2019-04-22 20:05:29,984 epoch 87 - iter 40/86 - loss 1.01283308\n",
      "2019-04-22 20:05:31,021 epoch 87 - iter 48/86 - loss 1.00387321\n",
      "2019-04-22 20:05:32,085 epoch 87 - iter 56/86 - loss 1.04119836\n",
      "2019-04-22 20:05:33,086 epoch 87 - iter 64/86 - loss 1.02649400\n",
      "2019-04-22 20:05:34,126 epoch 87 - iter 72/86 - loss 1.01012396\n",
      "2019-04-22 20:05:35,146 epoch 87 - iter 80/86 - loss 0.99735776\n",
      "2019-04-22 20:05:35,846 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:35,847 EPOCH 87 done: loss 0.9890 - lr 0.0031 - bad epochs 2\n",
      "2019-04-22 20:05:36,579 DEV  : loss 1.22136199 - f-score 0.2310 - acc 0.1306\n",
      "2019-04-22 20:05:38,369 TEST : loss 1.71550024 - f-score 0.2495 - acc 0.1425\n",
      "2019-04-22 20:05:38,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:38,516 epoch 88 - iter 0/86 - loss 1.88380778\n",
      "2019-04-22 20:05:39,537 epoch 88 - iter 8/86 - loss 1.00571042\n",
      "2019-04-22 20:05:40,604 epoch 88 - iter 16/86 - loss 1.03079730\n",
      "2019-04-22 20:05:41,656 epoch 88 - iter 24/86 - loss 1.02088849\n",
      "2019-04-22 20:05:42,656 epoch 88 - iter 32/86 - loss 1.03241065\n",
      "2019-04-22 20:05:43,695 epoch 88 - iter 40/86 - loss 1.03123520\n",
      "2019-04-22 20:05:44,699 epoch 88 - iter 48/86 - loss 1.03063872\n",
      "2019-04-22 20:05:45,707 epoch 88 - iter 56/86 - loss 1.00571752\n",
      "2019-04-22 20:05:46,698 epoch 88 - iter 64/86 - loss 1.01709839\n",
      "2019-04-22 20:05:47,698 epoch 88 - iter 72/86 - loss 1.00188585\n",
      "2019-04-22 20:05:48,705 epoch 88 - iter 80/86 - loss 0.97354334\n",
      "2019-04-22 20:05:49,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:49,386 EPOCH 88 done: loss 0.9724 - lr 0.0031 - bad epochs 3\n",
      "2019-04-22 20:05:50,179 DEV  : loss 1.22942603 - f-score 0.2319 - acc 0.1311\n",
      "2019-04-22 20:05:52,236 TEST : loss 1.70405757 - f-score 0.2450 - acc 0.1396\n",
      "2019-04-22 20:05:56,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:05:56,524 epoch 89 - iter 0/86 - loss 1.71183193\n",
      "2019-04-22 20:05:57,712 epoch 89 - iter 8/86 - loss 1.16042757\n",
      "2019-04-22 20:05:58,903 epoch 89 - iter 16/86 - loss 1.02030019\n",
      "2019-04-22 20:06:00,087 epoch 89 - iter 24/86 - loss 1.08328133\n",
      "2019-04-22 20:06:01,068 epoch 89 - iter 32/86 - loss 1.07091375\n",
      "2019-04-22 20:06:02,067 epoch 89 - iter 40/86 - loss 1.03929613\n",
      "2019-04-22 20:06:03,124 epoch 89 - iter 48/86 - loss 0.99494879\n",
      "2019-04-22 20:06:04,350 epoch 89 - iter 56/86 - loss 0.99866302\n",
      "2019-04-22 20:06:05,496 epoch 89 - iter 64/86 - loss 1.01653190\n",
      "2019-04-22 20:06:06,487 epoch 89 - iter 72/86 - loss 0.98788554\n",
      "2019-04-22 20:06:07,572 epoch 89 - iter 80/86 - loss 0.99599117\n",
      "2019-04-22 20:06:08,294 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:08,295 EPOCH 89 done: loss 1.0089 - lr 0.0031 - bad epochs 0\n",
      "2019-04-22 20:06:09,026 DEV  : loss 1.23176026 - f-score 0.2383 - acc 0.1352\n",
      "2019-04-22 20:06:10,824 TEST : loss 1.69649661 - f-score 0.2459 - acc 0.1402\n",
      "2019-04-22 20:06:10,835 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:10,936 epoch 90 - iter 0/86 - loss 1.19613791\n",
      "2019-04-22 20:06:11,986 epoch 90 - iter 8/86 - loss 1.25266092\n",
      "2019-04-22 20:06:13,022 epoch 90 - iter 16/86 - loss 1.23627835\n",
      "2019-04-22 20:06:14,031 epoch 90 - iter 24/86 - loss 1.15019653\n",
      "2019-04-22 20:06:15,068 epoch 90 - iter 32/86 - loss 1.12005800\n",
      "2019-04-22 20:06:16,053 epoch 90 - iter 40/86 - loss 1.08998944\n",
      "2019-04-22 20:06:17,053 epoch 90 - iter 48/86 - loss 1.04942870\n",
      "2019-04-22 20:06:18,042 epoch 90 - iter 56/86 - loss 1.02788683\n",
      "2019-04-22 20:06:19,038 epoch 90 - iter 64/86 - loss 1.01122294\n",
      "2019-04-22 20:06:20,044 epoch 90 - iter 72/86 - loss 0.98381344\n",
      "2019-04-22 20:06:21,060 epoch 90 - iter 80/86 - loss 0.97420656\n",
      "2019-04-22 20:06:21,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:21,779 EPOCH 90 done: loss 0.9884 - lr 0.0031 - bad epochs 1\n",
      "2019-04-22 20:06:22,506 DEV  : loss 1.22728121 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:06:24,302 TEST : loss 1.71170878 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:06:24,313 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:24,404 epoch 91 - iter 0/86 - loss 0.84681767\n",
      "2019-04-22 20:06:25,403 epoch 91 - iter 8/86 - loss 0.89044950\n",
      "2019-04-22 20:06:26,461 epoch 91 - iter 16/86 - loss 0.91676487\n",
      "2019-04-22 20:06:27,430 epoch 91 - iter 24/86 - loss 0.85325011\n",
      "2019-04-22 20:06:28,457 epoch 91 - iter 32/86 - loss 0.88967133\n",
      "2019-04-22 20:06:29,529 epoch 91 - iter 40/86 - loss 0.88787794\n",
      "2019-04-22 20:06:30,556 epoch 91 - iter 48/86 - loss 0.87568797\n",
      "2019-04-22 20:06:31,536 epoch 91 - iter 56/86 - loss 0.89300171\n",
      "2019-04-22 20:06:32,583 epoch 91 - iter 64/86 - loss 0.91272944\n",
      "2019-04-22 20:06:33,584 epoch 91 - iter 72/86 - loss 0.93943218\n",
      "2019-04-22 20:06:34,617 epoch 91 - iter 80/86 - loss 0.96983721\n",
      "2019-04-22 20:06:35,316 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:35,317 EPOCH 91 done: loss 0.9844 - lr 0.0031 - bad epochs 2\n",
      "2019-04-22 20:06:36,055 DEV  : loss 1.22063255 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:06:37,859 TEST : loss 1.72098231 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:06:37,869 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:37,976 epoch 92 - iter 0/86 - loss 1.36638141\n",
      "2019-04-22 20:06:39,025 epoch 92 - iter 8/86 - loss 1.23397449\n",
      "2019-04-22 20:06:40,057 epoch 92 - iter 16/86 - loss 1.15072311\n",
      "2019-04-22 20:06:41,027 epoch 92 - iter 24/86 - loss 1.09119695\n",
      "2019-04-22 20:06:42,007 epoch 92 - iter 32/86 - loss 1.05258289\n",
      "2019-04-22 20:06:43,038 epoch 92 - iter 40/86 - loss 1.02799012\n",
      "2019-04-22 20:06:44,107 epoch 92 - iter 48/86 - loss 1.01266515\n",
      "2019-04-22 20:06:45,080 epoch 92 - iter 56/86 - loss 0.98335843\n",
      "2019-04-22 20:06:46,119 epoch 92 - iter 64/86 - loss 0.99832293\n",
      "2019-04-22 20:06:47,116 epoch 92 - iter 72/86 - loss 1.00355106\n",
      "2019-04-22 20:06:48,166 epoch 92 - iter 80/86 - loss 1.00484134\n",
      "2019-04-22 20:06:48,891 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:48,892 EPOCH 92 done: loss 0.9996 - lr 0.0031 - bad epochs 3\n",
      "2019-04-22 20:06:49,635 DEV  : loss 1.22474897 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:06:51,455 TEST : loss 1.72292709 - f-score 0.2473 - acc 0.1411\n",
      "Epoch    91: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-04-22 20:06:51,464 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:06:51,573 epoch 93 - iter 0/86 - loss 1.11236310\n",
      "2019-04-22 20:06:52,581 epoch 93 - iter 8/86 - loss 1.10230227\n",
      "2019-04-22 20:06:53,636 epoch 93 - iter 16/86 - loss 1.07384727\n",
      "2019-04-22 20:06:54,653 epoch 93 - iter 24/86 - loss 0.98481185\n",
      "2019-04-22 20:06:55,677 epoch 93 - iter 32/86 - loss 0.97254892\n",
      "2019-04-22 20:06:56,732 epoch 93 - iter 40/86 - loss 1.02439404\n",
      "2019-04-22 20:06:57,737 epoch 93 - iter 48/86 - loss 0.98527621\n",
      "2019-04-22 20:06:58,787 epoch 93 - iter 56/86 - loss 1.01068458\n",
      "2019-04-22 20:06:59,801 epoch 93 - iter 64/86 - loss 1.01415268\n",
      "2019-04-22 20:07:00,810 epoch 93 - iter 72/86 - loss 1.02470072\n",
      "2019-04-22 20:07:01,898 epoch 93 - iter 80/86 - loss 1.00791545\n",
      "2019-04-22 20:07:02,704 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:02,707 EPOCH 93 done: loss 1.0061 - lr 0.0016 - bad epochs 0\n",
      "2019-04-22 20:07:03,440 DEV  : loss 1.22595704 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:07:05,245 TEST : loss 1.71852064 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:07:05,255 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:05,369 epoch 94 - iter 0/86 - loss 0.48749644\n",
      "2019-04-22 20:07:06,383 epoch 94 - iter 8/86 - loss 0.79867193\n",
      "2019-04-22 20:07:07,370 epoch 94 - iter 16/86 - loss 0.99847632\n",
      "2019-04-22 20:07:08,447 epoch 94 - iter 24/86 - loss 0.88890674\n",
      "2019-04-22 20:07:09,463 epoch 94 - iter 32/86 - loss 0.88319737\n",
      "2019-04-22 20:07:10,561 epoch 94 - iter 40/86 - loss 0.88292882\n",
      "2019-04-22 20:07:11,743 epoch 94 - iter 48/86 - loss 0.93647621\n",
      "2019-04-22 20:07:12,959 epoch 94 - iter 56/86 - loss 0.98333432\n",
      "2019-04-22 20:07:14,181 epoch 94 - iter 64/86 - loss 1.00189615\n",
      "2019-04-22 20:07:15,361 epoch 94 - iter 72/86 - loss 0.99866156\n",
      "2019-04-22 20:07:16,455 epoch 94 - iter 80/86 - loss 0.98707786\n",
      "2019-04-22 20:07:17,308 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:17,309 EPOCH 94 done: loss 0.9828 - lr 0.0016 - bad epochs 1\n",
      "2019-04-22 20:07:18,158 DEV  : loss 1.22231495 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:07:20,225 TEST : loss 1.71986902 - f-score 0.2595 - acc 0.1491\n",
      "2019-04-22 20:07:20,236 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:20,329 epoch 95 - iter 0/86 - loss 0.81813550\n",
      "2019-04-22 20:07:21,378 epoch 95 - iter 8/86 - loss 0.85343302\n",
      "2019-04-22 20:07:22,408 epoch 95 - iter 16/86 - loss 1.06651368\n",
      "2019-04-22 20:07:23,396 epoch 95 - iter 24/86 - loss 1.00907565\n",
      "2019-04-22 20:07:24,394 epoch 95 - iter 32/86 - loss 1.02442213\n",
      "2019-04-22 20:07:25,443 epoch 95 - iter 40/86 - loss 1.02763930\n",
      "2019-04-22 20:07:26,506 epoch 95 - iter 48/86 - loss 1.01724714\n",
      "2019-04-22 20:07:27,511 epoch 95 - iter 56/86 - loss 1.00863272\n",
      "2019-04-22 20:07:28,517 epoch 95 - iter 64/86 - loss 0.98198679\n",
      "2019-04-22 20:07:29,565 epoch 95 - iter 72/86 - loss 0.98955098\n",
      "2019-04-22 20:07:30,618 epoch 95 - iter 80/86 - loss 0.98739205\n",
      "2019-04-22 20:07:31,340 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:31,342 EPOCH 95 done: loss 0.9927 - lr 0.0016 - bad epochs 2\n",
      "2019-04-22 20:07:32,077 DEV  : loss 1.22239351 - f-score 0.2319 - acc 0.1311\n",
      "2019-04-22 20:07:33,881 TEST : loss 1.71976006 - f-score 0.2595 - acc 0.1491\n",
      "2019-04-22 20:07:33,891 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:34,015 epoch 96 - iter 0/86 - loss 1.64020669\n",
      "2019-04-22 20:07:35,102 epoch 96 - iter 8/86 - loss 1.08181498\n",
      "2019-04-22 20:07:36,163 epoch 96 - iter 16/86 - loss 0.94038617\n",
      "2019-04-22 20:07:37,207 epoch 96 - iter 24/86 - loss 0.92455096\n",
      "2019-04-22 20:07:38,241 epoch 96 - iter 32/86 - loss 0.90621120\n",
      "2019-04-22 20:07:39,247 epoch 96 - iter 40/86 - loss 0.92344030\n",
      "2019-04-22 20:07:40,286 epoch 96 - iter 48/86 - loss 0.96780984\n",
      "2019-04-22 20:07:41,263 epoch 96 - iter 56/86 - loss 0.96688751\n",
      "2019-04-22 20:07:42,286 epoch 96 - iter 64/86 - loss 0.96738710\n",
      "2019-04-22 20:07:43,294 epoch 96 - iter 72/86 - loss 0.94710069\n",
      "2019-04-22 20:07:44,293 epoch 96 - iter 80/86 - loss 0.97370624\n",
      "2019-04-22 20:07:44,981 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:44,983 EPOCH 96 done: loss 0.9796 - lr 0.0016 - bad epochs 3\n",
      "2019-04-22 20:07:45,727 DEV  : loss 1.22202492 - f-score 0.2446 - acc 0.1393\n",
      "2019-04-22 20:07:47,536 TEST : loss 1.71727443 - f-score 0.2595 - acc 0.1491\n",
      "Epoch    95: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-04-22 20:07:47,543 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:47,645 epoch 97 - iter 0/86 - loss 0.47610891\n",
      "2019-04-22 20:07:48,678 epoch 97 - iter 8/86 - loss 0.79262590\n",
      "2019-04-22 20:07:49,672 epoch 97 - iter 16/86 - loss 0.84495433\n",
      "2019-04-22 20:07:50,688 epoch 97 - iter 24/86 - loss 0.90163826\n",
      "2019-04-22 20:07:51,728 epoch 97 - iter 32/86 - loss 0.89345866\n",
      "2019-04-22 20:07:52,777 epoch 97 - iter 40/86 - loss 0.94110372\n",
      "2019-04-22 20:07:53,832 epoch 97 - iter 48/86 - loss 0.92425108\n",
      "2019-04-22 20:07:54,873 epoch 97 - iter 56/86 - loss 0.96306574\n",
      "2019-04-22 20:07:55,896 epoch 97 - iter 64/86 - loss 0.94331463\n",
      "2019-04-22 20:07:56,919 epoch 97 - iter 72/86 - loss 0.98860111\n",
      "2019-04-22 20:07:58,004 epoch 97 - iter 80/86 - loss 0.96988583\n",
      "2019-04-22 20:07:58,746 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:07:58,748 EPOCH 97 done: loss 0.9716 - lr 0.0008 - bad epochs 0\n",
      "2019-04-22 20:07:59,478 DEV  : loss 1.22389841 - f-score 0.2238 - acc 0.1260\n",
      "2019-04-22 20:08:01,295 TEST : loss 1.71738625 - f-score 0.2595 - acc 0.1491\n",
      "2019-04-22 20:08:04,950 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:05,060 epoch 98 - iter 0/86 - loss 0.77899146\n",
      "2019-04-22 20:08:06,153 epoch 98 - iter 8/86 - loss 1.08836960\n",
      "2019-04-22 20:08:07,162 epoch 98 - iter 16/86 - loss 1.01020157\n",
      "2019-04-22 20:08:08,160 epoch 98 - iter 24/86 - loss 1.01857814\n",
      "2019-04-22 20:08:09,178 epoch 98 - iter 32/86 - loss 0.96340220\n",
      "2019-04-22 20:08:10,186 epoch 98 - iter 40/86 - loss 0.91714840\n",
      "2019-04-22 20:08:11,222 epoch 98 - iter 48/86 - loss 0.95808121\n",
      "2019-04-22 20:08:12,239 epoch 98 - iter 56/86 - loss 0.96835387\n",
      "2019-04-22 20:08:13,393 epoch 98 - iter 64/86 - loss 0.95060395\n",
      "2019-04-22 20:08:14,638 epoch 98 - iter 72/86 - loss 0.93894270\n",
      "2019-04-22 20:08:15,864 epoch 98 - iter 80/86 - loss 0.98834168\n",
      "2019-04-22 20:08:16,574 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:16,575 EPOCH 98 done: loss 0.9734 - lr 0.0008 - bad epochs 0\n",
      "2019-04-22 20:08:17,319 DEV  : loss 1.22258711 - f-score 0.2319 - acc 0.1311\n",
      "2019-04-22 20:08:19,144 TEST : loss 1.71992028 - f-score 0.2505 - acc 0.1432\n",
      "2019-04-22 20:08:19,154 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:19,271 epoch 99 - iter 0/86 - loss 0.71704704\n",
      "2019-04-22 20:08:20,355 epoch 99 - iter 8/86 - loss 1.19813022\n",
      "2019-04-22 20:08:21,374 epoch 99 - iter 16/86 - loss 1.08986936\n",
      "2019-04-22 20:08:22,424 epoch 99 - iter 24/86 - loss 1.08573233\n",
      "2019-04-22 20:08:23,443 epoch 99 - iter 32/86 - loss 1.13770582\n",
      "2019-04-22 20:08:24,437 epoch 99 - iter 40/86 - loss 1.06881857\n",
      "2019-04-22 20:08:25,519 epoch 99 - iter 48/86 - loss 1.03138356\n",
      "2019-04-22 20:08:26,584 epoch 99 - iter 56/86 - loss 1.04321909\n",
      "2019-04-22 20:08:27,617 epoch 99 - iter 64/86 - loss 1.02948496\n",
      "2019-04-22 20:08:28,621 epoch 99 - iter 72/86 - loss 1.00365692\n",
      "2019-04-22 20:08:29,680 epoch 99 - iter 80/86 - loss 0.99094922\n",
      "2019-04-22 20:08:30,372 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:30,377 EPOCH 99 done: loss 0.9872 - lr 0.0008 - bad epochs 1\n",
      "2019-04-22 20:08:31,169 DEV  : loss 1.22208607 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:08:33,238 TEST : loss 1.72028315 - f-score 0.2505 - acc 0.1432\n",
      "2019-04-22 20:08:33,250 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:33,392 epoch 100 - iter 0/86 - loss 0.55230123\n",
      "2019-04-22 20:08:34,593 epoch 100 - iter 8/86 - loss 0.98092259\n",
      "2019-04-22 20:08:35,784 epoch 100 - iter 16/86 - loss 1.08406187\n",
      "2019-04-22 20:08:36,978 epoch 100 - iter 24/86 - loss 1.05892991\n",
      "2019-04-22 20:08:38,172 epoch 100 - iter 32/86 - loss 1.06760348\n",
      "2019-04-22 20:08:39,363 epoch 100 - iter 40/86 - loss 1.02884699\n",
      "2019-04-22 20:08:40,510 epoch 100 - iter 48/86 - loss 1.00420315\n",
      "2019-04-22 20:08:41,749 epoch 100 - iter 56/86 - loss 0.97889841\n",
      "2019-04-22 20:08:42,976 epoch 100 - iter 64/86 - loss 0.96260452\n",
      "2019-04-22 20:08:44,116 epoch 100 - iter 72/86 - loss 0.95450339\n",
      "2019-04-22 20:08:45,406 epoch 100 - iter 80/86 - loss 0.98533020\n",
      "2019-04-22 20:08:46,245 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:46,247 EPOCH 100 done: loss 0.9640 - lr 0.0008 - bad epochs 2\n",
      "2019-04-22 20:08:47,102 DEV  : loss 1.22367299 - f-score 0.2319 - acc 0.1311\n",
      "2019-04-22 20:08:48,921 TEST : loss 1.71678078 - f-score 0.2595 - acc 0.1491\n",
      "2019-04-22 20:08:52,587 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:08:52,707 epoch 101 - iter 0/86 - loss 0.97943228\n",
      "2019-04-22 20:08:53,750 epoch 101 - iter 8/86 - loss 1.13817622\n",
      "2019-04-22 20:08:54,783 epoch 101 - iter 16/86 - loss 1.12933400\n",
      "2019-04-22 20:08:55,807 epoch 101 - iter 24/86 - loss 1.07270578\n",
      "2019-04-22 20:08:56,864 epoch 101 - iter 32/86 - loss 1.06853198\n",
      "2019-04-22 20:08:57,956 epoch 101 - iter 40/86 - loss 1.00375437\n",
      "2019-04-22 20:08:58,971 epoch 101 - iter 48/86 - loss 0.99676754\n",
      "2019-04-22 20:08:59,994 epoch 101 - iter 56/86 - loss 0.99945192\n",
      "2019-04-22 20:09:01,171 epoch 101 - iter 64/86 - loss 1.03188217\n",
      "2019-04-22 20:09:02,329 epoch 101 - iter 72/86 - loss 1.01834063\n",
      "2019-04-22 20:09:03,518 epoch 101 - iter 80/86 - loss 1.02861053\n",
      "2019-04-22 20:09:04,249 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:04,250 EPOCH 101 done: loss 1.0172 - lr 0.0008 - bad epochs 0\n",
      "2019-04-22 20:09:04,982 DEV  : loss 1.22485745 - f-score 0.2327 - acc 0.1317\n",
      "2019-04-22 20:09:06,792 TEST : loss 1.71442616 - f-score 0.2505 - acc 0.1432\n",
      "2019-04-22 20:09:06,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:06,912 epoch 102 - iter 0/86 - loss 0.79795128\n",
      "2019-04-22 20:09:07,945 epoch 102 - iter 8/86 - loss 1.02004223\n",
      "2019-04-22 20:09:08,937 epoch 102 - iter 16/86 - loss 1.02642127\n",
      "2019-04-22 20:09:09,982 epoch 102 - iter 24/86 - loss 1.03240474\n",
      "2019-04-22 20:09:11,008 epoch 102 - iter 32/86 - loss 1.08755043\n",
      "2019-04-22 20:09:12,059 epoch 102 - iter 40/86 - loss 1.04755835\n",
      "2019-04-22 20:09:13,054 epoch 102 - iter 48/86 - loss 1.02680794\n",
      "2019-04-22 20:09:14,102 epoch 102 - iter 56/86 - loss 1.00680558\n",
      "2019-04-22 20:09:15,158 epoch 102 - iter 64/86 - loss 1.03300742\n",
      "2019-04-22 20:09:16,202 epoch 102 - iter 72/86 - loss 1.00825497\n",
      "2019-04-22 20:09:17,213 epoch 102 - iter 80/86 - loss 1.01278773\n",
      "2019-04-22 20:09:17,930 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:17,931 EPOCH 102 done: loss 1.0047 - lr 0.0008 - bad epochs 1\n",
      "2019-04-22 20:09:18,673 DEV  : loss 1.22387862 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:09:20,474 TEST : loss 1.71352971 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:09:20,483 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:20,602 epoch 103 - iter 0/86 - loss 0.58282781\n",
      "2019-04-22 20:09:21,660 epoch 103 - iter 8/86 - loss 1.09449049\n",
      "2019-04-22 20:09:22,709 epoch 103 - iter 16/86 - loss 0.98687899\n",
      "2019-04-22 20:09:23,751 epoch 103 - iter 24/86 - loss 1.00100975\n",
      "2019-04-22 20:09:24,740 epoch 103 - iter 32/86 - loss 1.00310160\n",
      "2019-04-22 20:09:25,792 epoch 103 - iter 40/86 - loss 1.00378339\n",
      "2019-04-22 20:09:26,789 epoch 103 - iter 48/86 - loss 0.99764964\n",
      "2019-04-22 20:09:27,839 epoch 103 - iter 56/86 - loss 1.00239458\n",
      "2019-04-22 20:09:28,829 epoch 103 - iter 64/86 - loss 1.00657767\n",
      "2019-04-22 20:09:29,874 epoch 103 - iter 72/86 - loss 1.00566739\n",
      "2019-04-22 20:09:30,902 epoch 103 - iter 80/86 - loss 1.01076415\n",
      "2019-04-22 20:09:31,609 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:31,610 EPOCH 103 done: loss 1.0081 - lr 0.0008 - bad epochs 2\n",
      "2019-04-22 20:09:32,351 DEV  : loss 1.22272348 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:09:34,170 TEST : loss 1.71233010 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:09:34,180 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:34,279 epoch 104 - iter 0/86 - loss 0.71302128\n",
      "2019-04-22 20:09:35,345 epoch 104 - iter 8/86 - loss 1.11706222\n",
      "2019-04-22 20:09:36,373 epoch 104 - iter 16/86 - loss 1.05119685\n",
      "2019-04-22 20:09:37,391 epoch 104 - iter 24/86 - loss 0.99823955\n",
      "2019-04-22 20:09:38,437 epoch 104 - iter 32/86 - loss 0.98314835\n",
      "2019-04-22 20:09:39,491 epoch 104 - iter 40/86 - loss 0.99025628\n",
      "2019-04-22 20:09:40,575 epoch 104 - iter 48/86 - loss 0.98509914\n",
      "2019-04-22 20:09:41,694 epoch 104 - iter 56/86 - loss 0.97790954\n",
      "2019-04-22 20:09:42,870 epoch 104 - iter 64/86 - loss 0.97544104\n",
      "2019-04-22 20:09:44,052 epoch 104 - iter 72/86 - loss 0.95756182\n",
      "2019-04-22 20:09:45,251 epoch 104 - iter 80/86 - loss 0.97480349\n",
      "2019-04-22 20:09:46,102 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:46,104 EPOCH 104 done: loss 0.9641 - lr 0.0008 - bad epochs 3\n",
      "2019-04-22 20:09:46,841 DEV  : loss 1.22357953 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:09:48,668 TEST : loss 1.71222377 - f-score 0.2473 - acc 0.1411\n",
      "Epoch   103: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-04-22 20:09:48,678 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:09:48,786 epoch 105 - iter 0/86 - loss 1.32833457\n",
      "2019-04-22 20:09:49,818 epoch 105 - iter 8/86 - loss 1.12288544\n",
      "2019-04-22 20:09:50,860 epoch 105 - iter 16/86 - loss 1.00410676\n",
      "2019-04-22 20:09:51,998 epoch 105 - iter 24/86 - loss 0.89652755\n",
      "2019-04-22 20:09:53,137 epoch 105 - iter 32/86 - loss 0.93210456\n",
      "2019-04-22 20:09:54,347 epoch 105 - iter 40/86 - loss 0.92012823\n",
      "2019-04-22 20:09:55,548 epoch 105 - iter 48/86 - loss 0.91234269\n",
      "2019-04-22 20:09:56,735 epoch 105 - iter 56/86 - loss 0.89178461\n",
      "2019-04-22 20:09:57,933 epoch 105 - iter 64/86 - loss 0.94127717\n",
      "2019-04-22 20:09:59,164 epoch 105 - iter 72/86 - loss 0.96505451\n",
      "2019-04-22 20:10:00,373 epoch 105 - iter 80/86 - loss 0.96468710\n",
      "2019-04-22 20:10:01,224 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:01,226 EPOCH 105 done: loss 0.9746 - lr 0.0004 - bad epochs 0\n",
      "2019-04-22 20:10:01,964 DEV  : loss 1.22200620 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:10:03,772 TEST : loss 1.71282458 - f-score 0.2473 - acc 0.1411\n",
      "2019-04-22 20:10:03,781 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:03,891 epoch 106 - iter 0/86 - loss 1.18042982\n",
      "2019-04-22 20:10:04,892 epoch 106 - iter 8/86 - loss 1.04816877\n",
      "2019-04-22 20:10:05,925 epoch 106 - iter 16/86 - loss 1.05399364\n",
      "2019-04-22 20:10:06,956 epoch 106 - iter 24/86 - loss 0.99807612\n",
      "2019-04-22 20:10:08,008 epoch 106 - iter 32/86 - loss 0.98178412\n",
      "2019-04-22 20:10:09,037 epoch 106 - iter 40/86 - loss 0.96851581\n",
      "2019-04-22 20:10:10,054 epoch 106 - iter 48/86 - loss 0.99639556\n",
      "2019-04-22 20:10:11,147 epoch 106 - iter 56/86 - loss 0.98145832\n",
      "2019-04-22 20:10:12,157 epoch 106 - iter 64/86 - loss 0.99971035\n",
      "2019-04-22 20:10:13,196 epoch 106 - iter 72/86 - loss 0.99761007\n",
      "2019-04-22 20:10:14,245 epoch 106 - iter 80/86 - loss 0.98624696\n",
      "2019-04-22 20:10:14,994 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:14,995 EPOCH 106 done: loss 0.9975 - lr 0.0004 - bad epochs 1\n",
      "2019-04-22 20:10:15,728 DEV  : loss 1.22155809 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:10:17,550 TEST : loss 1.71197617 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:10:17,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:17,663 epoch 107 - iter 0/86 - loss 0.95634210\n",
      "2019-04-22 20:10:18,721 epoch 107 - iter 8/86 - loss 0.96021016\n",
      "2019-04-22 20:10:19,741 epoch 107 - iter 16/86 - loss 0.98833619\n",
      "2019-04-22 20:10:20,805 epoch 107 - iter 24/86 - loss 1.04476738\n",
      "2019-04-22 20:10:21,836 epoch 107 - iter 32/86 - loss 1.06032138\n",
      "2019-04-22 20:10:22,903 epoch 107 - iter 40/86 - loss 1.10600116\n",
      "2019-04-22 20:10:23,945 epoch 107 - iter 48/86 - loss 1.08148849\n",
      "2019-04-22 20:10:25,014 epoch 107 - iter 56/86 - loss 1.05542733\n",
      "2019-04-22 20:10:26,083 epoch 107 - iter 64/86 - loss 1.04037974\n",
      "2019-04-22 20:10:27,072 epoch 107 - iter 72/86 - loss 1.01025854\n",
      "2019-04-22 20:10:28,138 epoch 107 - iter 80/86 - loss 1.00797521\n",
      "2019-04-22 20:10:28,830 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:28,832 EPOCH 107 done: loss 0.9959 - lr 0.0004 - bad epochs 2\n",
      "2019-04-22 20:10:29,568 DEV  : loss 1.22337353 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:10:31,384 TEST : loss 1.71140647 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:10:31,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:31,500 epoch 108 - iter 0/86 - loss 1.27512097\n",
      "2019-04-22 20:10:32,522 epoch 108 - iter 8/86 - loss 0.83244344\n",
      "2019-04-22 20:10:33,577 epoch 108 - iter 16/86 - loss 0.90548727\n",
      "2019-04-22 20:10:34,597 epoch 108 - iter 24/86 - loss 1.01426647\n",
      "2019-04-22 20:10:35,645 epoch 108 - iter 32/86 - loss 1.00941277\n",
      "2019-04-22 20:10:36,691 epoch 108 - iter 40/86 - loss 1.05753352\n",
      "2019-04-22 20:10:37,694 epoch 108 - iter 48/86 - loss 1.02269369\n",
      "2019-04-22 20:10:38,753 epoch 108 - iter 56/86 - loss 1.04041715\n",
      "2019-04-22 20:10:39,737 epoch 108 - iter 64/86 - loss 0.99856189\n",
      "2019-04-22 20:10:40,800 epoch 108 - iter 72/86 - loss 1.01995833\n",
      "2019-04-22 20:10:41,812 epoch 108 - iter 80/86 - loss 1.00306817\n",
      "2019-04-22 20:10:42,532 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:42,536 EPOCH 108 done: loss 1.0058 - lr 0.0004 - bad epochs 3\n",
      "2019-04-22 20:10:43,265 DEV  : loss 1.22371519 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:10:45,077 TEST : loss 1.71054304 - f-score 0.2567 - acc 0.1473\n",
      "Epoch   107: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-04-22 20:10:45,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:45,182 epoch 109 - iter 0/86 - loss 1.29756498\n",
      "2019-04-22 20:10:46,221 epoch 109 - iter 8/86 - loss 0.99023107\n",
      "2019-04-22 20:10:47,204 epoch 109 - iter 16/86 - loss 1.02615789\n",
      "2019-04-22 20:10:48,275 epoch 109 - iter 24/86 - loss 1.01725149\n",
      "2019-04-22 20:10:49,330 epoch 109 - iter 32/86 - loss 1.05302070\n",
      "2019-04-22 20:10:50,331 epoch 109 - iter 40/86 - loss 1.00109870\n",
      "2019-04-22 20:10:51,366 epoch 109 - iter 48/86 - loss 1.01865629\n",
      "2019-04-22 20:10:52,376 epoch 109 - iter 56/86 - loss 0.99726592\n",
      "2019-04-22 20:10:53,397 epoch 109 - iter 64/86 - loss 0.96841562\n",
      "2019-04-22 20:10:54,392 epoch 109 - iter 72/86 - loss 0.95584010\n",
      "2019-04-22 20:10:55,441 epoch 109 - iter 80/86 - loss 0.96826017\n",
      "2019-04-22 20:10:56,147 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:56,149 EPOCH 109 done: loss 0.9721 - lr 0.0002 - bad epochs 0\n",
      "2019-04-22 20:10:56,883 DEV  : loss 1.22293317 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:10:58,693 TEST : loss 1.71212292 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:10:58,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:10:58,807 epoch 110 - iter 0/86 - loss 0.88569307\n",
      "2019-04-22 20:10:59,903 epoch 110 - iter 8/86 - loss 1.01076009\n",
      "2019-04-22 20:11:00,952 epoch 110 - iter 16/86 - loss 0.91617684\n",
      "2019-04-22 20:11:01,974 epoch 110 - iter 24/86 - loss 1.01672869\n",
      "2019-04-22 20:11:02,994 epoch 110 - iter 32/86 - loss 1.03664475\n",
      "2019-04-22 20:11:03,971 epoch 110 - iter 40/86 - loss 0.99041345\n",
      "2019-04-22 20:11:04,953 epoch 110 - iter 48/86 - loss 0.97686538\n",
      "2019-04-22 20:11:06,016 epoch 110 - iter 56/86 - loss 0.96275697\n",
      "2019-04-22 20:11:07,045 epoch 110 - iter 64/86 - loss 0.98619855\n",
      "2019-04-22 20:11:08,081 epoch 110 - iter 72/86 - loss 0.95924867\n",
      "2019-04-22 20:11:09,138 epoch 110 - iter 80/86 - loss 0.95594157\n",
      "2019-04-22 20:11:09,841 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:09,845 EPOCH 110 done: loss 0.9605 - lr 0.0002 - bad epochs 1\n",
      "2019-04-22 20:11:10,577 DEV  : loss 1.22215438 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:11:12,490 TEST : loss 1.71355116 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:11:16,736 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:16,866 epoch 111 - iter 0/86 - loss 1.23248434\n",
      "2019-04-22 20:11:18,179 epoch 111 - iter 8/86 - loss 0.88241435\n",
      "2019-04-22 20:11:19,351 epoch 111 - iter 16/86 - loss 1.00658531\n",
      "2019-04-22 20:11:20,533 epoch 111 - iter 24/86 - loss 0.97893956\n",
      "2019-04-22 20:11:21,723 epoch 111 - iter 32/86 - loss 0.92460125\n",
      "2019-04-22 20:11:22,776 epoch 111 - iter 40/86 - loss 0.92011340\n",
      "2019-04-22 20:11:23,894 epoch 111 - iter 48/86 - loss 0.86874002\n",
      "2019-04-22 20:11:25,038 epoch 111 - iter 56/86 - loss 0.89505233\n",
      "2019-04-22 20:11:26,167 epoch 111 - iter 64/86 - loss 0.90185504\n",
      "2019-04-22 20:11:27,196 epoch 111 - iter 72/86 - loss 0.92983980\n",
      "2019-04-22 20:11:28,237 epoch 111 - iter 80/86 - loss 0.96326262\n",
      "2019-04-22 20:11:28,933 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:28,935 EPOCH 111 done: loss 0.9548 - lr 0.0002 - bad epochs 0\n",
      "2019-04-22 20:11:29,674 DEV  : loss 1.22243607 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:11:31,491 TEST : loss 1.71356225 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:11:35,242 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:35,363 epoch 112 - iter 0/86 - loss 0.63319957\n",
      "2019-04-22 20:11:36,409 epoch 112 - iter 8/86 - loss 0.83415362\n",
      "2019-04-22 20:11:37,405 epoch 112 - iter 16/86 - loss 0.93137315\n",
      "2019-04-22 20:11:38,495 epoch 112 - iter 24/86 - loss 0.96531299\n",
      "2019-04-22 20:11:39,527 epoch 112 - iter 32/86 - loss 0.93943892\n",
      "2019-04-22 20:11:40,522 epoch 112 - iter 40/86 - loss 0.89356450\n",
      "2019-04-22 20:11:41,571 epoch 112 - iter 48/86 - loss 0.94521464\n",
      "2019-04-22 20:11:42,612 epoch 112 - iter 56/86 - loss 0.91890639\n",
      "2019-04-22 20:11:43,740 epoch 112 - iter 64/86 - loss 0.93057589\n",
      "2019-04-22 20:11:44,934 epoch 112 - iter 72/86 - loss 0.95375804\n",
      "2019-04-22 20:11:46,098 epoch 112 - iter 80/86 - loss 0.96054269\n",
      "2019-04-22 20:11:46,835 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:46,839 EPOCH 112 done: loss 0.9695 - lr 0.0002 - bad epochs 0\n",
      "2019-04-22 20:11:47,579 DEV  : loss 1.22157669 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:11:49,392 TEST : loss 1.71350944 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:11:49,402 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:11:49,525 epoch 113 - iter 0/86 - loss 0.53903282\n",
      "2019-04-22 20:11:50,539 epoch 113 - iter 8/86 - loss 0.86178418\n",
      "2019-04-22 20:11:51,577 epoch 113 - iter 16/86 - loss 0.90852582\n",
      "2019-04-22 20:11:52,630 epoch 113 - iter 24/86 - loss 0.98384678\n",
      "2019-04-22 20:11:53,654 epoch 113 - iter 32/86 - loss 1.06369416\n",
      "2019-04-22 20:11:54,670 epoch 113 - iter 40/86 - loss 1.04251741\n",
      "2019-04-22 20:11:55,720 epoch 113 - iter 48/86 - loss 1.02869371\n",
      "2019-04-22 20:11:56,742 epoch 113 - iter 56/86 - loss 1.01738493\n",
      "2019-04-22 20:11:57,741 epoch 113 - iter 64/86 - loss 1.00323152\n",
      "2019-04-22 20:11:58,807 epoch 113 - iter 72/86 - loss 0.99624266\n",
      "2019-04-22 20:11:59,772 epoch 113 - iter 80/86 - loss 0.99511083\n",
      "2019-04-22 20:12:00,533 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:00,535 EPOCH 113 done: loss 0.9938 - lr 0.0002 - bad epochs 1\n",
      "2019-04-22 20:12:01,271 DEV  : loss 1.22182071 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:12:03,078 TEST : loss 1.71224749 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:12:03,087 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:03,214 epoch 114 - iter 0/86 - loss 1.13840389\n",
      "2019-04-22 20:12:04,260 epoch 114 - iter 8/86 - loss 0.98753162\n",
      "2019-04-22 20:12:05,312 epoch 114 - iter 16/86 - loss 1.01098216\n",
      "2019-04-22 20:12:06,335 epoch 114 - iter 24/86 - loss 0.99433477\n",
      "2019-04-22 20:12:07,349 epoch 114 - iter 32/86 - loss 0.97880518\n",
      "2019-04-22 20:12:08,367 epoch 114 - iter 40/86 - loss 0.99092985\n",
      "2019-04-22 20:12:09,427 epoch 114 - iter 48/86 - loss 1.03125621\n",
      "2019-04-22 20:12:10,481 epoch 114 - iter 56/86 - loss 1.00789668\n",
      "2019-04-22 20:12:11,541 epoch 114 - iter 64/86 - loss 0.97887819\n",
      "2019-04-22 20:12:12,537 epoch 114 - iter 72/86 - loss 0.96645647\n",
      "2019-04-22 20:12:13,518 epoch 114 - iter 80/86 - loss 0.96651686\n",
      "2019-04-22 20:12:14,248 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:14,249 EPOCH 114 done: loss 0.9629 - lr 0.0002 - bad epochs 2\n",
      "2019-04-22 20:12:14,993 DEV  : loss 1.22167778 - f-score 0.2366 - acc 0.1341\n",
      "2019-04-22 20:12:16,807 TEST : loss 1.71233344 - f-score 0.2562 - acc 0.1469\n",
      "2019-04-22 20:12:16,817 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:16,925 epoch 115 - iter 0/86 - loss 1.21008694\n",
      "2019-04-22 20:12:17,923 epoch 115 - iter 8/86 - loss 0.98217324\n",
      "2019-04-22 20:12:18,910 epoch 115 - iter 16/86 - loss 0.89871848\n",
      "2019-04-22 20:12:19,913 epoch 115 - iter 24/86 - loss 0.91414135\n",
      "2019-04-22 20:12:21,004 epoch 115 - iter 32/86 - loss 0.95656579\n",
      "2019-04-22 20:12:21,997 epoch 115 - iter 40/86 - loss 0.96827954\n",
      "2019-04-22 20:12:23,002 epoch 115 - iter 48/86 - loss 0.98325673\n",
      "2019-04-22 20:12:24,058 epoch 115 - iter 56/86 - loss 0.99005556\n",
      "2019-04-22 20:12:25,156 epoch 115 - iter 64/86 - loss 0.96938210\n",
      "2019-04-22 20:12:26,181 epoch 115 - iter 72/86 - loss 0.98026870\n",
      "2019-04-22 20:12:27,238 epoch 115 - iter 80/86 - loss 0.98401565\n",
      "2019-04-22 20:12:27,995 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:27,998 EPOCH 115 done: loss 0.9792 - lr 0.0002 - bad epochs 3\n",
      "2019-04-22 20:12:28,729 DEV  : loss 1.22173154 - f-score 0.2374 - acc 0.1347\n",
      "2019-04-22 20:12:30,540 TEST : loss 1.71241581 - f-score 0.2562 - acc 0.1469\n",
      "Epoch   114: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-04-22 20:12:30,550 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:30,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:30,552 learning rate too small - quitting training!\n",
      "2019-04-22 20:12:30,553 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:41,684 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-22 20:12:41,708 Testing using best model ...\n",
      "2019-04-22 20:12:41,717 loading file resources/taggers/example-ner/best-model.pt\n",
      "2019-04-22 20:12:44,818 MICRO_AVG: acc 0.1469 - f1-score 0.2562\n",
      "2019-04-22 20:12:44,824 MACRO_AVG: acc 0.1656 - f1-score 0.21619062500000003\n",
      "2019-04-22 20:12:44,825 -          tp: 4 - fp: 132 - fn: 24 - tn: 4 - precision: 0.0294 - recall: 0.1429 - accuracy: 0.0250 - f1-score: 0.0488\n",
      "2019-04-22 20:12:44,827 Can        tp: 0 - fp: 0 - fn: 4 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,829 College    tp: 2 - fp: 5 - fn: 3 - tn: 2 - precision: 0.2857 - recall: 0.4000 - accuracy: 0.2000 - f1-score: 0.3333\n",
      "2019-04-22 20:12:44,831 Companies  tp: 1 - fp: 0 - fn: 23 - tn: 1 - precision: 1.0000 - recall: 0.0417 - accuracy: 0.0417 - f1-score: 0.0801\n",
      "2019-04-22 20:12:44,832 Degree     tp: 4 - fp: 0 - fn: 5 - tn: 4 - precision: 1.0000 - recall: 0.4444 - accuracy: 0.4444 - f1-score: 0.6153\n",
      "2019-04-22 20:12:44,834 Designation tp: 6 - fp: 3 - fn: 21 - tn: 6 - precision: 0.6667 - recall: 0.2222 - accuracy: 0.2000 - f1-score: 0.3333\n",
      "2019-04-22 20:12:44,836 Email      tp: 0 - fp: 1 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,838 L-Can      tp: 0 - fp: 0 - fn: 4 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,839 L-College  tp: 5 - fp: 5 - fn: 1 - tn: 5 - precision: 0.5000 - recall: 0.8333 - accuracy: 0.4545 - f1-score: 0.6250\n",
      "2019-04-22 20:12:44,841 L-Companies tp: 1 - fp: 0 - fn: 23 - tn: 1 - precision: 1.0000 - recall: 0.0417 - accuracy: 0.0417 - f1-score: 0.0801\n",
      "2019-04-22 20:12:44,843 L-Degree   tp: 4 - fp: 0 - fn: 5 - tn: 4 - precision: 1.0000 - recall: 0.4444 - accuracy: 0.4444 - f1-score: 0.6153\n",
      "2019-04-22 20:12:44,845 L-Designation tp: 6 - fp: 3 - fn: 22 - tn: 6 - precision: 0.6667 - recall: 0.2143 - accuracy: 0.1935 - f1-score: 0.3243\n",
      "2019-04-22 20:12:44,846 L-Email    tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,847 L-Name     tp: 8 - fp: 0 - fn: 2 - tn: 8 - precision: 1.0000 - recall: 0.8000 - accuracy: 0.8000 - f1-score: 0.8889\n",
      "2019-04-22 20:12:44,849 L-Skills   tp: 1 - fp: 2 - fn: 8 - tn: 1 - precision: 0.3333 - recall: 0.1111 - accuracy: 0.0909 - f1-score: 0.1666\n",
      "2019-04-22 20:12:44,851 L-des      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,853 L-state    tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,854 Name       tp: 8 - fp: 0 - fn: 2 - tn: 8 - precision: 1.0000 - recall: 0.8000 - accuracy: 0.8000 - f1-score: 0.8889\n",
      "2019-04-22 20:12:44,855 Skills     tp: 1 - fp: 5 - fn: 8 - tn: 1 - precision: 0.1667 - recall: 0.1111 - accuracy: 0.0714 - f1-score: 0.1333\n",
      "2019-04-22 20:12:44,857 U-Can      tp: 0 - fp: 0 - fn: 5 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,858 U-College  tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,860 U-Companies tp: 0 - fp: 1 - fn: 0 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,862 U-Degree   tp: 1 - fp: 0 - fn: 0 - tn: 1 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "2019-04-22 20:12:44,863 U-Email    tp: 1 - fp: 4 - fn: 0 - tn: 1 - precision: 0.2000 - recall: 1.0000 - accuracy: 0.2000 - f1-score: 0.3333\n",
      "2019-04-22 20:12:44,866 U-Graduation tp: 0 - fp: 7 - fn: 0 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,868 U-Links    tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,869 U-Location tp: 14 - fp: 24 - fn: 10 - tn: 14 - precision: 0.3684 - recall: 0.5833 - accuracy: 0.2917 - f1-score: 0.4516\n",
      "2019-04-22 20:12:44,872 U-Skills   tp: 0 - fp: 0 - fn: 11 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,874 U-abc      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,875 U-state    tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,876 des        tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,877 state      tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-22 20:12:44,879 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training and test with 10% data\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from typing import List\n",
    "\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "data_folder = '/content/gdrive/My Drive/NER/'\n",
    "\n",
    "\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                              train_file='train.txt',\n",
    "                                                              test_file='test.txt',\n",
    "                                                              dev_file=None).downsample(0.345)\n",
    "print(corpus)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    WordEmbeddings('glove')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)\n",
    "\n",
    "# 8. plot training curves (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves('resources/taggers/example-ner/loss.tsv')\n",
    "plotter.plot_weights('resources/taggers/example-ner/weights.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 40659
    },
    "colab_type": "code",
    "id": "ymdid54_yw-Q",
    "outputId": "5602be94-24b6-4bc8-a794-e5941b888440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-18 06:55:09,549 Reading data from /content/gdrive/My Drive/NER\n",
      "2019-04-18 06:55:09,551 Train: /content/gdrive/My Drive/NER/train.txt\n",
      "2019-04-18 06:55:09,553 Dev: None\n",
      "2019-04-18 06:55:09,555 Test: /content/gdrive/My Drive/NER/test.txt\n",
      "TaggedCorpus: 7933 train + 881 dev + 2103 test sentences\n",
      "[b'<unk>', b'O', b'B-Name', b'L-Name', b'U-Location', b'U-Email', b'B-Companies', b'L-Companies', b'B-Degree', b'I-Degree', b'L-Degree', b'B-College', b'L-College', b'-', b'U-Graduation', b'B-Skills', b'I-Skills', b'L-Skills', b'U-Links', b'B-Designation', b'I-Designation', b'L-Designation', b'U-Companies', b'B-Years', b'L-Years', b'I-College', b'U-Can', b'U-Skills', b'I-Companies', b'B-Location', b'L-Location', b'U-Degree', b'B-UNKNOWN', b'L-UNKNOWN', b'B-Rewards', b'I-Rewards', b'L-Rewards', b'I-Years', b'U-Address', b'I-Name', b'B-University', b'I-University', b'L-University', b'I-Location', b'B-Email', b'I-Email', b'L-Email', b'U-Designation', b'U-College', b'I-UNKNOWN', b'B-Graduation', b'U-abc', b'B-des', b'L-des', b'B-state', b'L-state', b'U-state', b'B-Can', b'L-Can', b'<START>', b'<STOP>']\n",
      "2019-04-18 06:55:11,406 this function is deprecated, use smart_open.open instead\n",
      "2019-04-18 06:55:13,143 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:55:13,150 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-18 06:55:13,166 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:55:13,301 epoch 1 - iter 0/248 - loss 36.68326187\n",
      "2019-04-18 06:55:16,552 epoch 1 - iter 24/248 - loss 11.32679846\n",
      "2019-04-18 06:55:19,531 epoch 1 - iter 48/248 - loss 8.73250469\n",
      "2019-04-18 06:55:22,462 epoch 1 - iter 72/248 - loss 7.36791018\n",
      "2019-04-18 06:55:25,401 epoch 1 - iter 96/248 - loss 6.66633907\n",
      "2019-04-18 06:55:28,277 epoch 1 - iter 120/248 - loss 6.08900581\n",
      "2019-04-18 06:55:31,198 epoch 1 - iter 144/248 - loss 5.73004288\n",
      "2019-04-18 06:55:34,157 epoch 1 - iter 168/248 - loss 5.48045689\n",
      "2019-04-18 06:55:37,064 epoch 1 - iter 192/248 - loss 5.30195149\n",
      "2019-04-18 06:55:40,026 epoch 1 - iter 216/248 - loss 5.12832533\n",
      "2019-04-18 06:55:42,938 epoch 1 - iter 240/248 - loss 4.94873391\n",
      "2019-04-18 06:55:44,136 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:55:44,140 EPOCH 1 done: loss 4.9174 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:55:46,810 DEV  : loss 2.85091233 - f-score 0.0054 - acc 0.0027\n",
      "2019-04-18 06:55:53,111 TEST : loss 2.52845430 - f-score 0.0000 - acc 0.0000\n",
      "2019-04-18 06:55:57,141 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:55:57,268 epoch 2 - iter 0/248 - loss 3.90202379\n",
      "2019-04-18 06:56:00,135 epoch 2 - iter 24/248 - loss 2.89732197\n",
      "2019-04-18 06:56:03,001 epoch 2 - iter 48/248 - loss 3.10435889\n",
      "2019-04-18 06:56:06,161 epoch 2 - iter 72/248 - loss 3.24054244\n",
      "2019-04-18 06:56:09,443 epoch 2 - iter 96/248 - loss 3.23649383\n",
      "2019-04-18 06:56:12,649 epoch 2 - iter 120/248 - loss 3.22222909\n",
      "2019-04-18 06:56:15,793 epoch 2 - iter 144/248 - loss 3.12635601\n",
      "2019-04-18 06:56:18,779 epoch 2 - iter 168/248 - loss 3.07529909\n",
      "2019-04-18 06:56:21,621 epoch 2 - iter 192/248 - loss 3.02599738\n",
      "2019-04-18 06:56:24,452 epoch 2 - iter 216/248 - loss 3.00772288\n",
      "2019-04-18 06:56:27,352 epoch 2 - iter 240/248 - loss 2.96050160\n",
      "2019-04-18 06:56:28,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:56:28,336 EPOCH 2 done: loss 2.9468 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:56:30,620 DEV  : loss 2.64811349 - f-score 0.1007 - acc 0.0530\n",
      "2019-04-18 06:56:36,035 TEST : loss 2.13865685 - f-score 0.0330 - acc 0.0168\n",
      "2019-04-18 06:56:39,727 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:56:39,890 epoch 3 - iter 0/248 - loss 1.92669010\n",
      "2019-04-18 06:56:42,820 epoch 3 - iter 24/248 - loss 2.78718404\n",
      "2019-04-18 06:56:45,724 epoch 3 - iter 48/248 - loss 2.54176699\n",
      "2019-04-18 06:56:48,880 epoch 3 - iter 72/248 - loss 2.56888247\n",
      "2019-04-18 06:56:51,729 epoch 3 - iter 96/248 - loss 2.59874526\n",
      "2019-04-18 06:56:54,578 epoch 3 - iter 120/248 - loss 2.58449169\n",
      "2019-04-18 06:56:57,366 epoch 3 - iter 144/248 - loss 2.57842916\n",
      "2019-04-18 06:57:00,310 epoch 3 - iter 168/248 - loss 2.58019341\n",
      "2019-04-18 06:57:03,121 epoch 3 - iter 192/248 - loss 2.55372091\n",
      "2019-04-18 06:57:05,966 epoch 3 - iter 216/248 - loss 2.54064907\n",
      "2019-04-18 06:57:08,806 epoch 3 - iter 240/248 - loss 2.55014835\n",
      "2019-04-18 06:57:09,748 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:57:09,749 EPOCH 3 done: loss 2.5383 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:57:12,042 DEV  : loss 2.29139519 - f-score 0.1417 - acc 0.0762\n",
      "2019-04-18 06:57:17,423 TEST : loss 1.96189666 - f-score 0.0888 - acc 0.0465\n",
      "2019-04-18 06:57:21,115 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:57:21,263 epoch 4 - iter 0/248 - loss 1.45238304\n",
      "2019-04-18 06:57:24,246 epoch 4 - iter 24/248 - loss 2.71380289\n",
      "2019-04-18 06:57:27,048 epoch 4 - iter 48/248 - loss 2.46897418\n",
      "2019-04-18 06:57:30,414 epoch 4 - iter 72/248 - loss 2.48751016\n",
      "2019-04-18 06:57:33,794 epoch 4 - iter 96/248 - loss 2.47910139\n",
      "2019-04-18 06:57:36,927 epoch 4 - iter 120/248 - loss 2.45465951\n",
      "2019-04-18 06:57:39,726 epoch 4 - iter 144/248 - loss 2.41669658\n",
      "2019-04-18 06:57:42,547 epoch 4 - iter 168/248 - loss 2.39976790\n",
      "2019-04-18 06:57:45,396 epoch 4 - iter 192/248 - loss 2.37505224\n",
      "2019-04-18 06:57:48,170 epoch 4 - iter 216/248 - loss 2.33721181\n",
      "2019-04-18 06:57:50,940 epoch 4 - iter 240/248 - loss 2.32618934\n",
      "2019-04-18 06:57:51,986 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:57:51,988 EPOCH 4 done: loss 2.3271 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:57:54,288 DEV  : loss 2.12836766 - f-score 0.1923 - acc 0.1063\n",
      "2019-04-18 06:57:59,692 TEST : loss 1.98077393 - f-score 0.2331 - acc 0.1319\n",
      "2019-04-18 06:58:03,352 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:58:03,483 epoch 5 - iter 0/248 - loss 2.69985056\n",
      "2019-04-18 06:58:06,276 epoch 5 - iter 24/248 - loss 2.01674816\n",
      "2019-04-18 06:58:09,117 epoch 5 - iter 48/248 - loss 2.20288521\n",
      "2019-04-18 06:58:12,307 epoch 5 - iter 72/248 - loss 2.17212722\n",
      "2019-04-18 06:58:15,171 epoch 5 - iter 96/248 - loss 2.23092557\n",
      "2019-04-18 06:58:17,943 epoch 5 - iter 120/248 - loss 2.15093459\n",
      "2019-04-18 06:58:20,818 epoch 5 - iter 144/248 - loss 2.19316540\n",
      "2019-04-18 06:58:23,566 epoch 5 - iter 168/248 - loss 2.18133020\n",
      "2019-04-18 06:58:26,345 epoch 5 - iter 192/248 - loss 2.16667127\n",
      "2019-04-18 06:58:29,184 epoch 5 - iter 216/248 - loss 2.14671042\n",
      "2019-04-18 06:58:32,092 epoch 5 - iter 240/248 - loss 2.14644597\n",
      "2019-04-18 06:58:33,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:58:33,102 EPOCH 5 done: loss 2.1560 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:58:35,386 DEV  : loss 2.05995703 - f-score 0.1430 - acc 0.0770\n",
      "2019-04-18 06:58:40,762 TEST : loss 1.74813652 - f-score 0.1369 - acc 0.0735\n",
      "2019-04-18 06:58:44,390 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:58:44,516 epoch 6 - iter 0/248 - loss 2.24307442\n",
      "2019-04-18 06:58:47,426 epoch 6 - iter 24/248 - loss 1.85483762\n",
      "2019-04-18 06:58:50,589 epoch 6 - iter 48/248 - loss 1.91052366\n",
      "2019-04-18 06:58:54,211 epoch 6 - iter 72/248 - loss 1.92055135\n",
      "2019-04-18 06:58:57,449 epoch 6 - iter 96/248 - loss 1.98258924\n",
      "2019-04-18 06:59:00,249 epoch 6 - iter 120/248 - loss 2.06422358\n",
      "2019-04-18 06:59:03,008 epoch 6 - iter 144/248 - loss 2.05100213\n",
      "2019-04-18 06:59:05,875 epoch 6 - iter 168/248 - loss 2.04811380\n",
      "2019-04-18 06:59:08,532 epoch 6 - iter 192/248 - loss 2.01980355\n",
      "2019-04-18 06:59:11,363 epoch 6 - iter 216/248 - loss 2.00319684\n",
      "2019-04-18 06:59:14,194 epoch 6 - iter 240/248 - loss 2.03442132\n",
      "2019-04-18 06:59:15,230 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:59:15,231 EPOCH 6 done: loss 2.0240 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:59:17,513 DEV  : loss 1.82624578 - f-score 0.1850 - acc 0.1019\n",
      "2019-04-18 06:59:22,915 TEST : loss 1.53981340 - f-score 0.2495 - acc 0.1425\n",
      "2019-04-18 06:59:26,590 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:59:26,743 epoch 7 - iter 0/248 - loss 1.28661871\n",
      "2019-04-18 06:59:29,615 epoch 7 - iter 24/248 - loss 1.86302955\n",
      "2019-04-18 06:59:32,408 epoch 7 - iter 48/248 - loss 1.82953883\n",
      "2019-04-18 06:59:35,357 epoch 7 - iter 72/248 - loss 1.87038902\n",
      "2019-04-18 06:59:38,383 epoch 7 - iter 96/248 - loss 1.93606013\n",
      "2019-04-18 06:59:41,246 epoch 7 - iter 120/248 - loss 1.96063937\n",
      "2019-04-18 06:59:44,132 epoch 7 - iter 144/248 - loss 1.96974873\n",
      "2019-04-18 06:59:47,091 epoch 7 - iter 168/248 - loss 1.99930007\n",
      "2019-04-18 06:59:49,764 epoch 7 - iter 192/248 - loss 1.95806115\n",
      "2019-04-18 06:59:52,616 epoch 7 - iter 216/248 - loss 1.91768413\n",
      "2019-04-18 06:59:55,421 epoch 7 - iter 240/248 - loss 1.92403763\n",
      "2019-04-18 06:59:56,486 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 06:59:56,492 EPOCH 7 done: loss 1.9265 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 06:59:58,791 DEV  : loss 1.59112716 - f-score 0.2024 - acc 0.1126\n",
      "2019-04-18 07:00:04,281 TEST : loss 1.80972409 - f-score 0.1443 - acc 0.0778\n",
      "2019-04-18 07:00:08,063 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:00:08,208 epoch 8 - iter 0/248 - loss 2.06817198\n",
      "2019-04-18 07:00:11,485 epoch 8 - iter 24/248 - loss 1.86788826\n",
      "2019-04-18 07:00:14,704 epoch 8 - iter 48/248 - loss 1.96203891\n",
      "2019-04-18 07:00:18,261 epoch 8 - iter 72/248 - loss 1.90178421\n",
      "2019-04-18 07:00:21,553 epoch 8 - iter 96/248 - loss 1.88261492\n",
      "2019-04-18 07:00:24,276 epoch 8 - iter 120/248 - loss 1.84779689\n",
      "2019-04-18 07:00:27,053 epoch 8 - iter 144/248 - loss 1.86751733\n",
      "2019-04-18 07:00:29,900 epoch 8 - iter 168/248 - loss 1.85833537\n",
      "2019-04-18 07:00:32,756 epoch 8 - iter 192/248 - loss 1.87544165\n",
      "2019-04-18 07:00:35,561 epoch 8 - iter 216/248 - loss 1.87355989\n",
      "2019-04-18 07:00:38,320 epoch 8 - iter 240/248 - loss 1.86986693\n",
      "2019-04-18 07:00:39,399 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:00:39,404 EPOCH 8 done: loss 1.8683 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:00:41,696 DEV  : loss 1.76975155 - f-score 0.2462 - acc 0.1403\n",
      "2019-04-18 07:00:47,057 TEST : loss 1.85985625 - f-score 0.1975 - acc 0.1096\n",
      "2019-04-18 07:00:50,657 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:00:50,795 epoch 9 - iter 0/248 - loss 2.53707004\n",
      "2019-04-18 07:00:53,676 epoch 9 - iter 24/248 - loss 1.80687290\n",
      "2019-04-18 07:00:57,031 epoch 9 - iter 48/248 - loss 1.89876598\n",
      "2019-04-18 07:01:00,750 epoch 9 - iter 72/248 - loss 1.90807912\n",
      "2019-04-18 07:01:04,061 epoch 9 - iter 96/248 - loss 1.93888942\n",
      "2019-04-18 07:01:06,935 epoch 9 - iter 120/248 - loss 1.93119492\n",
      "2019-04-18 07:01:09,818 epoch 9 - iter 144/248 - loss 1.89305979\n",
      "2019-04-18 07:01:12,652 epoch 9 - iter 168/248 - loss 1.89681978\n",
      "2019-04-18 07:01:15,486 epoch 9 - iter 192/248 - loss 1.85225765\n",
      "2019-04-18 07:01:18,228 epoch 9 - iter 216/248 - loss 1.82391714\n",
      "2019-04-18 07:01:21,006 epoch 9 - iter 240/248 - loss 1.80538307\n",
      "2019-04-18 07:01:22,004 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:01:22,005 EPOCH 9 done: loss 1.8046 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:01:24,284 DEV  : loss 1.67887151 - f-score 0.2055 - acc 0.1145\n",
      "2019-04-18 07:01:29,928 TEST : loss 1.49923587 - f-score 0.2839 - acc 0.1655\n",
      "2019-04-18 07:01:34,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:01:34,229 epoch 10 - iter 0/248 - loss 1.72883761\n",
      "2019-04-18 07:01:37,478 epoch 10 - iter 24/248 - loss 1.81834987\n",
      "2019-04-18 07:01:40,327 epoch 10 - iter 48/248 - loss 1.86556928\n",
      "2019-04-18 07:01:43,308 epoch 10 - iter 72/248 - loss 1.74616438\n",
      "2019-04-18 07:01:46,283 epoch 10 - iter 96/248 - loss 1.71309782\n",
      "2019-04-18 07:01:49,077 epoch 10 - iter 120/248 - loss 1.75659655\n",
      "2019-04-18 07:01:51,902 epoch 10 - iter 144/248 - loss 1.75033590\n",
      "2019-04-18 07:01:54,702 epoch 10 - iter 168/248 - loss 1.76312224\n",
      "2019-04-18 07:01:57,666 epoch 10 - iter 192/248 - loss 1.75841246\n",
      "2019-04-18 07:02:00,507 epoch 10 - iter 216/248 - loss 1.75879127\n",
      "2019-04-18 07:02:03,396 epoch 10 - iter 240/248 - loss 1.75500334\n",
      "2019-04-18 07:02:04,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:02:04,387 EPOCH 10 done: loss 1.7594 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:02:06,680 DEV  : loss 1.60799754 - f-score 0.2720 - acc 0.1574\n",
      "2019-04-18 07:02:12,094 TEST : loss 1.60654140 - f-score 0.2502 - acc 0.1430\n",
      "2019-04-18 07:02:15,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:02:15,836 epoch 11 - iter 0/248 - loss 0.87799603\n",
      "2019-04-18 07:02:18,753 epoch 11 - iter 24/248 - loss 1.69424055\n",
      "2019-04-18 07:02:21,764 epoch 11 - iter 48/248 - loss 1.80111371\n",
      "2019-04-18 07:02:24,853 epoch 11 - iter 72/248 - loss 1.68956629\n",
      "2019-04-18 07:02:27,676 epoch 11 - iter 96/248 - loss 1.69925338\n",
      "2019-04-18 07:02:30,473 epoch 11 - iter 120/248 - loss 1.71222887\n",
      "2019-04-18 07:02:33,364 epoch 11 - iter 144/248 - loss 1.71104775\n",
      "2019-04-18 07:02:36,095 epoch 11 - iter 168/248 - loss 1.67158535\n",
      "2019-04-18 07:02:38,937 epoch 11 - iter 192/248 - loss 1.69221555\n",
      "2019-04-18 07:02:41,776 epoch 11 - iter 216/248 - loss 1.70259537\n",
      "2019-04-18 07:02:44,461 epoch 11 - iter 240/248 - loss 1.70904229\n",
      "2019-04-18 07:02:45,515 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:02:45,516 EPOCH 11 done: loss 1.7260 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:02:47,797 DEV  : loss 1.45147300 - f-score 0.4964 - acc 0.3301\n",
      "2019-04-18 07:02:53,890 TEST : loss 1.35663629 - f-score 0.2166 - acc 0.1214\n",
      "2019-04-18 07:02:58,012 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:02:58,193 epoch 12 - iter 0/248 - loss 0.93511790\n",
      "2019-04-18 07:03:01,163 epoch 12 - iter 24/248 - loss 1.66545732\n",
      "2019-04-18 07:03:03,975 epoch 12 - iter 48/248 - loss 1.62248692\n",
      "2019-04-18 07:03:07,156 epoch 12 - iter 72/248 - loss 1.65994507\n",
      "2019-04-18 07:03:09,927 epoch 12 - iter 96/248 - loss 1.64798838\n",
      "2019-04-18 07:03:12,882 epoch 12 - iter 120/248 - loss 1.66151556\n",
      "2019-04-18 07:03:15,722 epoch 12 - iter 144/248 - loss 1.65823673\n",
      "2019-04-18 07:03:18,497 epoch 12 - iter 168/248 - loss 1.65157484\n",
      "2019-04-18 07:03:21,407 epoch 12 - iter 192/248 - loss 1.68500035\n",
      "2019-04-18 07:03:24,244 epoch 12 - iter 216/248 - loss 1.67813198\n",
      "2019-04-18 07:03:26,959 epoch 12 - iter 240/248 - loss 1.67922784\n",
      "2019-04-18 07:03:27,923 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:03:27,925 EPOCH 12 done: loss 1.6874 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:03:30,206 DEV  : loss 1.72603416 - f-score 0.2176 - acc 0.1221\n",
      "2019-04-18 07:03:35,621 TEST : loss 1.46886623 - f-score 0.2892 - acc 0.1690\n",
      "2019-04-18 07:03:39,253 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:03:39,388 epoch 13 - iter 0/248 - loss 1.92401981\n",
      "2019-04-18 07:03:42,302 epoch 13 - iter 24/248 - loss 1.78414936\n",
      "2019-04-18 07:03:45,108 epoch 13 - iter 48/248 - loss 1.66949961\n",
      "2019-04-18 07:03:48,147 epoch 13 - iter 72/248 - loss 1.69330546\n",
      "2019-04-18 07:03:51,070 epoch 13 - iter 96/248 - loss 1.63406955\n",
      "2019-04-18 07:03:53,889 epoch 13 - iter 120/248 - loss 1.60026893\n",
      "2019-04-18 07:03:56,638 epoch 13 - iter 144/248 - loss 1.59858205\n",
      "2019-04-18 07:03:59,423 epoch 13 - iter 168/248 - loss 1.58485182\n",
      "2019-04-18 07:04:02,270 epoch 13 - iter 192/248 - loss 1.61351200\n",
      "2019-04-18 07:04:05,228 epoch 13 - iter 216/248 - loss 1.62954111\n",
      "2019-04-18 07:04:08,026 epoch 13 - iter 240/248 - loss 1.65182013\n",
      "2019-04-18 07:04:09,124 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:04:09,128 EPOCH 13 done: loss 1.6475 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:04:11,748 DEV  : loss 1.39559865 - f-score 0.4996 - acc 0.3330\n",
      "2019-04-18 07:04:17,874 TEST : loss 1.42686415 - f-score 0.2219 - acc 0.1248\n",
      "2019-04-18 07:04:21,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:04:21,746 epoch 14 - iter 0/248 - loss 1.13852096\n",
      "2019-04-18 07:04:24,653 epoch 14 - iter 24/248 - loss 1.66140073\n",
      "2019-04-18 07:04:27,529 epoch 14 - iter 48/248 - loss 1.56763536\n",
      "2019-04-18 07:04:30,397 epoch 14 - iter 72/248 - loss 1.56745116\n",
      "2019-04-18 07:04:33,390 epoch 14 - iter 96/248 - loss 1.62451544\n",
      "2019-04-18 07:04:36,163 epoch 14 - iter 120/248 - loss 1.59824939\n",
      "2019-04-18 07:04:38,983 epoch 14 - iter 144/248 - loss 1.59152541\n",
      "2019-04-18 07:04:41,862 epoch 14 - iter 168/248 - loss 1.58075330\n",
      "2019-04-18 07:04:44,650 epoch 14 - iter 192/248 - loss 1.58494049\n",
      "2019-04-18 07:04:47,467 epoch 14 - iter 216/248 - loss 1.60741975\n",
      "2019-04-18 07:04:50,258 epoch 14 - iter 240/248 - loss 1.61148737\n",
      "2019-04-18 07:04:51,284 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:04:51,290 EPOCH 14 done: loss 1.5944 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:04:53,560 DEV  : loss 1.44718158 - f-score 0.4126 - acc 0.2599\n",
      "2019-04-18 07:04:58,941 TEST : loss 1.33590829 - f-score 0.2396 - acc 0.1361\n",
      "2019-04-18 07:05:02,595 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:05:02,732 epoch 15 - iter 0/248 - loss 1.21713257\n",
      "2019-04-18 07:05:05,638 epoch 15 - iter 24/248 - loss 1.46073109\n",
      "2019-04-18 07:05:08,601 epoch 15 - iter 48/248 - loss 1.60850187\n",
      "2019-04-18 07:05:11,764 epoch 15 - iter 72/248 - loss 1.62954061\n",
      "2019-04-18 07:05:14,602 epoch 15 - iter 96/248 - loss 1.62277588\n",
      "2019-04-18 07:05:17,352 epoch 15 - iter 120/248 - loss 1.61781444\n",
      "2019-04-18 07:05:20,194 epoch 15 - iter 144/248 - loss 1.58657206\n",
      "2019-04-18 07:05:23,246 epoch 15 - iter 168/248 - loss 1.58133845\n",
      "2019-04-18 07:05:26,468 epoch 15 - iter 192/248 - loss 1.55668057\n",
      "2019-04-18 07:05:29,234 epoch 15 - iter 216/248 - loss 1.54660264\n",
      "2019-04-18 07:05:32,319 epoch 15 - iter 240/248 - loss 1.56729549\n",
      "2019-04-18 07:05:33,498 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:05:33,500 EPOCH 15 done: loss 1.5697 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:05:36,094 DEV  : loss 1.59973323 - f-score 0.2344 - acc 0.1327\n",
      "2019-04-18 07:05:41,873 TEST : loss 1.27425969 - f-score 0.3241 - acc 0.1934\n",
      "2019-04-18 07:05:45,507 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:05:45,651 epoch 16 - iter 0/248 - loss 2.11891818\n",
      "2019-04-18 07:05:48,587 epoch 16 - iter 24/248 - loss 1.62675450\n",
      "2019-04-18 07:05:51,454 epoch 16 - iter 48/248 - loss 1.62544393\n",
      "2019-04-18 07:05:54,580 epoch 16 - iter 72/248 - loss 1.61032607\n",
      "2019-04-18 07:05:57,459 epoch 16 - iter 96/248 - loss 1.58354527\n",
      "2019-04-18 07:06:00,374 epoch 16 - iter 120/248 - loss 1.60566890\n",
      "2019-04-18 07:06:03,224 epoch 16 - iter 144/248 - loss 1.59649507\n",
      "2019-04-18 07:06:06,192 epoch 16 - iter 168/248 - loss 1.58766720\n",
      "2019-04-18 07:06:09,444 epoch 16 - iter 192/248 - loss 1.58873304\n",
      "2019-04-18 07:06:12,646 epoch 16 - iter 216/248 - loss 1.56798773\n",
      "2019-04-18 07:06:15,731 epoch 16 - iter 240/248 - loss 1.56961612\n",
      "2019-04-18 07:06:16,700 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:06:16,703 EPOCH 16 done: loss 1.5600 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:06:18,963 DEV  : loss 1.30906546 - f-score 0.5274 - acc 0.3581\n",
      "2019-04-18 07:06:24,323 TEST : loss 1.33971393 - f-score 0.2753 - acc 0.1596\n",
      "2019-04-18 07:06:27,936 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:06:28,058 epoch 17 - iter 0/248 - loss 0.86563039\n",
      "2019-04-18 07:06:30,891 epoch 17 - iter 24/248 - loss 1.47432540\n",
      "2019-04-18 07:06:33,607 epoch 17 - iter 48/248 - loss 1.48278666\n",
      "2019-04-18 07:06:36,372 epoch 17 - iter 72/248 - loss 1.49140612\n",
      "2019-04-18 07:06:39,643 epoch 17 - iter 96/248 - loss 1.59320674\n",
      "2019-04-18 07:06:42,577 epoch 17 - iter 120/248 - loss 1.56709436\n",
      "2019-04-18 07:06:45,355 epoch 17 - iter 144/248 - loss 1.52381451\n",
      "2019-04-18 07:06:48,090 epoch 17 - iter 168/248 - loss 1.51137951\n",
      "2019-04-18 07:06:51,191 epoch 17 - iter 192/248 - loss 1.51940900\n",
      "2019-04-18 07:06:54,409 epoch 17 - iter 216/248 - loss 1.52144203\n",
      "2019-04-18 07:06:57,604 epoch 17 - iter 240/248 - loss 1.52876634\n",
      "2019-04-18 07:06:58,680 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:06:58,682 EPOCH 17 done: loss 1.5260 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:07:01,069 DEV  : loss 1.48784542 - f-score 0.2570 - acc 0.1474\n",
      "2019-04-18 07:07:06,436 TEST : loss 1.41831338 - f-score 0.2805 - acc 0.1631\n",
      "2019-04-18 07:07:10,146 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:07:10,276 epoch 18 - iter 0/248 - loss 1.97573948\n",
      "2019-04-18 07:07:13,181 epoch 18 - iter 24/248 - loss 1.50308151\n",
      "2019-04-18 07:07:16,139 epoch 18 - iter 48/248 - loss 1.58565442\n",
      "2019-04-18 07:07:19,422 epoch 18 - iter 72/248 - loss 1.56492669\n",
      "2019-04-18 07:07:22,182 epoch 18 - iter 96/248 - loss 1.52777523\n",
      "2019-04-18 07:07:25,021 epoch 18 - iter 120/248 - loss 1.50790080\n",
      "2019-04-18 07:07:27,856 epoch 18 - iter 144/248 - loss 1.49065129\n",
      "2019-04-18 07:07:30,550 epoch 18 - iter 168/248 - loss 1.48523951\n",
      "2019-04-18 07:07:33,292 epoch 18 - iter 192/248 - loss 1.50273441\n",
      "2019-04-18 07:07:36,039 epoch 18 - iter 216/248 - loss 1.49927991\n",
      "2019-04-18 07:07:38,799 epoch 18 - iter 240/248 - loss 1.49472570\n",
      "2019-04-18 07:07:39,796 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:07:39,802 EPOCH 18 done: loss 1.4942 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:07:42,088 DEV  : loss 1.44140613 - f-score 0.2823 - acc 0.1643\n",
      "2019-04-18 07:07:47,449 TEST : loss 1.32149947 - f-score 0.3824 - acc 0.2364\n",
      "2019-04-18 07:07:51,038 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:07:51,171 epoch 19 - iter 0/248 - loss 1.02282774\n",
      "2019-04-18 07:07:54,076 epoch 19 - iter 24/248 - loss 1.58568649\n",
      "2019-04-18 07:07:57,024 epoch 19 - iter 48/248 - loss 1.49769942\n",
      "2019-04-18 07:07:59,866 epoch 19 - iter 72/248 - loss 1.49134865\n",
      "2019-04-18 07:08:02,914 epoch 19 - iter 96/248 - loss 1.49927869\n",
      "2019-04-18 07:08:05,726 epoch 19 - iter 120/248 - loss 1.49337931\n",
      "2019-04-18 07:08:08,516 epoch 19 - iter 144/248 - loss 1.49136324\n",
      "2019-04-18 07:08:11,546 epoch 19 - iter 168/248 - loss 1.51552413\n",
      "2019-04-18 07:08:14,733 epoch 19 - iter 192/248 - loss 1.51807730\n",
      "2019-04-18 07:08:17,860 epoch 19 - iter 216/248 - loss 1.52438469\n",
      "2019-04-18 07:08:20,848 epoch 19 - iter 240/248 - loss 1.51007742\n",
      "2019-04-18 07:08:21,862 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:08:21,866 EPOCH 19 done: loss 1.5118 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:08:24,147 DEV  : loss 1.37773240 - f-score 0.2433 - acc 0.1385\n",
      "2019-04-18 07:08:29,505 TEST : loss 1.21620095 - f-score 0.3701 - acc 0.2271\n",
      "2019-04-18 07:08:29,517 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:08:29,635 epoch 20 - iter 0/248 - loss 2.57566595\n",
      "2019-04-18 07:08:32,451 epoch 20 - iter 24/248 - loss 1.42807620\n",
      "2019-04-18 07:08:35,193 epoch 20 - iter 48/248 - loss 1.54185474\n",
      "2019-04-18 07:08:38,009 epoch 20 - iter 72/248 - loss 1.49697197\n",
      "2019-04-18 07:08:40,998 epoch 20 - iter 96/248 - loss 1.51514921\n",
      "2019-04-18 07:08:43,891 epoch 20 - iter 120/248 - loss 1.51548103\n",
      "2019-04-18 07:08:46,690 epoch 20 - iter 144/248 - loss 1.52022614\n",
      "2019-04-18 07:08:49,410 epoch 20 - iter 168/248 - loss 1.50239438\n",
      "2019-04-18 07:08:52,170 epoch 20 - iter 192/248 - loss 1.50416233\n",
      "2019-04-18 07:08:54,976 epoch 20 - iter 216/248 - loss 1.50051126\n",
      "2019-04-18 07:08:57,767 epoch 20 - iter 240/248 - loss 1.48060691\n",
      "2019-04-18 07:08:58,709 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:08:58,713 EPOCH 20 done: loss 1.4777 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:09:00,968 DEV  : loss 1.41087306 - f-score 0.2879 - acc 0.1681\n",
      "2019-04-18 07:09:06,331 TEST : loss 1.37991178 - f-score 0.3440 - acc 0.2077\n",
      "2019-04-18 07:09:09,954 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:09:10,086 epoch 21 - iter 0/248 - loss 1.16500735\n",
      "2019-04-18 07:09:12,967 epoch 21 - iter 24/248 - loss 1.35124366\n",
      "2019-04-18 07:09:15,759 epoch 21 - iter 48/248 - loss 1.55908998\n",
      "2019-04-18 07:09:18,792 epoch 21 - iter 72/248 - loss 1.45865901\n",
      "2019-04-18 07:09:21,690 epoch 21 - iter 96/248 - loss 1.47152485\n",
      "2019-04-18 07:09:24,425 epoch 21 - iter 120/248 - loss 1.49376020\n",
      "2019-04-18 07:09:27,294 epoch 21 - iter 144/248 - loss 1.51390708\n",
      "2019-04-18 07:09:30,058 epoch 21 - iter 168/248 - loss 1.51859767\n",
      "2019-04-18 07:09:33,161 epoch 21 - iter 192/248 - loss 1.50195290\n",
      "2019-04-18 07:09:36,342 epoch 21 - iter 216/248 - loss 1.50002523\n",
      "2019-04-18 07:09:39,499 epoch 21 - iter 240/248 - loss 1.47801667\n",
      "2019-04-18 07:09:40,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:09:40,621 EPOCH 21 done: loss 1.4771 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:09:42,907 DEV  : loss 1.30957353 - f-score 0.2732 - acc 0.1582\n",
      "2019-04-18 07:09:48,230 TEST : loss 1.39052582 - f-score 0.2838 - acc 0.1654\n",
      "2019-04-18 07:09:51,812 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:09:51,958 epoch 22 - iter 0/248 - loss 1.62984097\n",
      "2019-04-18 07:09:54,816 epoch 22 - iter 24/248 - loss 1.33277165\n",
      "2019-04-18 07:09:57,610 epoch 22 - iter 48/248 - loss 1.45238926\n",
      "2019-04-18 07:10:00,615 epoch 22 - iter 72/248 - loss 1.45729167\n",
      "2019-04-18 07:10:03,675 epoch 22 - iter 96/248 - loss 1.46571091\n",
      "2019-04-18 07:10:06,517 epoch 22 - iter 120/248 - loss 1.44493990\n",
      "2019-04-18 07:10:09,294 epoch 22 - iter 144/248 - loss 1.43598073\n",
      "2019-04-18 07:10:12,072 epoch 22 - iter 168/248 - loss 1.42125362\n",
      "2019-04-18 07:10:14,884 epoch 22 - iter 192/248 - loss 1.43763732\n",
      "2019-04-18 07:10:17,702 epoch 22 - iter 216/248 - loss 1.45779801\n",
      "2019-04-18 07:10:20,395 epoch 22 - iter 240/248 - loss 1.44243463\n",
      "2019-04-18 07:10:21,358 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:10:21,360 EPOCH 22 done: loss 1.4323 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:10:23,627 DEV  : loss 1.39724874 - f-score 0.2922 - acc 0.1712\n",
      "2019-04-18 07:10:29,348 TEST : loss 1.48970830 - f-score 0.3050 - acc 0.1800\n",
      "2019-04-18 07:10:33,325 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:10:33,487 epoch 23 - iter 0/248 - loss 3.84269524\n",
      "2019-04-18 07:10:36,324 epoch 23 - iter 24/248 - loss 1.49526409\n",
      "2019-04-18 07:10:39,129 epoch 23 - iter 48/248 - loss 1.46404774\n",
      "2019-04-18 07:10:42,310 epoch 23 - iter 72/248 - loss 1.46932605\n",
      "2019-04-18 07:10:45,144 epoch 23 - iter 96/248 - loss 1.42126679\n",
      "2019-04-18 07:10:47,864 epoch 23 - iter 120/248 - loss 1.43241407\n",
      "2019-04-18 07:10:50,716 epoch 23 - iter 144/248 - loss 1.46720215\n",
      "2019-04-18 07:10:53,806 epoch 23 - iter 168/248 - loss 1.46981041\n",
      "2019-04-18 07:10:57,010 epoch 23 - iter 192/248 - loss 1.48454592\n",
      "2019-04-18 07:11:00,172 epoch 23 - iter 216/248 - loss 1.44326760\n",
      "2019-04-18 07:11:03,044 epoch 23 - iter 240/248 - loss 1.41457298\n",
      "2019-04-18 07:11:04,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:11:04,069 EPOCH 23 done: loss 1.4186 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:11:06,330 DEV  : loss 1.40501702 - f-score 0.2649 - acc 0.1527\n",
      "2019-04-18 07:11:11,706 TEST : loss 1.26580381 - f-score 0.3274 - acc 0.1957\n",
      "2019-04-18 07:11:15,396 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:11:15,591 epoch 24 - iter 0/248 - loss 1.92534423\n",
      "2019-04-18 07:11:18,878 epoch 24 - iter 24/248 - loss 1.40493714\n",
      "2019-04-18 07:11:22,283 epoch 24 - iter 48/248 - loss 1.34705699\n",
      "2019-04-18 07:11:25,874 epoch 24 - iter 72/248 - loss 1.40139545\n",
      "2019-04-18 07:11:28,637 epoch 24 - iter 96/248 - loss 1.42098626\n",
      "2019-04-18 07:11:31,430 epoch 24 - iter 120/248 - loss 1.39141654\n",
      "2019-04-18 07:11:34,227 epoch 24 - iter 144/248 - loss 1.41169641\n",
      "2019-04-18 07:11:37,006 epoch 24 - iter 168/248 - loss 1.38127497\n",
      "2019-04-18 07:11:39,775 epoch 24 - iter 192/248 - loss 1.36529251\n",
      "2019-04-18 07:11:42,598 epoch 24 - iter 216/248 - loss 1.37594500\n",
      "2019-04-18 07:11:45,476 epoch 24 - iter 240/248 - loss 1.38007508\n",
      "2019-04-18 07:11:46,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:11:46,449 EPOCH 24 done: loss 1.3851 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:11:48,720 DEV  : loss 1.22910035 - f-score 0.4649 - acc 0.3029\n",
      "2019-04-18 07:11:54,066 TEST : loss 1.31916440 - f-score 0.2009 - acc 0.1117\n",
      "2019-04-18 07:11:57,696 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:11:57,854 epoch 25 - iter 0/248 - loss 1.25964928\n",
      "2019-04-18 07:12:00,719 epoch 25 - iter 24/248 - loss 1.25818513\n",
      "2019-04-18 07:12:03,529 epoch 25 - iter 48/248 - loss 1.39353642\n",
      "2019-04-18 07:12:06,461 epoch 25 - iter 72/248 - loss 1.43077304\n",
      "2019-04-18 07:12:09,424 epoch 25 - iter 96/248 - loss 1.42418316\n",
      "2019-04-18 07:12:12,316 epoch 25 - iter 120/248 - loss 1.38020758\n",
      "2019-04-18 07:12:15,475 epoch 25 - iter 144/248 - loss 1.39507940\n",
      "2019-04-18 07:12:18,564 epoch 25 - iter 168/248 - loss 1.37031076\n",
      "2019-04-18 07:12:21,766 epoch 25 - iter 192/248 - loss 1.33694097\n",
      "2019-04-18 07:12:24,631 epoch 25 - iter 216/248 - loss 1.35588147\n",
      "2019-04-18 07:12:27,460 epoch 25 - iter 240/248 - loss 1.36189784\n",
      "2019-04-18 07:12:28,502 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:12:28,505 EPOCH 25 done: loss 1.3617 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:12:30,799 DEV  : loss 1.34532881 - f-score 0.4134 - acc 0.2606\n",
      "2019-04-18 07:12:36,178 TEST : loss 1.45829225 - f-score 0.2156 - acc 0.1208\n",
      "2019-04-18 07:12:39,817 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:12:39,951 epoch 26 - iter 0/248 - loss 2.71917796\n",
      "2019-04-18 07:12:42,787 epoch 26 - iter 24/248 - loss 1.53039063\n",
      "2019-04-18 07:12:45,570 epoch 26 - iter 48/248 - loss 1.41181581\n",
      "2019-04-18 07:12:48,580 epoch 26 - iter 72/248 - loss 1.37095295\n",
      "2019-04-18 07:12:51,434 epoch 26 - iter 96/248 - loss 1.35294911\n",
      "2019-04-18 07:12:54,307 epoch 26 - iter 120/248 - loss 1.37154875\n",
      "2019-04-18 07:12:57,185 epoch 26 - iter 144/248 - loss 1.40201578\n",
      "2019-04-18 07:13:00,024 epoch 26 - iter 168/248 - loss 1.44287281\n",
      "2019-04-18 07:13:02,837 epoch 26 - iter 192/248 - loss 1.42328692\n",
      "2019-04-18 07:13:05,761 epoch 26 - iter 216/248 - loss 1.40155478\n",
      "2019-04-18 07:13:08,513 epoch 26 - iter 240/248 - loss 1.38998998\n",
      "2019-04-18 07:13:09,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:13:09,470 EPOCH 26 done: loss 1.3870 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:13:11,767 DEV  : loss 1.23912501 - f-score 0.4114 - acc 0.2589\n",
      "2019-04-18 07:13:17,183 TEST : loss 1.32697070 - f-score 0.2675 - acc 0.1544\n",
      "2019-04-18 07:13:17,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:13:17,310 epoch 27 - iter 0/248 - loss 0.77227402\n",
      "2019-04-18 07:13:20,073 epoch 27 - iter 24/248 - loss 1.49759156\n",
      "2019-04-18 07:13:22,790 epoch 27 - iter 48/248 - loss 1.36632686\n",
      "2019-04-18 07:13:25,592 epoch 27 - iter 72/248 - loss 1.31052404\n",
      "2019-04-18 07:13:28,584 epoch 27 - iter 96/248 - loss 1.34410787\n",
      "2019-04-18 07:13:31,331 epoch 27 - iter 120/248 - loss 1.35319343\n",
      "2019-04-18 07:13:34,508 epoch 27 - iter 144/248 - loss 1.36207448\n",
      "2019-04-18 07:13:37,605 epoch 27 - iter 168/248 - loss 1.34122115\n",
      "2019-04-18 07:13:40,788 epoch 27 - iter 192/248 - loss 1.36023840\n",
      "2019-04-18 07:13:43,738 epoch 27 - iter 216/248 - loss 1.36300007\n",
      "2019-04-18 07:13:46,509 epoch 27 - iter 240/248 - loss 1.35947826\n",
      "2019-04-18 07:13:47,464 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:13:47,466 EPOCH 27 done: loss 1.3623 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:13:49,725 DEV  : loss 1.38046277 - f-score 0.3777 - acc 0.2328\n",
      "2019-04-18 07:13:55,054 TEST : loss 1.20262969 - f-score 0.2895 - acc 0.1692\n",
      "2019-04-18 07:13:55,071 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:13:55,202 epoch 28 - iter 0/248 - loss 1.25540805\n",
      "2019-04-18 07:13:58,053 epoch 28 - iter 24/248 - loss 1.41371353\n",
      "2019-04-18 07:14:00,882 epoch 28 - iter 48/248 - loss 1.33189132\n",
      "2019-04-18 07:14:03,697 epoch 28 - iter 72/248 - loss 1.33930779\n",
      "2019-04-18 07:14:06,521 epoch 28 - iter 96/248 - loss 1.31531665\n",
      "2019-04-18 07:14:09,381 epoch 28 - iter 120/248 - loss 1.37416933\n",
      "2019-04-18 07:14:12,146 epoch 28 - iter 144/248 - loss 1.36399215\n",
      "2019-04-18 07:14:14,958 epoch 28 - iter 168/248 - loss 1.34926898\n",
      "2019-04-18 07:14:17,673 epoch 28 - iter 192/248 - loss 1.36062335\n",
      "2019-04-18 07:14:20,565 epoch 28 - iter 216/248 - loss 1.36856863\n",
      "2019-04-18 07:14:23,316 epoch 28 - iter 240/248 - loss 1.36574374\n",
      "2019-04-18 07:14:24,314 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:14:24,318 EPOCH 28 done: loss 1.3764 - lr 0.1000 - bad epochs 2\n",
      "2019-04-18 07:14:26,591 DEV  : loss 1.43845153 - f-score 0.2542 - acc 0.1456\n",
      "2019-04-18 07:14:31,947 TEST : loss 1.15680707 - f-score 0.3807 - acc 0.2351\n",
      "2019-04-18 07:14:31,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:14:32,086 epoch 29 - iter 0/248 - loss 2.35822344\n",
      "2019-04-18 07:14:34,822 epoch 29 - iter 24/248 - loss 1.27623863\n",
      "2019-04-18 07:14:37,620 epoch 29 - iter 48/248 - loss 1.32019510\n",
      "2019-04-18 07:14:40,610 epoch 29 - iter 72/248 - loss 1.36554034\n",
      "2019-04-18 07:14:43,466 epoch 29 - iter 96/248 - loss 1.35691690\n",
      "2019-04-18 07:14:46,276 epoch 29 - iter 120/248 - loss 1.32455159\n",
      "2019-04-18 07:14:49,029 epoch 29 - iter 144/248 - loss 1.30373841\n",
      "2019-04-18 07:14:51,771 epoch 29 - iter 168/248 - loss 1.31718597\n",
      "2019-04-18 07:14:54,850 epoch 29 - iter 192/248 - loss 1.33094538\n",
      "2019-04-18 07:14:57,989 epoch 29 - iter 216/248 - loss 1.31034580\n",
      "2019-04-18 07:15:01,128 epoch 29 - iter 240/248 - loss 1.31714755\n",
      "2019-04-18 07:15:02,286 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:15:02,292 EPOCH 29 done: loss 1.3192 - lr 0.1000 - bad epochs 3\n",
      "2019-04-18 07:15:04,589 DEV  : loss 1.43138802 - f-score 0.2646 - acc 0.1525\n",
      "2019-04-18 07:15:09,944 TEST : loss 1.20025170 - f-score 0.3391 - acc 0.2042\n",
      "2019-04-18 07:15:13,649 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:15:13,783 epoch 30 - iter 0/248 - loss 0.75749642\n",
      "2019-04-18 07:15:16,681 epoch 30 - iter 24/248 - loss 1.22061371\n",
      "2019-04-18 07:15:19,452 epoch 30 - iter 48/248 - loss 1.25868667\n",
      "2019-04-18 07:15:22,275 epoch 30 - iter 72/248 - loss 1.34580796\n",
      "2019-04-18 07:15:25,337 epoch 30 - iter 96/248 - loss 1.34479910\n",
      "2019-04-18 07:15:28,083 epoch 30 - iter 120/248 - loss 1.35335221\n",
      "2019-04-18 07:15:30,934 epoch 30 - iter 144/248 - loss 1.33259159\n",
      "2019-04-18 07:15:33,909 epoch 30 - iter 168/248 - loss 1.35004853\n",
      "2019-04-18 07:15:37,158 epoch 30 - iter 192/248 - loss 1.36335792\n",
      "2019-04-18 07:15:39,984 epoch 30 - iter 216/248 - loss 1.34702180\n",
      "2019-04-18 07:15:42,935 epoch 30 - iter 240/248 - loss 1.35232486\n",
      "2019-04-18 07:15:43,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:15:43,959 EPOCH 30 done: loss 1.3551 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:15:46,248 DEV  : loss 1.38704264 - f-score 0.4444 - acc 0.2857\n",
      "2019-04-18 07:15:51,620 TEST : loss 1.13627875 - f-score 0.3726 - acc 0.2290\n",
      "2019-04-18 07:15:51,631 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:15:51,734 epoch 31 - iter 0/248 - loss 1.77440059\n",
      "2019-04-18 07:15:54,561 epoch 31 - iter 24/248 - loss 1.22928007\n",
      "2019-04-18 07:15:57,314 epoch 31 - iter 48/248 - loss 1.30639355\n",
      "2019-04-18 07:16:00,147 epoch 31 - iter 72/248 - loss 1.29034262\n",
      "2019-04-18 07:16:03,017 epoch 31 - iter 96/248 - loss 1.29904869\n",
      "2019-04-18 07:16:05,778 epoch 31 - iter 120/248 - loss 1.33592798\n",
      "2019-04-18 07:16:08,629 epoch 31 - iter 144/248 - loss 1.31956086\n",
      "2019-04-18 07:16:11,499 epoch 31 - iter 168/248 - loss 1.33140761\n",
      "2019-04-18 07:16:14,381 epoch 31 - iter 192/248 - loss 1.30615609\n",
      "2019-04-18 07:16:17,608 epoch 31 - iter 216/248 - loss 1.32735474\n",
      "2019-04-18 07:16:20,791 epoch 31 - iter 240/248 - loss 1.32538415\n",
      "2019-04-18 07:16:21,982 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:16:21,983 EPOCH 31 done: loss 1.3288 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:16:24,368 DEV  : loss 1.42240894 - f-score 0.3487 - acc 0.2111\n",
      "2019-04-18 07:16:30,430 TEST : loss 1.13704097 - f-score 0.3611 - acc 0.2204\n",
      "2019-04-18 07:16:30,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:16:30,569 epoch 32 - iter 0/248 - loss 1.95329130\n",
      "2019-04-18 07:16:33,788 epoch 32 - iter 24/248 - loss 1.34614796\n",
      "2019-04-18 07:16:36,890 epoch 32 - iter 48/248 - loss 1.28152092\n",
      "2019-04-18 07:16:39,714 epoch 32 - iter 72/248 - loss 1.29512167\n",
      "2019-04-18 07:16:42,534 epoch 32 - iter 96/248 - loss 1.26476169\n",
      "2019-04-18 07:16:45,328 epoch 32 - iter 120/248 - loss 1.26645649\n",
      "2019-04-18 07:16:48,167 epoch 32 - iter 144/248 - loss 1.30683953\n",
      "2019-04-18 07:16:50,975 epoch 32 - iter 168/248 - loss 1.31928428\n",
      "2019-04-18 07:16:53,734 epoch 32 - iter 192/248 - loss 1.31480249\n",
      "2019-04-18 07:16:56,574 epoch 32 - iter 216/248 - loss 1.32762243\n",
      "2019-04-18 07:16:59,360 epoch 32 - iter 240/248 - loss 1.32397203\n",
      "2019-04-18 07:17:00,358 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:17:00,362 EPOCH 32 done: loss 1.3264 - lr 0.1000 - bad epochs 2\n",
      "2019-04-18 07:17:02,627 DEV  : loss 1.45323777 - f-score 0.3145 - acc 0.1867\n",
      "2019-04-18 07:17:07,999 TEST : loss 1.31231177 - f-score 0.3317 - acc 0.1988\n",
      "2019-04-18 07:17:08,011 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:17:08,128 epoch 33 - iter 0/248 - loss 1.77309370\n",
      "2019-04-18 07:17:10,919 epoch 33 - iter 24/248 - loss 1.28430392\n",
      "2019-04-18 07:17:13,721 epoch 33 - iter 48/248 - loss 1.32160225\n",
      "2019-04-18 07:17:16,481 epoch 33 - iter 72/248 - loss 1.27292798\n",
      "2019-04-18 07:17:19,321 epoch 33 - iter 96/248 - loss 1.29018108\n",
      "2019-04-18 07:17:22,212 epoch 33 - iter 120/248 - loss 1.29544257\n",
      "2019-04-18 07:17:25,066 epoch 33 - iter 144/248 - loss 1.28944033\n",
      "2019-04-18 07:17:27,838 epoch 33 - iter 168/248 - loss 1.28295603\n",
      "2019-04-18 07:17:30,614 epoch 33 - iter 192/248 - loss 1.30157360\n",
      "2019-04-18 07:17:33,371 epoch 33 - iter 216/248 - loss 1.30830385\n",
      "2019-04-18 07:17:36,575 epoch 33 - iter 240/248 - loss 1.30731606\n",
      "2019-04-18 07:17:37,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:17:37,725 EPOCH 33 done: loss 1.3115 - lr 0.1000 - bad epochs 3\n",
      "2019-04-18 07:17:40,328 DEV  : loss 1.32509387 - f-score 0.2828 - acc 0.1647\n",
      "2019-04-18 07:17:46,102 TEST : loss 1.20708954 - f-score 0.3485 - acc 0.2110\n",
      "2019-04-18 07:17:49,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:17:49,879 epoch 34 - iter 0/248 - loss 0.68293309\n",
      "2019-04-18 07:17:52,762 epoch 34 - iter 24/248 - loss 1.36546525\n",
      "2019-04-18 07:17:55,580 epoch 34 - iter 48/248 - loss 1.26162412\n",
      "2019-04-18 07:17:58,605 epoch 34 - iter 72/248 - loss 1.31746530\n",
      "2019-04-18 07:18:01,689 epoch 34 - iter 96/248 - loss 1.35970428\n",
      "2019-04-18 07:18:04,553 epoch 34 - iter 120/248 - loss 1.35793095\n",
      "2019-04-18 07:18:07,337 epoch 34 - iter 144/248 - loss 1.32697632\n",
      "2019-04-18 07:18:10,103 epoch 34 - iter 168/248 - loss 1.30388542\n",
      "2019-04-18 07:18:12,865 epoch 34 - iter 192/248 - loss 1.29283651\n",
      "2019-04-18 07:18:15,664 epoch 34 - iter 216/248 - loss 1.30298677\n",
      "2019-04-18 07:18:18,440 epoch 34 - iter 240/248 - loss 1.31096370\n",
      "2019-04-18 07:18:19,404 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:18:19,405 EPOCH 34 done: loss 1.3187 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:18:21,696 DEV  : loss 1.18723297 - f-score 0.4549 - acc 0.2944\n",
      "2019-04-18 07:18:27,085 TEST : loss 1.29580867 - f-score 0.1616 - acc 0.0879\n",
      "2019-04-18 07:18:27,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:18:27,236 epoch 35 - iter 0/248 - loss 0.97841811\n",
      "2019-04-18 07:18:30,092 epoch 35 - iter 24/248 - loss 1.24696421\n",
      "2019-04-18 07:18:32,934 epoch 35 - iter 48/248 - loss 1.27894344\n",
      "2019-04-18 07:18:35,740 epoch 35 - iter 72/248 - loss 1.26963207\n",
      "2019-04-18 07:18:38,491 epoch 35 - iter 96/248 - loss 1.32014220\n",
      "2019-04-18 07:18:41,365 epoch 35 - iter 120/248 - loss 1.28840387\n",
      "2019-04-18 07:18:44,226 epoch 35 - iter 144/248 - loss 1.26939474\n",
      "2019-04-18 07:18:46,943 epoch 35 - iter 168/248 - loss 1.25255327\n",
      "2019-04-18 07:18:49,788 epoch 35 - iter 192/248 - loss 1.24231267\n",
      "2019-04-18 07:18:52,590 epoch 35 - iter 216/248 - loss 1.25362463\n",
      "2019-04-18 07:18:55,559 epoch 35 - iter 240/248 - loss 1.25861034\n",
      "2019-04-18 07:18:56,684 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:18:56,695 EPOCH 35 done: loss 1.2641 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:18:59,291 DEV  : loss 1.18320906 - f-score 0.3195 - acc 0.1901\n",
      "2019-04-18 07:19:05,265 TEST : loss 1.28051353 - f-score 0.3171 - acc 0.1884\n",
      "2019-04-18 07:19:08,927 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:19:09,057 epoch 36 - iter 0/248 - loss 0.88215739\n",
      "2019-04-18 07:19:11,983 epoch 36 - iter 24/248 - loss 1.31528357\n",
      "2019-04-18 07:19:14,765 epoch 36 - iter 48/248 - loss 1.29909684\n",
      "2019-04-18 07:19:17,617 epoch 36 - iter 72/248 - loss 1.28424779\n",
      "2019-04-18 07:19:20,670 epoch 36 - iter 96/248 - loss 1.26195085\n",
      "2019-04-18 07:19:23,468 epoch 36 - iter 120/248 - loss 1.21333882\n",
      "2019-04-18 07:19:26,266 epoch 36 - iter 144/248 - loss 1.21547158\n",
      "2019-04-18 07:19:29,127 epoch 36 - iter 168/248 - loss 1.21791316\n",
      "2019-04-18 07:19:31,903 epoch 36 - iter 192/248 - loss 1.23285118\n",
      "2019-04-18 07:19:34,698 epoch 36 - iter 216/248 - loss 1.24742574\n",
      "2019-04-18 07:19:37,543 epoch 36 - iter 240/248 - loss 1.25840802\n",
      "2019-04-18 07:19:38,589 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:19:38,591 EPOCH 36 done: loss 1.2656 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:19:40,885 DEV  : loss 1.15022802 - f-score 0.4917 - acc 0.3260\n",
      "2019-04-18 07:19:46,251 TEST : loss 1.27548277 - f-score 0.2345 - acc 0.1328\n",
      "2019-04-18 07:19:46,264 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:19:46,409 epoch 37 - iter 0/248 - loss 1.98549592\n",
      "2019-04-18 07:19:49,209 epoch 37 - iter 24/248 - loss 1.24776321\n",
      "2019-04-18 07:19:52,080 epoch 37 - iter 48/248 - loss 1.27045520\n",
      "2019-04-18 07:19:54,892 epoch 37 - iter 72/248 - loss 1.22304439\n",
      "2019-04-18 07:19:57,698 epoch 37 - iter 96/248 - loss 1.26398154\n",
      "2019-04-18 07:20:00,469 epoch 37 - iter 120/248 - loss 1.25625100\n",
      "2019-04-18 07:20:03,441 epoch 37 - iter 144/248 - loss 1.24914559\n",
      "2019-04-18 07:20:06,217 epoch 37 - iter 168/248 - loss 1.24186611\n",
      "2019-04-18 07:20:08,947 epoch 37 - iter 192/248 - loss 1.24741586\n",
      "2019-04-18 07:20:11,716 epoch 37 - iter 216/248 - loss 1.24179001\n",
      "2019-04-18 07:20:14,512 epoch 37 - iter 240/248 - loss 1.24497827\n",
      "2019-04-18 07:20:15,686 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:20:15,688 EPOCH 37 done: loss 1.2599 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:20:18,305 DEV  : loss 1.11479843 - f-score 0.4148 - acc 0.2617\n",
      "2019-04-18 07:20:24,431 TEST : loss 1.17841589 - f-score 0.2743 - acc 0.1589\n",
      "2019-04-18 07:20:28,084 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:20:28,214 epoch 38 - iter 0/248 - loss 1.80146909\n",
      "2019-04-18 07:20:31,207 epoch 38 - iter 24/248 - loss 1.31353414\n",
      "2019-04-18 07:20:33,941 epoch 38 - iter 48/248 - loss 1.28406346\n",
      "2019-04-18 07:20:36,963 epoch 38 - iter 72/248 - loss 1.20197173\n",
      "2019-04-18 07:20:40,196 epoch 38 - iter 96/248 - loss 1.23113484\n",
      "2019-04-18 07:20:43,344 epoch 38 - iter 120/248 - loss 1.25257396\n",
      "2019-04-18 07:20:46,051 epoch 38 - iter 144/248 - loss 1.23204418\n",
      "2019-04-18 07:20:48,932 epoch 38 - iter 168/248 - loss 1.23994360\n",
      "2019-04-18 07:20:51,664 epoch 38 - iter 192/248 - loss 1.22678354\n",
      "2019-04-18 07:20:54,565 epoch 38 - iter 216/248 - loss 1.24550328\n",
      "2019-04-18 07:20:57,450 epoch 38 - iter 240/248 - loss 1.25247455\n",
      "2019-04-18 07:20:58,398 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:20:58,404 EPOCH 38 done: loss 1.2464 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:21:00,687 DEV  : loss 1.13068116 - f-score 0.5299 - acc 0.3604\n",
      "2019-04-18 07:21:06,071 TEST : loss 1.25044513 - f-score 0.2444 - acc 0.1392\n",
      "2019-04-18 07:21:09,722 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:21:09,854 epoch 39 - iter 0/248 - loss 0.60156524\n",
      "2019-04-18 07:21:12,736 epoch 39 - iter 24/248 - loss 1.10967515\n",
      "2019-04-18 07:21:15,523 epoch 39 - iter 48/248 - loss 1.18674251\n",
      "2019-04-18 07:21:18,459 epoch 39 - iter 72/248 - loss 1.20383523\n",
      "2019-04-18 07:21:21,495 epoch 39 - iter 96/248 - loss 1.17489842\n",
      "2019-04-18 07:21:24,322 epoch 39 - iter 120/248 - loss 1.20795674\n",
      "2019-04-18 07:21:27,094 epoch 39 - iter 144/248 - loss 1.20658286\n",
      "2019-04-18 07:21:29,922 epoch 39 - iter 168/248 - loss 1.19727242\n",
      "2019-04-18 07:21:32,669 epoch 39 - iter 192/248 - loss 1.19189891\n",
      "2019-04-18 07:21:35,605 epoch 39 - iter 216/248 - loss 1.19032819\n",
      "2019-04-18 07:21:38,878 epoch 39 - iter 240/248 - loss 1.21857091\n",
      "2019-04-18 07:21:40,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:21:40,091 EPOCH 39 done: loss 1.2267 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:21:42,758 DEV  : loss 1.16833818 - f-score 0.3137 - acc 0.1860\n",
      "2019-04-18 07:21:48,648 TEST : loss 1.16255414 - f-score 0.3686 - acc 0.2259\n",
      "2019-04-18 07:21:52,300 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:21:52,434 epoch 40 - iter 0/248 - loss 1.19734430\n",
      "2019-04-18 07:21:55,324 epoch 40 - iter 24/248 - loss 1.28532000\n",
      "2019-04-18 07:21:58,268 epoch 40 - iter 48/248 - loss 1.27730440\n",
      "2019-04-18 07:22:01,342 epoch 40 - iter 72/248 - loss 1.30176985\n",
      "2019-04-18 07:22:04,101 epoch 40 - iter 96/248 - loss 1.25378925\n",
      "2019-04-18 07:22:06,853 epoch 40 - iter 120/248 - loss 1.30883952\n",
      "2019-04-18 07:22:09,562 epoch 40 - iter 144/248 - loss 1.29312217\n",
      "2019-04-18 07:22:12,423 epoch 40 - iter 168/248 - loss 1.29102783\n",
      "2019-04-18 07:22:15,210 epoch 40 - iter 192/248 - loss 1.26701502\n",
      "2019-04-18 07:22:17,962 epoch 40 - iter 216/248 - loss 1.24597858\n",
      "2019-04-18 07:22:20,749 epoch 40 - iter 240/248 - loss 1.24563956\n",
      "2019-04-18 07:22:21,787 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:22:21,793 EPOCH 40 done: loss 1.2542 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:22:24,064 DEV  : loss 1.16010380 - f-score 0.3135 - acc 0.1859\n",
      "2019-04-18 07:22:29,445 TEST : loss 1.16486943 - f-score 0.3639 - acc 0.2224\n",
      "2019-04-18 07:22:29,455 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:22:29,590 epoch 41 - iter 0/248 - loss 1.54850888\n",
      "2019-04-18 07:22:32,375 epoch 41 - iter 24/248 - loss 1.24190320\n",
      "2019-04-18 07:22:35,139 epoch 41 - iter 48/248 - loss 1.26461401\n",
      "2019-04-18 07:22:37,968 epoch 41 - iter 72/248 - loss 1.36352254\n",
      "2019-04-18 07:22:40,781 epoch 41 - iter 96/248 - loss 1.33596003\n",
      "2019-04-18 07:22:43,573 epoch 41 - iter 120/248 - loss 1.30648132\n",
      "2019-04-18 07:22:46,346 epoch 41 - iter 144/248 - loss 1.27551731\n",
      "2019-04-18 07:22:49,189 epoch 41 - iter 168/248 - loss 1.26236129\n",
      "2019-04-18 07:22:51,931 epoch 41 - iter 192/248 - loss 1.24453654\n",
      "2019-04-18 07:22:54,669 epoch 41 - iter 216/248 - loss 1.23141051\n",
      "2019-04-18 07:22:57,724 epoch 41 - iter 240/248 - loss 1.22864057\n",
      "2019-04-18 07:22:58,918 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:22:58,923 EPOCH 41 done: loss 1.2435 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:23:01,531 DEV  : loss 1.38919759 - f-score 0.4018 - acc 0.2514\n",
      "2019-04-18 07:23:07,397 TEST : loss 1.48705256 - f-score 0.1479 - acc 0.0799\n",
      "2019-04-18 07:23:07,407 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:23:07,525 epoch 42 - iter 0/248 - loss 0.81647664\n",
      "2019-04-18 07:23:10,314 epoch 42 - iter 24/248 - loss 1.25968520\n",
      "2019-04-18 07:23:13,061 epoch 42 - iter 48/248 - loss 1.23777274\n",
      "2019-04-18 07:23:15,851 epoch 42 - iter 72/248 - loss 1.20595287\n",
      "2019-04-18 07:23:18,681 epoch 42 - iter 96/248 - loss 1.18979782\n",
      "2019-04-18 07:23:21,502 epoch 42 - iter 120/248 - loss 1.20465601\n",
      "2019-04-18 07:23:24,360 epoch 42 - iter 144/248 - loss 1.19233850\n",
      "2019-04-18 07:23:27,126 epoch 42 - iter 168/248 - loss 1.21219222\n",
      "2019-04-18 07:23:30,051 epoch 42 - iter 192/248 - loss 1.23802468\n",
      "2019-04-18 07:23:32,850 epoch 42 - iter 216/248 - loss 1.23945530\n",
      "2019-04-18 07:23:35,618 epoch 42 - iter 240/248 - loss 1.23275441\n",
      "2019-04-18 07:23:36,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:23:36,611 EPOCH 42 done: loss 1.2286 - lr 0.1000 - bad epochs 2\n",
      "2019-04-18 07:23:38,867 DEV  : loss 1.16111481 - f-score 0.3267 - acc 0.1952\n",
      "2019-04-18 07:23:44,236 TEST : loss 1.18213642 - f-score 0.3628 - acc 0.2216\n",
      "2019-04-18 07:23:44,248 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:23:44,367 epoch 43 - iter 0/248 - loss 0.85987461\n",
      "2019-04-18 07:23:47,138 epoch 43 - iter 24/248 - loss 1.28571345\n",
      "2019-04-18 07:23:49,958 epoch 43 - iter 48/248 - loss 1.16367530\n",
      "2019-04-18 07:23:52,686 epoch 43 - iter 72/248 - loss 1.17151723\n",
      "2019-04-18 07:23:55,510 epoch 43 - iter 96/248 - loss 1.15259993\n",
      "2019-04-18 07:23:58,329 epoch 43 - iter 120/248 - loss 1.18127566\n",
      "2019-04-18 07:24:01,183 epoch 43 - iter 144/248 - loss 1.18498468\n",
      "2019-04-18 07:24:04,002 epoch 43 - iter 168/248 - loss 1.18575944\n",
      "2019-04-18 07:24:06,874 epoch 43 - iter 192/248 - loss 1.20850948\n",
      "2019-04-18 07:24:09,720 epoch 43 - iter 216/248 - loss 1.20606657\n",
      "2019-04-18 07:24:12,513 epoch 43 - iter 240/248 - loss 1.21433540\n",
      "2019-04-18 07:24:13,518 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:24:13,523 EPOCH 43 done: loss 1.2160 - lr 0.1000 - bad epochs 3\n",
      "2019-04-18 07:24:15,784 DEV  : loss 1.35134244 - f-score 0.2540 - acc 0.1455\n",
      "2019-04-18 07:24:22,616 TEST : loss 1.12513244 - f-score 0.3026 - acc 0.1783\n",
      "2019-04-18 07:24:27,445 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:24:27,702 epoch 44 - iter 0/248 - loss 1.92450714\n",
      "2019-04-18 07:24:30,581 epoch 44 - iter 24/248 - loss 1.20719917\n",
      "2019-04-18 07:24:33,318 epoch 44 - iter 48/248 - loss 1.11862211\n",
      "2019-04-18 07:24:36,220 epoch 44 - iter 72/248 - loss 1.12944524\n",
      "2019-04-18 07:24:39,230 epoch 44 - iter 96/248 - loss 1.15419417\n",
      "2019-04-18 07:24:42,021 epoch 44 - iter 120/248 - loss 1.19848710\n",
      "2019-04-18 07:24:44,832 epoch 44 - iter 144/248 - loss 1.18032373\n",
      "2019-04-18 07:24:47,644 epoch 44 - iter 168/248 - loss 1.20627794\n",
      "2019-04-18 07:24:50,456 epoch 44 - iter 192/248 - loss 1.21664234\n",
      "2019-04-18 07:24:53,237 epoch 44 - iter 216/248 - loss 1.21662625\n",
      "2019-04-18 07:24:56,053 epoch 44 - iter 240/248 - loss 1.22048443\n",
      "2019-04-18 07:24:57,038 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:24:57,043 EPOCH 44 done: loss 1.2187 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:24:59,355 DEV  : loss 1.28390336 - f-score 0.2824 - acc 0.1644\n",
      "2019-04-18 07:25:04,733 TEST : loss 1.10852337 - f-score 0.3438 - acc 0.2076\n",
      "2019-04-18 07:25:04,743 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:25:04,854 epoch 45 - iter 0/248 - loss 1.23135376\n",
      "2019-04-18 07:25:07,692 epoch 45 - iter 24/248 - loss 1.25115872\n",
      "2019-04-18 07:25:10,490 epoch 45 - iter 48/248 - loss 1.19433865\n",
      "2019-04-18 07:25:13,248 epoch 45 - iter 72/248 - loss 1.18069485\n",
      "2019-04-18 07:25:16,119 epoch 45 - iter 96/248 - loss 1.16465741\n",
      "2019-04-18 07:25:18,965 epoch 45 - iter 120/248 - loss 1.18498641\n",
      "2019-04-18 07:25:21,792 epoch 45 - iter 144/248 - loss 1.19593313\n",
      "2019-04-18 07:25:24,684 epoch 45 - iter 168/248 - loss 1.18758000\n",
      "2019-04-18 07:25:27,508 epoch 45 - iter 192/248 - loss 1.19372723\n",
      "2019-04-18 07:25:30,292 epoch 45 - iter 216/248 - loss 1.19642738\n",
      "2019-04-18 07:25:33,120 epoch 45 - iter 240/248 - loss 1.21306417\n",
      "2019-04-18 07:25:34,106 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:25:34,110 EPOCH 45 done: loss 1.2128 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:25:36,409 DEV  : loss 1.31688571 - f-score 0.3054 - acc 0.1802\n",
      "2019-04-18 07:25:42,585 TEST : loss 1.09408605 - f-score 0.3414 - acc 0.2058\n",
      "2019-04-18 07:25:46,868 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:25:47,012 epoch 46 - iter 0/248 - loss 1.22758842\n",
      "2019-04-18 07:25:49,929 epoch 46 - iter 24/248 - loss 1.16593288\n",
      "2019-04-18 07:25:52,837 epoch 46 - iter 48/248 - loss 1.12532296\n",
      "2019-04-18 07:25:55,965 epoch 46 - iter 72/248 - loss 1.10168368\n",
      "2019-04-18 07:25:58,687 epoch 46 - iter 96/248 - loss 1.09327698\n",
      "2019-04-18 07:26:01,586 epoch 46 - iter 120/248 - loss 1.10310626\n",
      "2019-04-18 07:26:04,384 epoch 46 - iter 144/248 - loss 1.11069889\n",
      "2019-04-18 07:26:07,215 epoch 46 - iter 168/248 - loss 1.14514775\n",
      "2019-04-18 07:26:10,026 epoch 46 - iter 192/248 - loss 1.18437306\n",
      "2019-04-18 07:26:12,841 epoch 46 - iter 216/248 - loss 1.20278006\n",
      "2019-04-18 07:26:15,692 epoch 46 - iter 240/248 - loss 1.21129100\n",
      "2019-04-18 07:26:16,737 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:26:16,739 EPOCH 46 done: loss 1.2145 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:26:19,044 DEV  : loss 1.20061088 - f-score 0.4904 - acc 0.3248\n",
      "2019-04-18 07:26:24,448 TEST : loss 1.10637283 - f-score 0.2811 - acc 0.1635\n",
      "2019-04-18 07:26:24,459 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:26:24,586 epoch 47 - iter 0/248 - loss 1.10889709\n",
      "2019-04-18 07:26:27,343 epoch 47 - iter 24/248 - loss 1.05217425\n",
      "2019-04-18 07:26:30,147 epoch 47 - iter 48/248 - loss 1.15858208\n",
      "2019-04-18 07:26:32,960 epoch 47 - iter 72/248 - loss 1.13300322\n",
      "2019-04-18 07:26:35,829 epoch 47 - iter 96/248 - loss 1.13112075\n",
      "2019-04-18 07:26:38,641 epoch 47 - iter 120/248 - loss 1.13875097\n",
      "2019-04-18 07:26:41,489 epoch 47 - iter 144/248 - loss 1.18014601\n",
      "2019-04-18 07:26:44,254 epoch 47 - iter 168/248 - loss 1.14579737\n",
      "2019-04-18 07:26:47,252 epoch 47 - iter 192/248 - loss 1.16058283\n",
      "2019-04-18 07:26:50,540 epoch 47 - iter 216/248 - loss 1.16839575\n",
      "2019-04-18 07:26:53,893 epoch 47 - iter 240/248 - loss 1.19390157\n",
      "2019-04-18 07:26:54,998 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:26:55,000 EPOCH 47 done: loss 1.1922 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:26:57,648 DEV  : loss 1.19177210 - f-score 0.2809 - acc 0.1634\n",
      "2019-04-18 07:27:03,807 TEST : loss 1.11877787 - f-score 0.3384 - acc 0.2037\n",
      "2019-04-18 07:27:07,889 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:27:08,019 epoch 48 - iter 0/248 - loss 1.69047630\n",
      "2019-04-18 07:27:10,965 epoch 48 - iter 24/248 - loss 1.21189105\n",
      "2019-04-18 07:27:13,689 epoch 48 - iter 48/248 - loss 1.14194186\n",
      "2019-04-18 07:27:16,728 epoch 48 - iter 72/248 - loss 1.16354755\n",
      "2019-04-18 07:27:19,741 epoch 48 - iter 96/248 - loss 1.19265433\n",
      "2019-04-18 07:27:22,487 epoch 48 - iter 120/248 - loss 1.20471880\n",
      "2019-04-18 07:27:25,244 epoch 48 - iter 144/248 - loss 1.20610980\n",
      "2019-04-18 07:27:28,009 epoch 48 - iter 168/248 - loss 1.21175402\n",
      "2019-04-18 07:27:30,912 epoch 48 - iter 192/248 - loss 1.22258608\n",
      "2019-04-18 07:27:33,658 epoch 48 - iter 216/248 - loss 1.21438856\n",
      "2019-04-18 07:27:36,391 epoch 48 - iter 240/248 - loss 1.22514319\n",
      "2019-04-18 07:27:37,422 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:27:37,423 EPOCH 48 done: loss 1.2163 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:27:39,702 DEV  : loss 1.30147052 - f-score 0.3910 - acc 0.2430\n",
      "2019-04-18 07:27:45,081 TEST : loss 1.13454890 - f-score 0.3094 - acc 0.1831\n",
      "2019-04-18 07:27:45,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:27:45,206 epoch 49 - iter 0/248 - loss 1.08646274\n",
      "2019-04-18 07:27:48,115 epoch 49 - iter 24/248 - loss 1.13426296\n",
      "2019-04-18 07:27:50,880 epoch 49 - iter 48/248 - loss 1.12889853\n",
      "2019-04-18 07:27:53,749 epoch 49 - iter 72/248 - loss 1.13762042\n",
      "2019-04-18 07:27:56,508 epoch 49 - iter 96/248 - loss 1.12443053\n",
      "2019-04-18 07:27:59,389 epoch 49 - iter 120/248 - loss 1.15960330\n",
      "2019-04-18 07:28:02,152 epoch 49 - iter 144/248 - loss 1.18056964\n",
      "2019-04-18 07:28:05,062 epoch 49 - iter 168/248 - loss 1.18250501\n",
      "2019-04-18 07:28:07,903 epoch 49 - iter 192/248 - loss 1.18375225\n",
      "2019-04-18 07:28:10,675 epoch 49 - iter 216/248 - loss 1.18211393\n",
      "2019-04-18 07:28:13,488 epoch 49 - iter 240/248 - loss 1.17389666\n",
      "2019-04-18 07:28:14,453 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:28:14,458 EPOCH 49 done: loss 1.1785 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:28:16,732 DEV  : loss 1.17708755 - f-score 0.4800 - acc 0.3157\n",
      "2019-04-18 07:28:22,758 TEST : loss 1.21130490 - f-score 0.2487 - acc 0.1420\n",
      "2019-04-18 07:28:26,878 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:28:27,014 epoch 50 - iter 0/248 - loss 0.80814511\n",
      "2019-04-18 07:28:29,887 epoch 50 - iter 24/248 - loss 1.25593538\n",
      "2019-04-18 07:28:32,736 epoch 50 - iter 48/248 - loss 1.19205585\n",
      "2019-04-18 07:28:35,797 epoch 50 - iter 72/248 - loss 1.15592173\n",
      "2019-04-18 07:28:38,714 epoch 50 - iter 96/248 - loss 1.18483687\n",
      "2019-04-18 07:28:41,512 epoch 50 - iter 120/248 - loss 1.19505910\n",
      "2019-04-18 07:28:44,326 epoch 50 - iter 144/248 - loss 1.19029359\n",
      "2019-04-18 07:28:47,152 epoch 50 - iter 168/248 - loss 1.20652928\n",
      "2019-04-18 07:28:49,929 epoch 50 - iter 192/248 - loss 1.18390236\n",
      "2019-04-18 07:28:52,657 epoch 50 - iter 216/248 - loss 1.17315512\n",
      "2019-04-18 07:28:55,451 epoch 50 - iter 240/248 - loss 1.17966078\n",
      "2019-04-18 07:28:56,504 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:28:56,511 EPOCH 50 done: loss 1.1845 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:28:58,781 DEV  : loss 1.23181212 - f-score 0.3716 - acc 0.2282\n",
      "2019-04-18 07:29:04,169 TEST : loss 1.13565123 - f-score 0.3285 - acc 0.1965\n",
      "2019-04-18 07:29:04,180 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:29:04,314 epoch 51 - iter 0/248 - loss 0.72061008\n",
      "2019-04-18 07:29:07,146 epoch 51 - iter 24/248 - loss 1.20032680\n",
      "2019-04-18 07:29:09,989 epoch 51 - iter 48/248 - loss 1.17914534\n",
      "2019-04-18 07:29:12,766 epoch 51 - iter 72/248 - loss 1.13203892\n",
      "2019-04-18 07:29:15,641 epoch 51 - iter 96/248 - loss 1.18231127\n",
      "2019-04-18 07:29:18,497 epoch 51 - iter 120/248 - loss 1.19732009\n",
      "2019-04-18 07:29:21,355 epoch 51 - iter 144/248 - loss 1.19156639\n",
      "2019-04-18 07:29:24,085 epoch 51 - iter 168/248 - loss 1.16841438\n",
      "2019-04-18 07:29:26,916 epoch 51 - iter 192/248 - loss 1.15567086\n",
      "2019-04-18 07:29:29,637 epoch 51 - iter 216/248 - loss 1.14255247\n",
      "2019-04-18 07:29:32,409 epoch 51 - iter 240/248 - loss 1.15377667\n",
      "2019-04-18 07:29:33,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:29:33,435 EPOCH 51 done: loss 1.1585 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:29:35,698 DEV  : loss 1.18685007 - f-score 0.3668 - acc 0.2246\n",
      "2019-04-18 07:29:41,508 TEST : loss 1.29365289 - f-score 0.3616 - acc 0.2207\n",
      "2019-04-18 07:29:45,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:29:45,801 epoch 52 - iter 0/248 - loss 1.23625433\n",
      "2019-04-18 07:29:48,882 epoch 52 - iter 24/248 - loss 1.10426786\n",
      "2019-04-18 07:29:51,676 epoch 52 - iter 48/248 - loss 1.05751046\n",
      "2019-04-18 07:29:54,735 epoch 52 - iter 72/248 - loss 1.09502092\n",
      "2019-04-18 07:29:57,786 epoch 52 - iter 96/248 - loss 1.12103215\n",
      "2019-04-18 07:30:00,524 epoch 52 - iter 120/248 - loss 1.16551091\n",
      "2019-04-18 07:30:03,242 epoch 52 - iter 144/248 - loss 1.17739201\n",
      "2019-04-18 07:30:06,057 epoch 52 - iter 168/248 - loss 1.17322257\n",
      "2019-04-18 07:30:08,934 epoch 52 - iter 192/248 - loss 1.19556785\n",
      "2019-04-18 07:30:11,706 epoch 52 - iter 216/248 - loss 1.17531210\n",
      "2019-04-18 07:30:14,466 epoch 52 - iter 240/248 - loss 1.18513116\n",
      "2019-04-18 07:30:15,444 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:30:15,445 EPOCH 52 done: loss 1.1835 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:30:17,732 DEV  : loss 1.32932293 - f-score 0.2978 - acc 0.1749\n",
      "2019-04-18 07:30:23,116 TEST : loss 1.28693581 - f-score 0.3612 - acc 0.2204\n",
      "2019-04-18 07:30:23,126 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:30:23,241 epoch 53 - iter 0/248 - loss 1.32502913\n",
      "2019-04-18 07:30:26,113 epoch 53 - iter 24/248 - loss 1.06904598\n",
      "2019-04-18 07:30:28,849 epoch 53 - iter 48/248 - loss 1.06760047\n",
      "2019-04-18 07:30:31,646 epoch 53 - iter 72/248 - loss 1.10448582\n",
      "2019-04-18 07:30:34,514 epoch 53 - iter 96/248 - loss 1.11679822\n",
      "2019-04-18 07:30:37,308 epoch 53 - iter 120/248 - loss 1.16055340\n",
      "2019-04-18 07:30:40,086 epoch 53 - iter 144/248 - loss 1.16889687\n",
      "2019-04-18 07:30:42,823 epoch 53 - iter 168/248 - loss 1.15473174\n",
      "2019-04-18 07:30:45,611 epoch 53 - iter 192/248 - loss 1.15723503\n",
      "2019-04-18 07:30:48,442 epoch 53 - iter 216/248 - loss 1.16272608\n",
      "2019-04-18 07:30:51,737 epoch 53 - iter 240/248 - loss 1.16338451\n",
      "2019-04-18 07:30:52,984 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:30:52,986 EPOCH 53 done: loss 1.1627 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:30:55,297 DEV  : loss 1.16908586 - f-score 0.3529 - acc 0.2143\n",
      "2019-04-18 07:31:00,990 TEST : loss 1.17483580 - f-score 0.2894 - acc 0.1692\n",
      "2019-04-18 07:31:01,003 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:31:01,135 epoch 54 - iter 0/248 - loss 0.99665934\n",
      "2019-04-18 07:31:04,289 epoch 54 - iter 24/248 - loss 1.17586390\n",
      "2019-04-18 07:31:07,394 epoch 54 - iter 48/248 - loss 1.15370742\n",
      "2019-04-18 07:31:10,338 epoch 54 - iter 72/248 - loss 1.15100332\n",
      "2019-04-18 07:31:13,185 epoch 54 - iter 96/248 - loss 1.17588727\n",
      "2019-04-18 07:31:16,053 epoch 54 - iter 120/248 - loss 1.16143334\n",
      "2019-04-18 07:31:18,840 epoch 54 - iter 144/248 - loss 1.16318468\n",
      "2019-04-18 07:31:21,736 epoch 54 - iter 168/248 - loss 1.17969198\n",
      "2019-04-18 07:31:24,610 epoch 54 - iter 192/248 - loss 1.16711835\n",
      "2019-04-18 07:31:27,349 epoch 54 - iter 216/248 - loss 1.17001846\n",
      "2019-04-18 07:31:30,060 epoch 54 - iter 240/248 - loss 1.16516179\n",
      "2019-04-18 07:31:31,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:31:31,102 EPOCH 54 done: loss 1.1621 - lr 0.1000 - bad epochs 2\n",
      "2019-04-18 07:31:33,380 DEV  : loss 1.09914112 - f-score 0.3534 - acc 0.2147\n",
      "2019-04-18 07:31:38,778 TEST : loss 1.15799749 - f-score 0.3575 - acc 0.2177\n",
      "2019-04-18 07:31:38,789 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:31:38,908 epoch 55 - iter 0/248 - loss 0.68175411\n",
      "2019-04-18 07:31:41,708 epoch 55 - iter 24/248 - loss 1.00017660\n",
      "2019-04-18 07:31:44,433 epoch 55 - iter 48/248 - loss 1.02377064\n",
      "2019-04-18 07:31:47,227 epoch 55 - iter 72/248 - loss 1.06079622\n",
      "2019-04-18 07:31:50,044 epoch 55 - iter 96/248 - loss 1.07445730\n",
      "2019-04-18 07:31:52,937 epoch 55 - iter 120/248 - loss 1.08330907\n",
      "2019-04-18 07:31:55,814 epoch 55 - iter 144/248 - loss 1.10564314\n",
      "2019-04-18 07:31:58,780 epoch 55 - iter 168/248 - loss 1.11575926\n",
      "2019-04-18 07:32:02,094 epoch 55 - iter 192/248 - loss 1.11939894\n",
      "2019-04-18 07:32:05,273 epoch 55 - iter 216/248 - loss 1.13364399\n",
      "2019-04-18 07:32:08,471 epoch 55 - iter 240/248 - loss 1.14765501\n",
      "2019-04-18 07:32:09,441 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:32:09,444 EPOCH 55 done: loss 1.1519 - lr 0.1000 - bad epochs 3\n",
      "2019-04-18 07:32:11,723 DEV  : loss 1.13045883 - f-score 0.4985 - acc 0.3320\n",
      "2019-04-18 07:32:17,106 TEST : loss 1.33038378 - f-score 0.2139 - acc 0.1198\n",
      "2019-04-18 07:32:20,972 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:32:21,131 epoch 56 - iter 0/248 - loss 2.30385137\n",
      "2019-04-18 07:32:24,487 epoch 56 - iter 24/248 - loss 1.13899876\n",
      "2019-04-18 07:32:27,673 epoch 56 - iter 48/248 - loss 1.16485888\n",
      "2019-04-18 07:32:30,852 epoch 56 - iter 72/248 - loss 1.11141715\n",
      "2019-04-18 07:32:33,735 epoch 56 - iter 96/248 - loss 1.09654006\n",
      "2019-04-18 07:32:36,611 epoch 56 - iter 120/248 - loss 1.13696946\n",
      "2019-04-18 07:32:39,437 epoch 56 - iter 144/248 - loss 1.11064695\n",
      "2019-04-18 07:32:42,251 epoch 56 - iter 168/248 - loss 1.12625620\n",
      "2019-04-18 07:32:44,983 epoch 56 - iter 192/248 - loss 1.11535191\n",
      "2019-04-18 07:32:47,768 epoch 56 - iter 216/248 - loss 1.11101704\n",
      "2019-04-18 07:32:50,586 epoch 56 - iter 240/248 - loss 1.12353891\n",
      "2019-04-18 07:32:51,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:32:51,557 EPOCH 56 done: loss 1.1223 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:32:53,822 DEV  : loss 1.08552122 - f-score 0.5209 - acc 0.3522\n",
      "2019-04-18 07:32:59,182 TEST : loss 1.18429792 - f-score 0.2830 - acc 0.1648\n",
      "2019-04-18 07:33:02,783 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:33:02,919 epoch 57 - iter 0/248 - loss 0.61372364\n",
      "2019-04-18 07:33:05,791 epoch 57 - iter 24/248 - loss 1.10735928\n",
      "2019-04-18 07:33:08,686 epoch 57 - iter 48/248 - loss 1.10645012\n",
      "2019-04-18 07:33:11,725 epoch 57 - iter 72/248 - loss 1.14916482\n",
      "2019-04-18 07:33:14,522 epoch 57 - iter 96/248 - loss 1.12698626\n",
      "2019-04-18 07:33:17,292 epoch 57 - iter 120/248 - loss 1.14295501\n",
      "2019-04-18 07:33:20,129 epoch 57 - iter 144/248 - loss 1.15446617\n",
      "2019-04-18 07:33:22,861 epoch 57 - iter 168/248 - loss 1.14762714\n",
      "2019-04-18 07:33:25,659 epoch 57 - iter 192/248 - loss 1.12809646\n",
      "2019-04-18 07:33:28,515 epoch 57 - iter 216/248 - loss 1.14141666\n",
      "2019-04-18 07:33:31,380 epoch 57 - iter 240/248 - loss 1.14215055\n",
      "2019-04-18 07:33:32,331 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:33:32,333 EPOCH 57 done: loss 1.1451 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:33:34,610 DEV  : loss 1.28896976 - f-score 0.3734 - acc 0.2296\n",
      "2019-04-18 07:33:40,075 TEST : loss 1.10882199 - f-score 0.3180 - acc 0.1891\n",
      "2019-04-18 07:33:40,094 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:33:40,234 epoch 58 - iter 0/248 - loss 1.61407280\n",
      "2019-04-18 07:33:43,345 epoch 58 - iter 24/248 - loss 1.21536021\n",
      "2019-04-18 07:33:46,473 epoch 58 - iter 48/248 - loss 1.10933225\n",
      "2019-04-18 07:33:49,606 epoch 58 - iter 72/248 - loss 1.11032088\n",
      "2019-04-18 07:33:52,328 epoch 58 - iter 96/248 - loss 1.13496169\n",
      "2019-04-18 07:33:55,167 epoch 58 - iter 120/248 - loss 1.12057828\n",
      "2019-04-18 07:33:58,011 epoch 58 - iter 144/248 - loss 1.11116393\n",
      "2019-04-18 07:34:00,800 epoch 58 - iter 168/248 - loss 1.11654578\n",
      "2019-04-18 07:34:03,687 epoch 58 - iter 192/248 - loss 1.12236775\n",
      "2019-04-18 07:34:06,412 epoch 58 - iter 216/248 - loss 1.12197636\n",
      "2019-04-18 07:34:09,296 epoch 58 - iter 240/248 - loss 1.12759232\n",
      "2019-04-18 07:34:10,239 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:34:10,241 EPOCH 58 done: loss 1.1213 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:34:12,523 DEV  : loss 1.56943858 - f-score 0.3141 - acc 0.1863\n",
      "2019-04-18 07:34:17,898 TEST : loss 1.42640114 - f-score 0.3286 - acc 0.1966\n",
      "2019-04-18 07:34:21,531 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:34:21,657 epoch 59 - iter 0/248 - loss 1.67513871\n",
      "2019-04-18 07:34:24,453 epoch 59 - iter 24/248 - loss 1.16358394\n",
      "2019-04-18 07:34:27,345 epoch 59 - iter 48/248 - loss 1.08318211\n",
      "2019-04-18 07:34:30,354 epoch 59 - iter 72/248 - loss 1.09722381\n",
      "2019-04-18 07:34:33,195 epoch 59 - iter 96/248 - loss 1.11383306\n",
      "2019-04-18 07:34:36,029 epoch 59 - iter 120/248 - loss 1.11157113\n",
      "2019-04-18 07:34:38,895 epoch 59 - iter 144/248 - loss 1.11601897\n",
      "2019-04-18 07:34:41,666 epoch 59 - iter 168/248 - loss 1.11857683\n",
      "2019-04-18 07:34:44,414 epoch 59 - iter 192/248 - loss 1.09584934\n",
      "2019-04-18 07:34:47,243 epoch 59 - iter 216/248 - loss 1.09903154\n",
      "2019-04-18 07:34:50,068 epoch 59 - iter 240/248 - loss 1.10124269\n",
      "2019-04-18 07:34:51,073 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:34:51,079 EPOCH 59 done: loss 1.1069 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:34:53,340 DEV  : loss 1.22341311 - f-score 0.3471 - acc 0.2100\n",
      "2019-04-18 07:34:58,673 TEST : loss 1.12770092 - f-score 0.2978 - acc 0.1750\n",
      "2019-04-18 07:35:02,566 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:35:02,734 epoch 60 - iter 0/248 - loss 1.50801909\n",
      "2019-04-18 07:35:05,953 epoch 60 - iter 24/248 - loss 1.20883100\n",
      "2019-04-18 07:35:09,332 epoch 60 - iter 48/248 - loss 1.11506404\n",
      "2019-04-18 07:35:12,339 epoch 60 - iter 72/248 - loss 1.14333544\n",
      "2019-04-18 07:35:15,066 epoch 60 - iter 96/248 - loss 1.15648082\n",
      "2019-04-18 07:35:17,845 epoch 60 - iter 120/248 - loss 1.16070125\n",
      "2019-04-18 07:35:20,666 epoch 60 - iter 144/248 - loss 1.14478760\n",
      "2019-04-18 07:35:23,481 epoch 60 - iter 168/248 - loss 1.13330856\n",
      "2019-04-18 07:35:26,329 epoch 60 - iter 192/248 - loss 1.13480193\n",
      "2019-04-18 07:35:29,148 epoch 60 - iter 216/248 - loss 1.12504489\n",
      "2019-04-18 07:35:31,871 epoch 60 - iter 240/248 - loss 1.11784200\n",
      "2019-04-18 07:35:32,844 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:35:32,846 EPOCH 60 done: loss 1.1121 - lr 0.1000 - bad epochs 0\n",
      "2019-04-18 07:35:35,107 DEV  : loss 1.33716941 - f-score 0.2848 - acc 0.1661\n",
      "2019-04-18 07:35:40,506 TEST : loss 1.18661642 - f-score 0.3297 - acc 0.1974\n",
      "2019-04-18 07:35:40,517 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:35:40,632 epoch 61 - iter 0/248 - loss 0.70472884\n",
      "2019-04-18 07:35:43,453 epoch 61 - iter 24/248 - loss 1.26706790\n",
      "2019-04-18 07:35:46,295 epoch 61 - iter 48/248 - loss 1.22954894\n",
      "2019-04-18 07:35:49,053 epoch 61 - iter 72/248 - loss 1.19485362\n",
      "2019-04-18 07:35:51,842 epoch 61 - iter 96/248 - loss 1.20809637\n",
      "2019-04-18 07:35:54,793 epoch 61 - iter 120/248 - loss 1.17686048\n",
      "2019-04-18 07:35:57,989 epoch 61 - iter 144/248 - loss 1.15912440\n",
      "2019-04-18 07:36:00,858 epoch 61 - iter 168/248 - loss 1.12762950\n",
      "2019-04-18 07:36:03,687 epoch 61 - iter 192/248 - loss 1.10854686\n",
      "2019-04-18 07:36:06,504 epoch 61 - iter 216/248 - loss 1.09250465\n",
      "2019-04-18 07:36:09,236 epoch 61 - iter 240/248 - loss 1.10381140\n",
      "2019-04-18 07:36:10,187 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:36:10,189 EPOCH 61 done: loss 1.1079 - lr 0.1000 - bad epochs 1\n",
      "2019-04-18 07:36:12,471 DEV  : loss 1.09747601 - f-score 0.4678 - acc 0.3053\n",
      "2019-04-18 07:36:17,825 TEST : loss 1.07057738 - f-score 0.3352 - acc 0.2013\n",
      "2019-04-18 07:36:17,840 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:36:17,971 epoch 62 - iter 0/248 - loss 0.95152473\n",
      "2019-04-18 07:36:20,828 epoch 62 - iter 24/248 - loss 1.04729005\n",
      "2019-04-18 07:36:24,091 epoch 62 - iter 48/248 - loss 1.05957989\n",
      "2019-04-18 07:36:27,157 epoch 62 - iter 72/248 - loss 1.05201616\n",
      "2019-04-18 07:36:30,312 epoch 62 - iter 96/248 - loss 1.07402353\n",
      "2019-04-18 07:36:33,133 epoch 62 - iter 120/248 - loss 1.09744374\n",
      "2019-04-18 07:36:36,017 epoch 62 - iter 144/248 - loss 1.08505362\n",
      "2019-04-18 07:36:38,841 epoch 62 - iter 168/248 - loss 1.09250150\n",
      "2019-04-18 07:36:41,677 epoch 62 - iter 192/248 - loss 1.08832878\n",
      "2019-04-18 07:36:44,437 epoch 62 - iter 216/248 - loss 1.08613736\n",
      "2019-04-18 07:36:47,193 epoch 62 - iter 240/248 - loss 1.10458143\n",
      "2019-04-18 07:36:48,146 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:36:48,148 EPOCH 62 done: loss 1.1069 - lr 0.1000 - bad epochs 2\n",
      "2019-04-18 07:36:50,425 DEV  : loss 1.22694206 - f-score 0.4940 - acc 0.3280\n",
      "2019-04-18 07:36:55,792 TEST : loss 1.33744514 - f-score 0.2268 - acc 0.1279\n",
      "2019-04-18 07:36:55,803 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:36:55,929 epoch 63 - iter 0/248 - loss 1.20085025\n",
      "2019-04-18 07:36:58,704 epoch 63 - iter 24/248 - loss 1.11813964\n",
      "2019-04-18 07:37:01,503 epoch 63 - iter 48/248 - loss 1.13383338\n",
      "2019-04-18 07:37:04,307 epoch 63 - iter 72/248 - loss 1.12172606\n",
      "2019-04-18 07:37:07,112 epoch 63 - iter 96/248 - loss 1.10136316\n",
      "2019-04-18 07:37:10,171 epoch 63 - iter 120/248 - loss 1.11232383\n",
      "2019-04-18 07:37:13,500 epoch 63 - iter 144/248 - loss 1.12554369\n",
      "2019-04-18 07:37:16,700 epoch 63 - iter 168/248 - loss 1.12187015\n",
      "2019-04-18 07:37:19,727 epoch 63 - iter 192/248 - loss 1.11327524\n",
      "2019-04-18 07:37:22,492 epoch 63 - iter 216/248 - loss 1.11749449\n",
      "2019-04-18 07:37:25,283 epoch 63 - iter 240/248 - loss 1.12071455\n",
      "2019-04-18 07:37:26,309 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:37:26,310 EPOCH 63 done: loss 1.1134 - lr 0.1000 - bad epochs 3\n",
      "2019-04-18 07:37:28,580 DEV  : loss 1.25462747 - f-score 0.3485 - acc 0.2110\n",
      "2019-04-18 07:37:33,911 TEST : loss 1.11119592 - f-score 0.3288 - acc 0.1967\n",
      "Epoch    62: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-04-18 07:37:33,922 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:37:34,046 epoch 64 - iter 0/248 - loss 1.17720580\n",
      "2019-04-18 07:37:36,882 epoch 64 - iter 24/248 - loss 0.94647200\n",
      "2019-04-18 07:37:39,723 epoch 64 - iter 48/248 - loss 1.01003027\n",
      "2019-04-18 07:37:42,786 epoch 64 - iter 72/248 - loss 0.94388868\n",
      "2019-04-18 07:37:45,968 epoch 64 - iter 96/248 - loss 0.91988341\n",
      "2019-04-18 07:37:49,098 epoch 64 - iter 120/248 - loss 0.93915023\n",
      "2019-04-18 07:37:52,226 epoch 64 - iter 144/248 - loss 0.97208300\n",
      "2019-04-18 07:37:55,087 epoch 64 - iter 168/248 - loss 0.97778848\n",
      "2019-04-18 07:37:57,830 epoch 64 - iter 192/248 - loss 0.97907867\n",
      "2019-04-18 07:38:00,616 epoch 64 - iter 216/248 - loss 0.96924051\n",
      "2019-04-18 07:38:03,348 epoch 64 - iter 240/248 - loss 0.97316608\n",
      "2019-04-18 07:38:04,304 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:38:04,306 EPOCH 64 done: loss 0.9695 - lr 0.0500 - bad epochs 0\n",
      "2019-04-18 07:38:06,567 DEV  : loss 1.13462889 - f-score 0.3926 - acc 0.2443\n",
      "2019-04-18 07:38:11,896 TEST : loss 1.12937558 - f-score 0.2888 - acc 0.1687\n",
      "2019-04-18 07:38:15,530 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:38:15,687 epoch 65 - iter 0/248 - loss 0.56662208\n",
      "2019-04-18 07:38:18,478 epoch 65 - iter 24/248 - loss 1.03186116\n",
      "2019-04-18 07:38:21,360 epoch 65 - iter 48/248 - loss 1.04819744\n",
      "2019-04-18 07:38:24,220 epoch 65 - iter 72/248 - loss 0.99685661\n",
      "2019-04-18 07:38:27,198 epoch 65 - iter 96/248 - loss 0.97280025\n",
      "2019-04-18 07:38:29,936 epoch 65 - iter 120/248 - loss 0.95822464\n",
      "2019-04-18 07:38:32,717 epoch 65 - iter 144/248 - loss 0.96244555\n",
      "2019-04-18 07:38:35,453 epoch 65 - iter 168/248 - loss 0.95340187\n",
      "2019-04-18 07:38:38,246 epoch 65 - iter 192/248 - loss 0.95382371\n",
      "2019-04-18 07:38:41,050 epoch 65 - iter 216/248 - loss 0.96305702\n",
      "2019-04-18 07:38:43,836 epoch 65 - iter 240/248 - loss 0.97050615\n",
      "2019-04-18 07:38:44,797 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:38:44,801 EPOCH 65 done: loss 0.9646 - lr 0.0500 - bad epochs 0\n",
      "2019-04-18 07:38:47,069 DEV  : loss 1.14504755 - f-score 0.5222 - acc 0.3533\n",
      "2019-04-18 07:38:52,423 TEST : loss 1.09990704 - f-score 0.2512 - acc 0.1436\n",
      "2019-04-18 07:38:55,983 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:38:56,108 epoch 66 - iter 0/248 - loss 1.05116928\n",
      "2019-04-18 07:38:58,926 epoch 66 - iter 24/248 - loss 0.95795951\n",
      "2019-04-18 07:39:01,694 epoch 66 - iter 48/248 - loss 0.96204067\n",
      "2019-04-18 07:39:05,079 epoch 66 - iter 72/248 - loss 0.94983866\n",
      "2019-04-18 07:39:08,507 epoch 66 - iter 96/248 - loss 0.96811015\n",
      "2019-04-18 07:39:11,670 epoch 66 - iter 120/248 - loss 0.98933904\n",
      "2019-04-18 07:39:14,417 epoch 66 - iter 144/248 - loss 0.99562251\n",
      "2019-04-18 07:39:17,165 epoch 66 - iter 168/248 - loss 0.97723562\n",
      "2019-04-18 07:39:19,939 epoch 66 - iter 192/248 - loss 0.96531892\n",
      "2019-04-18 07:39:22,721 epoch 66 - iter 216/248 - loss 0.96120275\n",
      "2019-04-18 07:39:25,574 epoch 66 - iter 240/248 - loss 0.97251191\n",
      "2019-04-18 07:39:26,556 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:39:26,561 EPOCH 66 done: loss 0.9718 - lr 0.0500 - bad epochs 0\n",
      "2019-04-18 07:39:28,827 DEV  : loss 1.16446340 - f-score 0.4995 - acc 0.3330\n",
      "2019-04-18 07:39:34,177 TEST : loss 1.10064995 - f-score 0.2930 - acc 0.1717\n",
      "2019-04-18 07:39:34,188 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:39:34,301 epoch 67 - iter 0/248 - loss 0.70363414\n",
      "2019-04-18 07:39:37,146 epoch 67 - iter 24/248 - loss 0.97400772\n",
      "2019-04-18 07:39:39,897 epoch 67 - iter 48/248 - loss 0.89820383\n",
      "2019-04-18 07:39:42,669 epoch 67 - iter 72/248 - loss 0.86975032\n",
      "2019-04-18 07:39:45,464 epoch 67 - iter 96/248 - loss 0.89763279\n",
      "2019-04-18 07:39:48,324 epoch 67 - iter 120/248 - loss 0.92522812\n",
      "2019-04-18 07:39:51,027 epoch 67 - iter 144/248 - loss 0.91992168\n",
      "2019-04-18 07:39:53,771 epoch 67 - iter 168/248 - loss 0.90258328\n",
      "2019-04-18 07:39:56,460 epoch 67 - iter 192/248 - loss 0.91955232\n",
      "2019-04-18 07:39:59,195 epoch 67 - iter 216/248 - loss 0.92725186\n",
      "2019-04-18 07:40:01,996 epoch 67 - iter 240/248 - loss 0.94141008\n",
      "2019-04-18 07:40:03,021 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:40:03,023 EPOCH 67 done: loss 0.9470 - lr 0.0500 - bad epochs 1\n",
      "2019-04-18 07:40:05,296 DEV  : loss 1.06953728 - f-score 0.3094 - acc 0.1830\n",
      "2019-04-18 07:40:10,658 TEST : loss 1.14185417 - f-score 0.3428 - acc 0.2068\n",
      "2019-04-18 07:40:14,445 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:40:14,575 epoch 68 - iter 0/248 - loss 0.73413622\n",
      "2019-04-18 07:40:17,397 epoch 68 - iter 24/248 - loss 0.87410493\n",
      "2019-04-18 07:40:20,190 epoch 68 - iter 48/248 - loss 0.86393203\n",
      "2019-04-18 07:40:23,131 epoch 68 - iter 72/248 - loss 0.89019587\n",
      "2019-04-18 07:40:26,697 epoch 68 - iter 96/248 - loss 0.93634374\n",
      "2019-04-18 07:40:29,849 epoch 68 - iter 120/248 - loss 0.93101055\n",
      "2019-04-18 07:40:32,785 epoch 68 - iter 144/248 - loss 0.93631257\n",
      "2019-04-18 07:40:35,564 epoch 68 - iter 168/248 - loss 0.94319014\n",
      "2019-04-18 07:40:38,466 epoch 68 - iter 192/248 - loss 0.95709773\n",
      "2019-04-18 07:40:41,189 epoch 68 - iter 216/248 - loss 0.94820105\n",
      "2019-04-18 07:40:43,913 epoch 68 - iter 240/248 - loss 0.95204039\n",
      "2019-04-18 07:40:44,902 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:40:44,906 EPOCH 68 done: loss 0.9515 - lr 0.0500 - bad epochs 0\n",
      "2019-04-18 07:40:47,186 DEV  : loss 1.04315889 - f-score 0.3328 - acc 0.1996\n",
      "2019-04-18 07:40:52,555 TEST : loss 1.17917323 - f-score 0.3153 - acc 0.1872\n",
      "2019-04-18 07:40:52,566 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:40:52,682 epoch 69 - iter 0/248 - loss 0.95277280\n",
      "2019-04-18 07:40:55,499 epoch 69 - iter 24/248 - loss 0.94584245\n",
      "2019-04-18 07:40:58,347 epoch 69 - iter 48/248 - loss 0.91722235\n",
      "2019-04-18 07:41:01,644 epoch 69 - iter 72/248 - loss 0.91041506\n",
      "2019-04-18 07:41:04,679 epoch 69 - iter 96/248 - loss 0.92675386\n",
      "2019-04-18 07:41:07,416 epoch 69 - iter 120/248 - loss 0.93083800\n",
      "2019-04-18 07:41:10,120 epoch 69 - iter 144/248 - loss 0.92108171\n",
      "2019-04-18 07:41:12,863 epoch 69 - iter 168/248 - loss 0.91496366\n",
      "2019-04-18 07:41:15,651 epoch 69 - iter 192/248 - loss 0.92535118\n",
      "2019-04-18 07:41:18,467 epoch 69 - iter 216/248 - loss 0.93060957\n",
      "2019-04-18 07:41:21,253 epoch 69 - iter 240/248 - loss 0.92546476\n",
      "2019-04-18 07:41:22,251 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:41:22,256 EPOCH 69 done: loss 0.9231 - lr 0.0500 - bad epochs 1\n",
      "2019-04-18 07:41:24,506 DEV  : loss 1.04143703 - f-score 0.4305 - acc 0.2743\n",
      "2019-04-18 07:41:29,830 TEST : loss 1.17974627 - f-score 0.2888 - acc 0.1688\n",
      "2019-04-18 07:41:33,448 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:41:33,567 epoch 70 - iter 0/248 - loss 0.33447111\n",
      "2019-04-18 07:41:36,397 epoch 70 - iter 24/248 - loss 0.87393112\n",
      "2019-04-18 07:41:39,241 epoch 70 - iter 48/248 - loss 0.90310781\n",
      "2019-04-18 07:41:42,312 epoch 70 - iter 72/248 - loss 0.93360504\n",
      "2019-04-18 07:41:45,578 epoch 70 - iter 96/248 - loss 0.93700788\n",
      "2019-04-18 07:41:48,851 epoch 70 - iter 120/248 - loss 0.91655282\n",
      "2019-04-18 07:41:51,975 epoch 70 - iter 144/248 - loss 0.90836997\n",
      "2019-04-18 07:41:54,804 epoch 70 - iter 168/248 - loss 0.91134777\n",
      "2019-04-18 07:41:57,538 epoch 70 - iter 192/248 - loss 0.91613806\n",
      "2019-04-18 07:42:00,325 epoch 70 - iter 216/248 - loss 0.92359699\n",
      "2019-04-18 07:42:03,083 epoch 70 - iter 240/248 - loss 0.92158732\n",
      "2019-04-18 07:42:04,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:42:04,089 EPOCH 70 done: loss 0.9249 - lr 0.0500 - bad epochs 0\n",
      "2019-04-18 07:42:06,359 DEV  : loss 1.07771945 - f-score 0.3153 - acc 0.1871\n",
      "2019-04-18 07:42:11,712 TEST : loss 1.16649044 - f-score 0.3491 - acc 0.2114\n",
      "2019-04-18 07:42:11,722 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:42:11,833 epoch 71 - iter 0/248 - loss 0.86584324\n",
      "2019-04-18 07:42:14,632 epoch 71 - iter 24/248 - loss 0.94769529\n",
      "2019-04-18 07:42:17,458 epoch 71 - iter 48/248 - loss 0.95638921\n",
      "2019-04-18 07:42:20,616 epoch 71 - iter 72/248 - loss 0.94914939\n",
      "2019-04-18 07:42:23,865 epoch 71 - iter 96/248 - loss 0.95611286\n",
      "2019-04-18 07:42:27,237 epoch 71 - iter 120/248 - loss 0.95831229\n",
      "2019-04-18 07:42:30,213 epoch 71 - iter 144/248 - loss 0.94502031\n",
      "2019-04-18 07:42:32,923 epoch 71 - iter 168/248 - loss 0.92719155\n",
      "2019-04-18 07:42:35,678 epoch 71 - iter 192/248 - loss 0.91344679\n",
      "2019-04-18 07:42:38,463 epoch 71 - iter 216/248 - loss 0.91791791\n",
      "2019-04-18 07:42:41,254 epoch 71 - iter 240/248 - loss 0.91743556\n",
      "2019-04-18 07:42:42,225 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:42:42,229 EPOCH 71 done: loss 0.9237 - lr 0.0500 - bad epochs 1\n",
      "2019-04-18 07:42:44,485 DEV  : loss 1.04268289 - f-score 0.4065 - acc 0.2551\n",
      "2019-04-18 07:42:49,828 TEST : loss 1.25861180 - f-score 0.2964 - acc 0.1740\n",
      "2019-04-18 07:42:49,839 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:42:49,964 epoch 72 - iter 0/248 - loss 0.88646245\n",
      "2019-04-18 07:42:52,713 epoch 72 - iter 24/248 - loss 0.89208677\n",
      "2019-04-18 07:42:55,399 epoch 72 - iter 48/248 - loss 0.89798257\n",
      "2019-04-18 07:42:58,235 epoch 72 - iter 72/248 - loss 0.93501644\n",
      "2019-04-18 07:43:01,028 epoch 72 - iter 96/248 - loss 0.92525503\n",
      "2019-04-18 07:43:03,931 epoch 72 - iter 120/248 - loss 0.92549735\n",
      "2019-04-18 07:43:07,049 epoch 72 - iter 144/248 - loss 0.92123960\n",
      "2019-04-18 07:43:10,215 epoch 72 - iter 168/248 - loss 0.91927954\n",
      "2019-04-18 07:43:13,390 epoch 72 - iter 192/248 - loss 0.93147182\n",
      "2019-04-18 07:43:16,159 epoch 72 - iter 216/248 - loss 0.93712926\n",
      "2019-04-18 07:43:18,982 epoch 72 - iter 240/248 - loss 0.94509565\n",
      "2019-04-18 07:43:19,997 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:43:20,003 EPOCH 72 done: loss 0.9480 - lr 0.0500 - bad epochs 2\n",
      "2019-04-18 07:43:22,296 DEV  : loss 1.05148757 - f-score 0.4950 - acc 0.3289\n",
      "2019-04-18 07:43:27,656 TEST : loss 1.16311336 - f-score 0.2529 - acc 0.1447\n",
      "2019-04-18 07:43:27,666 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:43:27,773 epoch 73 - iter 0/248 - loss 1.02210045\n",
      "2019-04-18 07:43:30,553 epoch 73 - iter 24/248 - loss 0.96217393\n",
      "2019-04-18 07:43:33,299 epoch 73 - iter 48/248 - loss 0.90883287\n",
      "2019-04-18 07:43:36,109 epoch 73 - iter 72/248 - loss 0.90251597\n",
      "2019-04-18 07:43:38,984 epoch 73 - iter 96/248 - loss 0.92336902\n",
      "2019-04-18 07:43:41,761 epoch 73 - iter 120/248 - loss 0.91240613\n",
      "2019-04-18 07:43:44,537 epoch 73 - iter 144/248 - loss 0.89835391\n",
      "2019-04-18 07:43:47,329 epoch 73 - iter 168/248 - loss 0.91645919\n",
      "2019-04-18 07:43:50,093 epoch 73 - iter 192/248 - loss 0.91943444\n",
      "2019-04-18 07:43:52,898 epoch 73 - iter 216/248 - loss 0.93332473\n",
      "2019-04-18 07:43:55,672 epoch 73 - iter 240/248 - loss 0.92519226\n",
      "2019-04-18 07:43:56,620 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:43:56,622 EPOCH 73 done: loss 0.9240 - lr 0.0500 - bad epochs 3\n",
      "2019-04-18 07:43:58,878 DEV  : loss 1.10281050 - f-score 0.3036 - acc 0.1789\n",
      "2019-04-18 07:44:04,230 TEST : loss 1.09186113 - f-score 0.4037 - acc 0.2528\n",
      "Epoch    72: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-04-18 07:44:04,241 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:44:04,354 epoch 74 - iter 0/248 - loss 0.97433102\n",
      "2019-04-18 07:44:07,169 epoch 74 - iter 24/248 - loss 0.86792152\n",
      "2019-04-18 07:44:09,889 epoch 74 - iter 48/248 - loss 0.88138753\n",
      "2019-04-18 07:44:12,706 epoch 74 - iter 72/248 - loss 0.85928951\n",
      "2019-04-18 07:44:15,476 epoch 74 - iter 96/248 - loss 0.83484904\n",
      "2019-04-18 07:44:18,207 epoch 74 - iter 120/248 - loss 0.84006947\n",
      "2019-04-18 07:44:21,016 epoch 74 - iter 144/248 - loss 0.83877611\n",
      "2019-04-18 07:44:23,901 epoch 74 - iter 168/248 - loss 0.85879096\n",
      "2019-04-18 07:44:27,077 epoch 74 - iter 192/248 - loss 0.86299972\n",
      "2019-04-18 07:44:30,265 epoch 74 - iter 216/248 - loss 0.86233473\n",
      "2019-04-18 07:44:33,474 epoch 74 - iter 240/248 - loss 0.87843221\n",
      "2019-04-18 07:44:34,486 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:44:34,490 EPOCH 74 done: loss 0.8777 - lr 0.0250 - bad epochs 0\n",
      "2019-04-18 07:44:36,759 DEV  : loss 1.01810563 - f-score 0.4935 - acc 0.3276\n",
      "2019-04-18 07:44:42,127 TEST : loss 1.16710687 - f-score 0.2767 - acc 0.1606\n",
      "2019-04-18 07:44:45,694 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:44:45,827 epoch 75 - iter 0/248 - loss 0.98402262\n",
      "2019-04-18 07:44:48,691 epoch 75 - iter 24/248 - loss 0.90375642\n",
      "2019-04-18 07:44:51,421 epoch 75 - iter 48/248 - loss 0.86360617\n",
      "2019-04-18 07:44:54,383 epoch 75 - iter 72/248 - loss 0.84449159\n",
      "2019-04-18 07:44:57,333 epoch 75 - iter 96/248 - loss 0.88170120\n",
      "2019-04-18 07:45:00,142 epoch 75 - iter 120/248 - loss 0.89405168\n",
      "2019-04-18 07:45:02,935 epoch 75 - iter 144/248 - loss 0.89382550\n",
      "2019-04-18 07:45:05,709 epoch 75 - iter 168/248 - loss 0.90266198\n",
      "2019-04-18 07:45:08,467 epoch 75 - iter 192/248 - loss 0.89254424\n",
      "2019-04-18 07:45:11,261 epoch 75 - iter 216/248 - loss 0.88094219\n",
      "2019-04-18 07:45:14,066 epoch 75 - iter 240/248 - loss 0.87200401\n",
      "2019-04-18 07:45:15,094 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:45:15,099 EPOCH 75 done: loss 0.8688 - lr 0.0250 - bad epochs 0\n",
      "2019-04-18 07:45:17,355 DEV  : loss 1.02248621 - f-score 0.4059 - acc 0.2547\n",
      "2019-04-18 07:45:22,752 TEST : loss 1.14621127 - f-score 0.3390 - acc 0.2041\n",
      "2019-04-18 07:45:26,346 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:45:26,513 epoch 76 - iter 0/248 - loss 0.71727467\n",
      "2019-04-18 07:45:29,302 epoch 76 - iter 24/248 - loss 0.90666735\n",
      "2019-04-18 07:45:32,160 epoch 76 - iter 48/248 - loss 0.89640429\n",
      "2019-04-18 07:45:35,207 epoch 76 - iter 72/248 - loss 0.87705952\n",
      "2019-04-18 07:45:38,158 epoch 76 - iter 96/248 - loss 0.86564449\n",
      "2019-04-18 07:45:40,874 epoch 76 - iter 120/248 - loss 0.87204691\n",
      "2019-04-18 07:45:43,643 epoch 76 - iter 144/248 - loss 0.85574770\n",
      "2019-04-18 07:45:46,775 epoch 76 - iter 168/248 - loss 0.85817687\n",
      "2019-04-18 07:45:49,987 epoch 76 - iter 192/248 - loss 0.87821700\n",
      "2019-04-18 07:45:53,134 epoch 76 - iter 216/248 - loss 0.87272930\n",
      "2019-04-18 07:45:55,979 epoch 76 - iter 240/248 - loss 0.88046384\n",
      "2019-04-18 07:45:56,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:45:56,931 EPOCH 76 done: loss 0.8775 - lr 0.0250 - bad epochs 0\n",
      "2019-04-18 07:45:59,204 DEV  : loss 1.01999784 - f-score 0.4157 - acc 0.2624\n",
      "2019-04-18 07:46:04,632 TEST : loss 1.15660799 - f-score 0.3479 - acc 0.2106\n",
      "2019-04-18 07:46:04,645 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:46:04,776 epoch 77 - iter 0/248 - loss 1.25201249\n",
      "2019-04-18 07:46:08,095 epoch 77 - iter 24/248 - loss 0.80862374\n",
      "2019-04-18 07:46:11,039 epoch 77 - iter 48/248 - loss 0.84239794\n",
      "2019-04-18 07:46:13,822 epoch 77 - iter 72/248 - loss 0.82752690\n",
      "2019-04-18 07:46:16,634 epoch 77 - iter 96/248 - loss 0.85324087\n",
      "2019-04-18 07:46:19,423 epoch 77 - iter 120/248 - loss 0.84656369\n",
      "2019-04-18 07:46:22,267 epoch 77 - iter 144/248 - loss 0.85488305\n",
      "2019-04-18 07:46:25,052 epoch 77 - iter 168/248 - loss 0.84844590\n",
      "2019-04-18 07:46:27,796 epoch 77 - iter 192/248 - loss 0.86706056\n",
      "2019-04-18 07:46:30,580 epoch 77 - iter 216/248 - loss 0.87413994\n",
      "2019-04-18 07:46:33,364 epoch 77 - iter 240/248 - loss 0.86910645\n",
      "2019-04-18 07:46:34,361 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:46:34,364 EPOCH 77 done: loss 0.8640 - lr 0.0250 - bad epochs 1\n",
      "2019-04-18 07:46:36,635 DEV  : loss 1.16020274 - f-score 0.2735 - acc 0.1584\n",
      "2019-04-18 07:46:42,020 TEST : loss 1.13149798 - f-score 0.3484 - acc 0.2110\n",
      "2019-04-18 07:46:45,598 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:46:45,716 epoch 78 - iter 0/248 - loss 0.86952329\n",
      "2019-04-18 07:46:48,567 epoch 78 - iter 24/248 - loss 0.80136584\n",
      "2019-04-18 07:46:51,311 epoch 78 - iter 48/248 - loss 0.82447126\n",
      "2019-04-18 07:46:54,117 epoch 78 - iter 72/248 - loss 0.78842051\n",
      "2019-04-18 07:46:57,040 epoch 78 - iter 96/248 - loss 0.80313456\n",
      "2019-04-18 07:47:00,021 epoch 78 - iter 120/248 - loss 0.82459141\n",
      "2019-04-18 07:47:02,785 epoch 78 - iter 144/248 - loss 0.82298427\n",
      "2019-04-18 07:47:05,770 epoch 78 - iter 168/248 - loss 0.84323618\n",
      "2019-04-18 07:47:09,019 epoch 78 - iter 192/248 - loss 0.83239390\n",
      "2019-04-18 07:47:12,175 epoch 78 - iter 216/248 - loss 0.84481452\n",
      "2019-04-18 07:47:15,198 epoch 78 - iter 240/248 - loss 0.84133687\n",
      "2019-04-18 07:47:16,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:47:16,196 EPOCH 78 done: loss 0.8407 - lr 0.0250 - bad epochs 0\n",
      "2019-04-18 07:47:18,463 DEV  : loss 1.01505160 - f-score 0.3774 - acc 0.2326\n",
      "2019-04-18 07:47:23,852 TEST : loss 1.15272188 - f-score 0.3624 - acc 0.2213\n",
      "2019-04-18 07:47:27,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:47:27,605 epoch 79 - iter 0/248 - loss 0.51798171\n",
      "2019-04-18 07:47:30,449 epoch 79 - iter 24/248 - loss 0.90413454\n",
      "2019-04-18 07:47:33,832 epoch 79 - iter 48/248 - loss 0.89823593\n",
      "2019-04-18 07:47:37,340 epoch 79 - iter 72/248 - loss 0.86894260\n",
      "2019-04-18 07:47:40,379 epoch 79 - iter 96/248 - loss 0.84267230\n",
      "2019-04-18 07:47:43,161 epoch 79 - iter 120/248 - loss 0.84177282\n",
      "2019-04-18 07:47:46,072 epoch 79 - iter 144/248 - loss 0.83591953\n",
      "2019-04-18 07:47:48,731 epoch 79 - iter 168/248 - loss 0.84306465\n",
      "2019-04-18 07:47:51,586 epoch 79 - iter 192/248 - loss 0.83866671\n",
      "2019-04-18 07:47:54,451 epoch 79 - iter 216/248 - loss 0.85745318\n",
      "2019-04-18 07:47:57,319 epoch 79 - iter 240/248 - loss 0.85497686\n",
      "2019-04-18 07:47:58,278 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:47:58,282 EPOCH 79 done: loss 0.8557 - lr 0.0250 - bad epochs 0\n",
      "2019-04-18 07:48:00,553 DEV  : loss 1.07326174 - f-score 0.5530 - acc 0.3822\n",
      "2019-04-18 07:48:05,935 TEST : loss 1.11371076 - f-score 0.3118 - acc 0.1847\n",
      "2019-04-18 07:48:05,945 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:48:06,085 epoch 80 - iter 0/248 - loss 0.48787349\n",
      "2019-04-18 07:48:08,859 epoch 80 - iter 24/248 - loss 0.87673159\n",
      "2019-04-18 07:48:11,685 epoch 80 - iter 48/248 - loss 0.86017879\n",
      "2019-04-18 07:48:14,340 epoch 80 - iter 72/248 - loss 0.85837313\n",
      "2019-04-18 07:48:17,186 epoch 80 - iter 96/248 - loss 0.87762422\n",
      "2019-04-18 07:48:19,960 epoch 80 - iter 120/248 - loss 0.84197841\n",
      "2019-04-18 07:48:22,820 epoch 80 - iter 144/248 - loss 0.83206653\n",
      "2019-04-18 07:48:25,821 epoch 80 - iter 168/248 - loss 0.84289464\n",
      "2019-04-18 07:48:29,089 epoch 80 - iter 192/248 - loss 0.84321344\n",
      "2019-04-18 07:48:32,331 epoch 80 - iter 216/248 - loss 0.83939183\n",
      "2019-04-18 07:48:35,413 epoch 80 - iter 240/248 - loss 0.85184371\n",
      "2019-04-18 07:48:36,395 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:48:36,397 EPOCH 80 done: loss 0.8506 - lr 0.0250 - bad epochs 1\n",
      "2019-04-18 07:48:38,672 DEV  : loss 1.00738251 - f-score 0.4375 - acc 0.2800\n",
      "2019-04-18 07:48:44,092 TEST : loss 1.12094903 - f-score 0.3388 - acc 0.2040\n",
      "2019-04-18 07:48:44,102 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:48:44,231 epoch 81 - iter 0/248 - loss 0.91558081\n",
      "2019-04-18 07:48:47,060 epoch 81 - iter 24/248 - loss 0.71690246\n",
      "2019-04-18 07:48:49,907 epoch 81 - iter 48/248 - loss 0.80141870\n",
      "2019-04-18 07:48:52,793 epoch 81 - iter 72/248 - loss 0.82758609\n",
      "2019-04-18 07:48:55,561 epoch 81 - iter 96/248 - loss 0.86401104\n",
      "2019-04-18 07:48:58,405 epoch 81 - iter 120/248 - loss 0.85604730\n",
      "2019-04-18 07:49:01,257 epoch 81 - iter 144/248 - loss 0.85694341\n",
      "2019-04-18 07:49:04,022 epoch 81 - iter 168/248 - loss 0.85005533\n",
      "2019-04-18 07:49:06,769 epoch 81 - iter 192/248 - loss 0.85919446\n",
      "2019-04-18 07:49:09,567 epoch 81 - iter 216/248 - loss 0.85981690\n",
      "2019-04-18 07:49:12,391 epoch 81 - iter 240/248 - loss 0.85018969\n",
      "2019-04-18 07:49:13,356 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:49:13,358 EPOCH 81 done: loss 0.8525 - lr 0.0250 - bad epochs 2\n",
      "2019-04-18 07:49:15,618 DEV  : loss 0.99264139 - f-score 0.5145 - acc 0.3463\n",
      "2019-04-18 07:49:20,981 TEST : loss 1.15163589 - f-score 0.2801 - acc 0.1628\n",
      "2019-04-18 07:49:20,992 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:49:21,130 epoch 82 - iter 0/248 - loss 0.70388764\n",
      "2019-04-18 07:49:23,859 epoch 82 - iter 24/248 - loss 0.87167752\n",
      "2019-04-18 07:49:26,726 epoch 82 - iter 48/248 - loss 0.83305498\n",
      "2019-04-18 07:49:29,437 epoch 82 - iter 72/248 - loss 0.86277493\n",
      "2019-04-18 07:49:32,331 epoch 82 - iter 96/248 - loss 0.85978721\n",
      "2019-04-18 07:49:35,165 epoch 82 - iter 120/248 - loss 0.85592634\n",
      "2019-04-18 07:49:37,940 epoch 82 - iter 144/248 - loss 0.86594765\n",
      "2019-04-18 07:49:40,750 epoch 82 - iter 168/248 - loss 0.86683142\n",
      "2019-04-18 07:49:43,516 epoch 82 - iter 192/248 - loss 0.86631388\n",
      "2019-04-18 07:49:46,464 epoch 82 - iter 216/248 - loss 0.86582719\n",
      "2019-04-18 07:49:49,698 epoch 82 - iter 240/248 - loss 0.85527585\n",
      "2019-04-18 07:49:50,831 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:49:50,835 EPOCH 82 done: loss 0.8566 - lr 0.0250 - bad epochs 3\n",
      "2019-04-18 07:49:53,458 DEV  : loss 0.98396087 - f-score 0.5128 - acc 0.3448\n",
      "2019-04-18 07:49:59,053 TEST : loss 1.19318652 - f-score 0.2912 - acc 0.1704\n",
      "Epoch    81: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-04-18 07:49:59,064 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:49:59,220 epoch 83 - iter 0/248 - loss 0.75831908\n",
      "2019-04-18 07:50:02,048 epoch 83 - iter 24/248 - loss 0.85563820\n",
      "2019-04-18 07:50:04,790 epoch 83 - iter 48/248 - loss 0.81417349\n",
      "2019-04-18 07:50:07,597 epoch 83 - iter 72/248 - loss 0.80089738\n",
      "2019-04-18 07:50:10,334 epoch 83 - iter 96/248 - loss 0.80539030\n",
      "2019-04-18 07:50:13,197 epoch 83 - iter 120/248 - loss 0.80121871\n",
      "2019-04-18 07:50:16,007 epoch 83 - iter 144/248 - loss 0.81435284\n",
      "2019-04-18 07:50:18,728 epoch 83 - iter 168/248 - loss 0.81143934\n",
      "2019-04-18 07:50:21,605 epoch 83 - iter 192/248 - loss 0.82995861\n",
      "2019-04-18 07:50:24,403 epoch 83 - iter 216/248 - loss 0.82948490\n",
      "2019-04-18 07:50:27,257 epoch 83 - iter 240/248 - loss 0.83710279\n",
      "2019-04-18 07:50:28,205 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:50:28,209 EPOCH 83 done: loss 0.8339 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:50:30,483 DEV  : loss 1.01149845 - f-score 0.4424 - acc 0.2841\n",
      "2019-04-18 07:50:35,914 TEST : loss 1.14048743 - f-score 0.3264 - acc 0.1950\n",
      "2019-04-18 07:50:39,632 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:50:39,767 epoch 84 - iter 0/248 - loss 1.26618183\n",
      "2019-04-18 07:50:42,681 epoch 84 - iter 24/248 - loss 0.82114391\n",
      "2019-04-18 07:50:45,530 epoch 84 - iter 48/248 - loss 0.79594416\n",
      "2019-04-18 07:50:48,377 epoch 84 - iter 72/248 - loss 0.79117705\n",
      "2019-04-18 07:50:51,481 epoch 84 - iter 96/248 - loss 0.78963686\n",
      "2019-04-18 07:50:54,252 epoch 84 - iter 120/248 - loss 0.78968466\n",
      "2019-04-18 07:50:57,145 epoch 84 - iter 144/248 - loss 0.81629807\n",
      "2019-04-18 07:50:59,906 epoch 84 - iter 168/248 - loss 0.82141974\n",
      "2019-04-18 07:51:02,659 epoch 84 - iter 192/248 - loss 0.82455456\n",
      "2019-04-18 07:51:05,467 epoch 84 - iter 216/248 - loss 0.82312563\n",
      "2019-04-18 07:51:08,651 epoch 84 - iter 240/248 - loss 0.81896547\n",
      "2019-04-18 07:51:09,804 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:51:09,808 EPOCH 84 done: loss 0.8149 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:51:12,462 DEV  : loss 1.02021420 - f-score 0.3810 - acc 0.2353\n",
      "2019-04-18 07:51:18,280 TEST : loss 1.12867880 - f-score 0.3078 - acc 0.1819\n",
      "2019-04-18 07:51:21,910 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:51:22,052 epoch 85 - iter 0/248 - loss 0.65242696\n",
      "2019-04-18 07:51:24,836 epoch 85 - iter 24/248 - loss 0.75060326\n",
      "2019-04-18 07:51:27,731 epoch 85 - iter 48/248 - loss 0.77878240\n",
      "2019-04-18 07:51:30,966 epoch 85 - iter 72/248 - loss 0.81409837\n",
      "2019-04-18 07:51:33,957 epoch 85 - iter 96/248 - loss 0.81860394\n",
      "2019-04-18 07:51:36,747 epoch 85 - iter 120/248 - loss 0.80444011\n",
      "2019-04-18 07:51:39,465 epoch 85 - iter 144/248 - loss 0.81798354\n",
      "2019-04-18 07:51:42,295 epoch 85 - iter 168/248 - loss 0.82129779\n",
      "2019-04-18 07:51:45,151 epoch 85 - iter 192/248 - loss 0.81441057\n",
      "2019-04-18 07:51:47,993 epoch 85 - iter 216/248 - loss 0.82472357\n",
      "2019-04-18 07:51:50,779 epoch 85 - iter 240/248 - loss 0.83066915\n",
      "2019-04-18 07:51:51,785 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:51:51,792 EPOCH 85 done: loss 0.8280 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:51:54,078 DEV  : loss 0.98674941 - f-score 0.4224 - acc 0.2678\n",
      "2019-04-18 07:51:59,449 TEST : loss 1.13606906 - f-score 0.3238 - acc 0.1932\n",
      "2019-04-18 07:51:59,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:51:59,568 epoch 86 - iter 0/248 - loss 0.69299036\n",
      "2019-04-18 07:52:02,408 epoch 86 - iter 24/248 - loss 0.81071640\n",
      "2019-04-18 07:52:05,180 epoch 86 - iter 48/248 - loss 0.78106465\n",
      "2019-04-18 07:52:07,987 epoch 86 - iter 72/248 - loss 0.80937099\n",
      "2019-04-18 07:52:10,785 epoch 86 - iter 96/248 - loss 0.82952426\n",
      "2019-04-18 07:52:13,542 epoch 86 - iter 120/248 - loss 0.81210765\n",
      "2019-04-18 07:52:16,267 epoch 86 - iter 144/248 - loss 0.81298215\n",
      "2019-04-18 07:52:18,990 epoch 86 - iter 168/248 - loss 0.80900224\n",
      "2019-04-18 07:52:21,777 epoch 86 - iter 192/248 - loss 0.80394016\n",
      "2019-04-18 07:52:24,501 epoch 86 - iter 216/248 - loss 0.81403291\n",
      "2019-04-18 07:52:27,500 epoch 86 - iter 240/248 - loss 0.81551676\n",
      "2019-04-18 07:52:28,704 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:52:28,709 EPOCH 86 done: loss 0.8179 - lr 0.0125 - bad epochs 1\n",
      "2019-04-18 07:52:31,318 DEV  : loss 0.99318260 - f-score 0.4772 - acc 0.3134\n",
      "2019-04-18 07:52:37,289 TEST : loss 1.12868035 - f-score 0.3024 - acc 0.1781\n",
      "2019-04-18 07:52:37,301 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:52:37,427 epoch 87 - iter 0/248 - loss 1.05735886\n",
      "2019-04-18 07:52:40,223 epoch 87 - iter 24/248 - loss 0.74185538\n",
      "2019-04-18 07:52:43,457 epoch 87 - iter 48/248 - loss 0.79977066\n",
      "2019-04-18 07:52:46,774 epoch 87 - iter 72/248 - loss 0.84786400\n",
      "2019-04-18 07:52:50,138 epoch 87 - iter 96/248 - loss 0.82186611\n",
      "2019-04-18 07:52:52,957 epoch 87 - iter 120/248 - loss 0.80877941\n",
      "2019-04-18 07:52:55,686 epoch 87 - iter 144/248 - loss 0.80681427\n",
      "2019-04-18 07:52:58,484 epoch 87 - iter 168/248 - loss 0.81786589\n",
      "2019-04-18 07:53:01,343 epoch 87 - iter 192/248 - loss 0.82041904\n",
      "2019-04-18 07:53:04,208 epoch 87 - iter 216/248 - loss 0.81913288\n",
      "2019-04-18 07:53:07,120 epoch 87 - iter 240/248 - loss 0.81412222\n",
      "2019-04-18 07:53:08,143 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:53:08,149 EPOCH 87 done: loss 0.8143 - lr 0.0125 - bad epochs 2\n",
      "2019-04-18 07:53:10,422 DEV  : loss 1.01104999 - f-score 0.4007 - acc 0.2506\n",
      "2019-04-18 07:53:15,796 TEST : loss 1.15083277 - f-score 0.3551 - acc 0.2158\n",
      "2019-04-18 07:53:19,451 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:53:19,580 epoch 88 - iter 0/248 - loss 0.84290850\n",
      "2019-04-18 07:53:22,474 epoch 88 - iter 24/248 - loss 0.73346869\n",
      "2019-04-18 07:53:25,292 epoch 88 - iter 48/248 - loss 0.80163444\n",
      "2019-04-18 07:53:28,529 epoch 88 - iter 72/248 - loss 0.86710034\n",
      "2019-04-18 07:53:31,374 epoch 88 - iter 96/248 - loss 0.85059226\n",
      "2019-04-18 07:53:34,142 epoch 88 - iter 120/248 - loss 0.82649748\n",
      "2019-04-18 07:53:37,098 epoch 88 - iter 144/248 - loss 0.83415365\n",
      "2019-04-18 07:53:39,795 epoch 88 - iter 168/248 - loss 0.80919321\n",
      "2019-04-18 07:53:42,615 epoch 88 - iter 192/248 - loss 0.80384805\n",
      "2019-04-18 07:53:45,349 epoch 88 - iter 216/248 - loss 0.80318710\n",
      "2019-04-18 07:53:48,310 epoch 88 - iter 240/248 - loss 0.80384988\n",
      "2019-04-18 07:53:49,430 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:53:49,432 EPOCH 88 done: loss 0.8097 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:53:52,042 DEV  : loss 0.97612077 - f-score 0.5254 - acc 0.3563\n",
      "2019-04-18 07:53:58,005 TEST : loss 1.15288758 - f-score 0.2660 - acc 0.1534\n",
      "2019-04-18 07:54:01,649 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:54:01,809 epoch 89 - iter 0/248 - loss 0.80864501\n",
      "2019-04-18 07:54:04,698 epoch 89 - iter 24/248 - loss 0.89122602\n",
      "2019-04-18 07:54:07,374 epoch 89 - iter 48/248 - loss 0.87420889\n",
      "2019-04-18 07:54:10,625 epoch 89 - iter 72/248 - loss 0.84661102\n",
      "2019-04-18 07:54:13,408 epoch 89 - iter 96/248 - loss 0.81687681\n",
      "2019-04-18 07:54:16,126 epoch 89 - iter 120/248 - loss 0.82456142\n",
      "2019-04-18 07:54:18,936 epoch 89 - iter 144/248 - loss 0.83025365\n",
      "2019-04-18 07:54:21,732 epoch 89 - iter 168/248 - loss 0.82588412\n",
      "2019-04-18 07:54:24,441 epoch 89 - iter 192/248 - loss 0.80199658\n",
      "2019-04-18 07:54:27,300 epoch 89 - iter 216/248 - loss 0.79346573\n",
      "2019-04-18 07:54:30,159 epoch 89 - iter 240/248 - loss 0.80457430\n",
      "2019-04-18 07:54:31,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:54:31,167 EPOCH 89 done: loss 0.8106 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:54:33,443 DEV  : loss 0.98781866 - f-score 0.4396 - acc 0.2817\n",
      "2019-04-18 07:54:38,803 TEST : loss 1.13204753 - f-score 0.3103 - acc 0.1837\n",
      "2019-04-18 07:54:38,813 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:54:38,950 epoch 90 - iter 0/248 - loss 1.28903389\n",
      "2019-04-18 07:54:41,734 epoch 90 - iter 24/248 - loss 0.67236319\n",
      "2019-04-18 07:54:44,549 epoch 90 - iter 48/248 - loss 0.75414833\n",
      "2019-04-18 07:54:47,338 epoch 90 - iter 72/248 - loss 0.78801828\n",
      "2019-04-18 07:54:50,164 epoch 90 - iter 96/248 - loss 0.79803164\n",
      "2019-04-18 07:54:52,988 epoch 90 - iter 120/248 - loss 0.81070641\n",
      "2019-04-18 07:54:55,743 epoch 90 - iter 144/248 - loss 0.80540591\n",
      "2019-04-18 07:54:58,643 epoch 90 - iter 168/248 - loss 0.80444543\n",
      "2019-04-18 07:55:01,441 epoch 90 - iter 192/248 - loss 0.80470775\n",
      "2019-04-18 07:55:04,161 epoch 90 - iter 216/248 - loss 0.81139279\n",
      "2019-04-18 07:55:07,002 epoch 90 - iter 240/248 - loss 0.80604696\n",
      "2019-04-18 07:55:08,131 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:55:08,137 EPOCH 90 done: loss 0.8075 - lr 0.0125 - bad epochs 1\n",
      "2019-04-18 07:55:10,716 DEV  : loss 1.00785780 - f-score 0.4981 - acc 0.3316\n",
      "2019-04-18 07:55:16,884 TEST : loss 1.12185216 - f-score 0.3030 - acc 0.1785\n",
      "2019-04-18 07:55:20,573 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:55:20,708 epoch 91 - iter 0/248 - loss 0.94887769\n",
      "2019-04-18 07:55:23,640 epoch 91 - iter 24/248 - loss 0.78914912\n",
      "2019-04-18 07:55:26,429 epoch 91 - iter 48/248 - loss 0.79862936\n",
      "2019-04-18 07:55:29,280 epoch 91 - iter 72/248 - loss 0.80501269\n",
      "2019-04-18 07:55:32,213 epoch 91 - iter 96/248 - loss 0.80251402\n",
      "2019-04-18 07:55:34,966 epoch 91 - iter 120/248 - loss 0.81355753\n",
      "2019-04-18 07:55:37,789 epoch 91 - iter 144/248 - loss 0.82025516\n",
      "2019-04-18 07:55:40,642 epoch 91 - iter 168/248 - loss 0.80763195\n",
      "2019-04-18 07:55:43,517 epoch 91 - iter 192/248 - loss 0.81028734\n",
      "2019-04-18 07:55:46,282 epoch 91 - iter 216/248 - loss 0.80540393\n",
      "2019-04-18 07:55:49,063 epoch 91 - iter 240/248 - loss 0.81044920\n",
      "2019-04-18 07:55:50,047 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:55:50,049 EPOCH 91 done: loss 0.8174 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:55:52,321 DEV  : loss 0.97919005 - f-score 0.4275 - acc 0.2718\n",
      "2019-04-18 07:55:57,686 TEST : loss 1.15901399 - f-score 0.2991 - acc 0.1759\n",
      "2019-04-18 07:55:57,697 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:55:57,827 epoch 92 - iter 0/248 - loss 0.58248436\n",
      "2019-04-18 07:56:00,580 epoch 92 - iter 24/248 - loss 0.85253377\n",
      "2019-04-18 07:56:03,415 epoch 92 - iter 48/248 - loss 0.89843625\n",
      "2019-04-18 07:56:06,205 epoch 92 - iter 72/248 - loss 0.86301824\n",
      "2019-04-18 07:56:08,917 epoch 92 - iter 96/248 - loss 0.83108436\n",
      "2019-04-18 07:56:11,667 epoch 92 - iter 120/248 - loss 0.81621040\n",
      "2019-04-18 07:56:14,483 epoch 92 - iter 144/248 - loss 0.81386382\n",
      "2019-04-18 07:56:17,642 epoch 92 - iter 168/248 - loss 0.82272273\n",
      "2019-04-18 07:56:20,828 epoch 92 - iter 192/248 - loss 0.81002388\n",
      "2019-04-18 07:56:23,688 epoch 92 - iter 216/248 - loss 0.81330649\n",
      "2019-04-18 07:56:26,494 epoch 92 - iter 240/248 - loss 0.81142123\n",
      "2019-04-18 07:56:27,472 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:56:27,478 EPOCH 92 done: loss 0.8111 - lr 0.0125 - bad epochs 1\n",
      "2019-04-18 07:56:30,096 DEV  : loss 0.97268808 - f-score 0.4941 - acc 0.3281\n",
      "2019-04-18 07:56:36,261 TEST : loss 1.16839945 - f-score 0.2909 - acc 0.1702\n",
      "2019-04-18 07:56:36,273 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:56:36,395 epoch 93 - iter 0/248 - loss 0.67326725\n",
      "2019-04-18 07:56:39,392 epoch 93 - iter 24/248 - loss 0.77716565\n",
      "2019-04-18 07:56:42,211 epoch 93 - iter 48/248 - loss 0.79782036\n",
      "2019-04-18 07:56:45,011 epoch 93 - iter 72/248 - loss 0.77681068\n",
      "2019-04-18 07:56:47,820 epoch 93 - iter 96/248 - loss 0.80436915\n",
      "2019-04-18 07:56:50,607 epoch 93 - iter 120/248 - loss 0.79806936\n",
      "2019-04-18 07:56:53,412 epoch 93 - iter 144/248 - loss 0.79659116\n",
      "2019-04-18 07:56:56,224 epoch 93 - iter 168/248 - loss 0.80692981\n",
      "2019-04-18 07:56:59,019 epoch 93 - iter 192/248 - loss 0.79796157\n",
      "2019-04-18 07:57:01,742 epoch 93 - iter 216/248 - loss 0.78519863\n",
      "2019-04-18 07:57:04,590 epoch 93 - iter 240/248 - loss 0.79146889\n",
      "2019-04-18 07:57:05,609 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:57:05,615 EPOCH 93 done: loss 0.7923 - lr 0.0125 - bad epochs 2\n",
      "2019-04-18 07:57:07,882 DEV  : loss 1.00979745 - f-score 0.4407 - acc 0.2826\n",
      "2019-04-18 07:57:13,258 TEST : loss 1.14242303 - f-score 0.3359 - acc 0.2019\n",
      "2019-04-18 07:57:16,881 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:57:16,999 epoch 94 - iter 0/248 - loss 1.21048796\n",
      "2019-04-18 07:57:19,797 epoch 94 - iter 24/248 - loss 0.83697303\n",
      "2019-04-18 07:57:22,657 epoch 94 - iter 48/248 - loss 0.84788702\n",
      "2019-04-18 07:57:25,610 epoch 94 - iter 72/248 - loss 0.80649176\n",
      "2019-04-18 07:57:28,532 epoch 94 - iter 96/248 - loss 0.81267612\n",
      "2019-04-18 07:57:31,290 epoch 94 - iter 120/248 - loss 0.83847903\n",
      "2019-04-18 07:57:34,080 epoch 94 - iter 144/248 - loss 0.83777885\n",
      "2019-04-18 07:57:36,924 epoch 94 - iter 168/248 - loss 0.82599430\n",
      "2019-04-18 07:57:39,686 epoch 94 - iter 192/248 - loss 0.82892872\n",
      "2019-04-18 07:57:42,493 epoch 94 - iter 216/248 - loss 0.82654359\n",
      "2019-04-18 07:57:45,285 epoch 94 - iter 240/248 - loss 0.82434294\n",
      "2019-04-18 07:57:46,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:57:46,283 EPOCH 94 done: loss 0.8237 - lr 0.0125 - bad epochs 0\n",
      "2019-04-18 07:57:48,635 DEV  : loss 0.99818838 - f-score 0.4203 - acc 0.2661\n",
      "2019-04-18 07:57:54,957 TEST : loss 1.13357115 - f-score 0.3333 - acc 0.2000\n",
      "2019-04-18 07:57:54,969 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:57:55,104 epoch 95 - iter 0/248 - loss 0.91568434\n",
      "2019-04-18 07:57:58,375 epoch 95 - iter 24/248 - loss 0.78794038\n",
      "2019-04-18 07:58:01,555 epoch 95 - iter 48/248 - loss 0.82527865\n",
      "2019-04-18 07:58:04,353 epoch 95 - iter 72/248 - loss 0.78032551\n",
      "2019-04-18 07:58:07,182 epoch 95 - iter 96/248 - loss 0.78028391\n",
      "2019-04-18 07:58:10,007 epoch 95 - iter 120/248 - loss 0.78133680\n",
      "2019-04-18 07:58:12,818 epoch 95 - iter 144/248 - loss 0.79672310\n",
      "2019-04-18 07:58:15,562 epoch 95 - iter 168/248 - loss 0.79715879\n",
      "2019-04-18 07:58:18,406 epoch 95 - iter 192/248 - loss 0.80674018\n",
      "2019-04-18 07:58:21,172 epoch 95 - iter 216/248 - loss 0.79991033\n",
      "2019-04-18 07:58:24,012 epoch 95 - iter 240/248 - loss 0.80622165\n",
      "2019-04-18 07:58:24,979 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:58:24,980 EPOCH 95 done: loss 0.8032 - lr 0.0125 - bad epochs 1\n",
      "2019-04-18 07:58:27,269 DEV  : loss 0.98427182 - f-score 0.4810 - acc 0.3166\n",
      "2019-04-18 07:58:32,695 TEST : loss 1.15130401 - f-score 0.2967 - acc 0.1742\n",
      "2019-04-18 07:58:32,706 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:58:32,829 epoch 96 - iter 0/248 - loss 0.35658133\n",
      "2019-04-18 07:58:35,689 epoch 96 - iter 24/248 - loss 0.82823725\n",
      "2019-04-18 07:58:38,490 epoch 96 - iter 48/248 - loss 0.81138712\n",
      "2019-04-18 07:58:41,362 epoch 96 - iter 72/248 - loss 0.82618215\n",
      "2019-04-18 07:58:44,218 epoch 96 - iter 96/248 - loss 0.84245420\n",
      "2019-04-18 07:58:47,021 epoch 96 - iter 120/248 - loss 0.84315690\n",
      "2019-04-18 07:58:49,759 epoch 96 - iter 144/248 - loss 0.82246087\n",
      "2019-04-18 07:58:52,626 epoch 96 - iter 168/248 - loss 0.82023290\n",
      "2019-04-18 07:58:55,397 epoch 96 - iter 192/248 - loss 0.82186175\n",
      "2019-04-18 07:58:58,194 epoch 96 - iter 216/248 - loss 0.81098484\n",
      "2019-04-18 07:59:00,964 epoch 96 - iter 240/248 - loss 0.80170039\n",
      "2019-04-18 07:59:01,976 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:59:01,980 EPOCH 96 done: loss 0.8000 - lr 0.0125 - bad epochs 2\n",
      "2019-04-18 07:59:04,260 DEV  : loss 0.99611306 - f-score 0.4280 - acc 0.2723\n",
      "2019-04-18 07:59:09,830 TEST : loss 1.15766609 - f-score 0.3215 - acc 0.1916\n",
      "2019-04-18 07:59:09,843 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:59:09,974 epoch 97 - iter 0/248 - loss 0.86073291\n",
      "2019-04-18 07:59:13,233 epoch 97 - iter 24/248 - loss 0.69729946\n",
      "2019-04-18 07:59:16,410 epoch 97 - iter 48/248 - loss 0.74120232\n",
      "2019-04-18 07:59:19,439 epoch 97 - iter 72/248 - loss 0.76012838\n",
      "2019-04-18 07:59:22,259 epoch 97 - iter 96/248 - loss 0.77448610\n",
      "2019-04-18 07:59:25,096 epoch 97 - iter 120/248 - loss 0.77955564\n",
      "2019-04-18 07:59:27,868 epoch 97 - iter 144/248 - loss 0.79652369\n",
      "2019-04-18 07:59:30,690 epoch 97 - iter 168/248 - loss 0.79949661\n",
      "2019-04-18 07:59:33,510 epoch 97 - iter 192/248 - loss 0.80720555\n",
      "2019-04-18 07:59:36,264 epoch 97 - iter 216/248 - loss 0.80161461\n",
      "2019-04-18 07:59:39,149 epoch 97 - iter 240/248 - loss 0.80569206\n",
      "2019-04-18 07:59:40,146 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:59:40,148 EPOCH 97 done: loss 0.8052 - lr 0.0125 - bad epochs 3\n",
      "2019-04-18 07:59:42,442 DEV  : loss 0.99862307 - f-score 0.4154 - acc 0.2621\n",
      "2019-04-18 07:59:47,827 TEST : loss 1.14884257 - f-score 0.3216 - acc 0.1916\n",
      "Epoch    96: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-04-18 07:59:47,837 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 07:59:47,945 epoch 98 - iter 0/248 - loss 0.70580941\n",
      "2019-04-18 07:59:50,752 epoch 98 - iter 24/248 - loss 0.68149966\n",
      "2019-04-18 07:59:53,486 epoch 98 - iter 48/248 - loss 0.73761451\n",
      "2019-04-18 07:59:56,332 epoch 98 - iter 72/248 - loss 0.76751600\n",
      "2019-04-18 07:59:59,331 epoch 98 - iter 96/248 - loss 0.80465100\n",
      "2019-04-18 08:00:02,116 epoch 98 - iter 120/248 - loss 0.79712333\n",
      "2019-04-18 08:00:04,967 epoch 98 - iter 144/248 - loss 0.78595504\n",
      "2019-04-18 08:00:07,795 epoch 98 - iter 168/248 - loss 0.79543843\n",
      "2019-04-18 08:00:10,512 epoch 98 - iter 192/248 - loss 0.78696037\n",
      "2019-04-18 08:00:13,353 epoch 98 - iter 216/248 - loss 0.77814613\n",
      "2019-04-18 08:00:16,127 epoch 98 - iter 240/248 - loss 0.78024030\n",
      "2019-04-18 08:00:17,149 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:00:17,155 EPOCH 98 done: loss 0.7836 - lr 0.0063 - bad epochs 0\n",
      "2019-04-18 08:00:19,432 DEV  : loss 0.97257823 - f-score 0.4893 - acc 0.3239\n",
      "2019-04-18 08:00:24,842 TEST : loss 1.15496182 - f-score 0.2886 - acc 0.1687\n",
      "2019-04-18 08:00:28,525 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:00:28,654 epoch 99 - iter 0/248 - loss 0.62867689\n",
      "2019-04-18 08:00:31,915 epoch 99 - iter 24/248 - loss 0.86480301\n",
      "2019-04-18 08:00:35,095 epoch 99 - iter 48/248 - loss 0.83050695\n",
      "2019-04-18 08:00:38,573 epoch 99 - iter 72/248 - loss 0.83525560\n",
      "2019-04-18 08:00:41,533 epoch 99 - iter 96/248 - loss 0.81853630\n",
      "2019-04-18 08:00:44,310 epoch 99 - iter 120/248 - loss 0.80143715\n",
      "2019-04-18 08:00:47,152 epoch 99 - iter 144/248 - loss 0.81986024\n",
      "2019-04-18 08:00:49,943 epoch 99 - iter 168/248 - loss 0.82057069\n",
      "2019-04-18 08:00:52,740 epoch 99 - iter 192/248 - loss 0.80865715\n",
      "2019-04-18 08:00:55,460 epoch 99 - iter 216/248 - loss 0.80574915\n",
      "2019-04-18 08:00:58,340 epoch 99 - iter 240/248 - loss 0.80127679\n",
      "2019-04-18 08:00:59,338 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:00:59,340 EPOCH 99 done: loss 0.8003 - lr 0.0063 - bad epochs 0\n",
      "2019-04-18 08:01:01,631 DEV  : loss 0.98667276 - f-score 0.4804 - acc 0.3162\n",
      "2019-04-18 08:01:07,057 TEST : loss 1.14912140 - f-score 0.3153 - acc 0.1871\n",
      "2019-04-18 08:01:07,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:01:07,202 epoch 100 - iter 0/248 - loss 0.93094218\n",
      "2019-04-18 08:01:10,038 epoch 100 - iter 24/248 - loss 0.86833137\n",
      "2019-04-18 08:01:12,803 epoch 100 - iter 48/248 - loss 0.77756703\n",
      "2019-04-18 08:01:15,652 epoch 100 - iter 72/248 - loss 0.79733875\n",
      "2019-04-18 08:01:18,475 epoch 100 - iter 96/248 - loss 0.80625756\n",
      "2019-04-18 08:01:21,463 epoch 100 - iter 120/248 - loss 0.81786331\n",
      "2019-04-18 08:01:24,730 epoch 100 - iter 144/248 - loss 0.82437315\n",
      "2019-04-18 08:01:27,707 epoch 100 - iter 168/248 - loss 0.80994152\n",
      "2019-04-18 08:01:30,497 epoch 100 - iter 192/248 - loss 0.80945514\n",
      "2019-04-18 08:01:33,341 epoch 100 - iter 216/248 - loss 0.79519595\n",
      "2019-04-18 08:01:36,112 epoch 100 - iter 240/248 - loss 0.79210083\n",
      "2019-04-18 08:01:37,123 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:01:37,127 EPOCH 100 done: loss 0.7861 - lr 0.0063 - bad epochs 1\n",
      "2019-04-18 08:01:39,436 DEV  : loss 0.99263710 - f-score 0.4381 - acc 0.2805\n",
      "2019-04-18 08:01:44,843 TEST : loss 1.13606584 - f-score 0.3213 - acc 0.1914\n",
      "2019-04-18 08:01:44,854 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:01:44,999 epoch 101 - iter 0/248 - loss 0.72591943\n",
      "2019-04-18 08:01:47,940 epoch 101 - iter 24/248 - loss 0.84135976\n",
      "2019-04-18 08:01:50,931 epoch 101 - iter 48/248 - loss 0.82916312\n",
      "2019-04-18 08:01:54,205 epoch 101 - iter 72/248 - loss 0.84378150\n",
      "2019-04-18 08:01:57,410 epoch 101 - iter 96/248 - loss 0.81036662\n",
      "2019-04-18 08:02:00,435 epoch 101 - iter 120/248 - loss 0.80972621\n",
      "2019-04-18 08:02:03,267 epoch 101 - iter 144/248 - loss 0.83156880\n",
      "2019-04-18 08:02:06,059 epoch 101 - iter 168/248 - loss 0.81937109\n",
      "2019-04-18 08:02:08,852 epoch 101 - iter 192/248 - loss 0.81591412\n",
      "2019-04-18 08:02:11,640 epoch 101 - iter 216/248 - loss 0.80919781\n",
      "2019-04-18 08:02:14,442 epoch 101 - iter 240/248 - loss 0.81055421\n",
      "2019-04-18 08:02:15,402 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:02:15,407 EPOCH 101 done: loss 0.8101 - lr 0.0063 - bad epochs 2\n",
      "2019-04-18 08:02:17,684 DEV  : loss 0.97155654 - f-score 0.4823 - acc 0.3178\n",
      "2019-04-18 08:02:23,095 TEST : loss 1.15663660 - f-score 0.3021 - acc 0.1779\n",
      "2019-04-18 08:02:23,107 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:02:23,218 epoch 102 - iter 0/248 - loss 0.56924951\n",
      "2019-04-18 08:02:26,057 epoch 102 - iter 24/248 - loss 0.70407517\n",
      "2019-04-18 08:02:28,927 epoch 102 - iter 48/248 - loss 0.75711576\n",
      "2019-04-18 08:02:31,715 epoch 102 - iter 72/248 - loss 0.74161609\n",
      "2019-04-18 08:02:34,568 epoch 102 - iter 96/248 - loss 0.76242130\n",
      "2019-04-18 08:02:37,319 epoch 102 - iter 120/248 - loss 0.75311697\n",
      "2019-04-18 08:02:40,094 epoch 102 - iter 144/248 - loss 0.75227886\n",
      "2019-04-18 08:02:42,945 epoch 102 - iter 168/248 - loss 0.75954565\n",
      "2019-04-18 08:02:45,858 epoch 102 - iter 192/248 - loss 0.76410860\n",
      "2019-04-18 08:02:48,700 epoch 102 - iter 216/248 - loss 0.76377456\n",
      "2019-04-18 08:02:51,460 epoch 102 - iter 240/248 - loss 0.77578432\n",
      "2019-04-18 08:02:52,502 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:02:52,504 EPOCH 102 done: loss 0.7823 - lr 0.0063 - bad epochs 3\n",
      "2019-04-18 08:02:54,799 DEV  : loss 0.97830099 - f-score 0.4859 - acc 0.3209\n",
      "2019-04-18 08:03:00,206 TEST : loss 1.14759028 - f-score 0.3011 - acc 0.1773\n",
      "2019-04-18 08:03:04,426 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:03:04,596 epoch 103 - iter 0/248 - loss 1.33404779\n",
      "2019-04-18 08:03:07,867 epoch 103 - iter 24/248 - loss 0.87871087\n",
      "2019-04-18 08:03:11,123 epoch 103 - iter 48/248 - loss 0.79805587\n",
      "2019-04-18 08:03:14,571 epoch 103 - iter 72/248 - loss 0.75334376\n",
      "2019-04-18 08:03:17,949 epoch 103 - iter 96/248 - loss 0.79524439\n",
      "2019-04-18 08:03:21,043 epoch 103 - iter 120/248 - loss 0.82076109\n",
      "2019-04-18 08:03:23,873 epoch 103 - iter 144/248 - loss 0.79857500\n",
      "2019-04-18 08:03:26,711 epoch 103 - iter 168/248 - loss 0.80604289\n",
      "2019-04-18 08:03:29,554 epoch 103 - iter 192/248 - loss 0.80510365\n",
      "2019-04-18 08:03:32,398 epoch 103 - iter 216/248 - loss 0.79973341\n",
      "2019-04-18 08:03:35,268 epoch 103 - iter 240/248 - loss 0.79285750\n",
      "2019-04-18 08:03:36,254 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:03:36,256 EPOCH 103 done: loss 0.7943 - lr 0.0063 - bad epochs 0\n",
      "2019-04-18 08:03:38,543 DEV  : loss 0.98606861 - f-score 0.4430 - acc 0.2845\n",
      "2019-04-18 08:03:43,983 TEST : loss 1.13571513 - f-score 0.3283 - acc 0.1964\n",
      "2019-04-18 08:03:43,999 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:03:44,114 epoch 104 - iter 0/248 - loss 0.37145180\n",
      "2019-04-18 08:03:46,911 epoch 104 - iter 24/248 - loss 0.74501920\n",
      "2019-04-18 08:03:49,683 epoch 104 - iter 48/248 - loss 0.70723800\n",
      "2019-04-18 08:03:52,525 epoch 104 - iter 72/248 - loss 0.68477923\n",
      "2019-04-18 08:03:55,384 epoch 104 - iter 96/248 - loss 0.72215241\n",
      "2019-04-18 08:03:58,194 epoch 104 - iter 120/248 - loss 0.73422659\n",
      "2019-04-18 08:04:01,041 epoch 104 - iter 144/248 - loss 0.75655855\n",
      "2019-04-18 08:04:03,886 epoch 104 - iter 168/248 - loss 0.77210758\n",
      "2019-04-18 08:04:06,718 epoch 104 - iter 192/248 - loss 0.77284660\n",
      "2019-04-18 08:04:09,519 epoch 104 - iter 216/248 - loss 0.77461423\n",
      "2019-04-18 08:04:12,377 epoch 104 - iter 240/248 - loss 0.78140581\n",
      "2019-04-18 08:04:13,399 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:04:13,401 EPOCH 104 done: loss 0.7836 - lr 0.0063 - bad epochs 1\n",
      "2019-04-18 08:04:15,685 DEV  : loss 0.99137914 - f-score 0.4334 - acc 0.2767\n",
      "2019-04-18 08:04:21,077 TEST : loss 1.14162493 - f-score 0.3349 - acc 0.2011\n",
      "2019-04-18 08:04:21,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:04:21,215 epoch 105 - iter 0/248 - loss 1.03980279\n",
      "2019-04-18 08:04:23,985 epoch 105 - iter 24/248 - loss 0.91253739\n",
      "2019-04-18 08:04:26,771 epoch 105 - iter 48/248 - loss 0.84690280\n",
      "2019-04-18 08:04:29,598 epoch 105 - iter 72/248 - loss 0.82316606\n",
      "2019-04-18 08:04:32,662 epoch 105 - iter 96/248 - loss 0.80535267\n",
      "2019-04-18 08:04:35,903 epoch 105 - iter 120/248 - loss 0.79550085\n",
      "2019-04-18 08:04:39,035 epoch 105 - iter 144/248 - loss 0.77749890\n",
      "2019-04-18 08:04:42,010 epoch 105 - iter 168/248 - loss 0.77562677\n",
      "2019-04-18 08:04:44,875 epoch 105 - iter 192/248 - loss 0.78232738\n",
      "2019-04-18 08:04:47,713 epoch 105 - iter 216/248 - loss 0.78998069\n",
      "2019-04-18 08:04:50,479 epoch 105 - iter 240/248 - loss 0.79614005\n",
      "2019-04-18 08:04:51,455 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:04:51,461 EPOCH 105 done: loss 0.7909 - lr 0.0063 - bad epochs 2\n",
      "2019-04-18 08:04:53,736 DEV  : loss 0.98892879 - f-score 0.4421 - acc 0.2838\n",
      "2019-04-18 08:04:59,147 TEST : loss 1.13704026 - f-score 0.3315 - acc 0.1987\n",
      "2019-04-18 08:04:59,158 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:04:59,301 epoch 106 - iter 0/248 - loss 0.99502087\n",
      "2019-04-18 08:05:02,067 epoch 106 - iter 24/248 - loss 0.83135703\n",
      "2019-04-18 08:05:04,916 epoch 106 - iter 48/248 - loss 0.83304145\n",
      "2019-04-18 08:05:07,779 epoch 106 - iter 72/248 - loss 0.83652314\n",
      "2019-04-18 08:05:10,581 epoch 106 - iter 96/248 - loss 0.81746454\n",
      "2019-04-18 08:05:13,403 epoch 106 - iter 120/248 - loss 0.83330969\n",
      "2019-04-18 08:05:16,217 epoch 106 - iter 144/248 - loss 0.82077380\n",
      "2019-04-18 08:05:18,997 epoch 106 - iter 168/248 - loss 0.79947696\n",
      "2019-04-18 08:05:21,788 epoch 106 - iter 192/248 - loss 0.79028897\n",
      "2019-04-18 08:05:24,586 epoch 106 - iter 216/248 - loss 0.78599340\n",
      "2019-04-18 08:05:27,376 epoch 106 - iter 240/248 - loss 0.79733274\n",
      "2019-04-18 08:05:28,365 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:05:28,368 EPOCH 106 done: loss 0.7956 - lr 0.0063 - bad epochs 3\n",
      "2019-04-18 08:05:30,636 DEV  : loss 0.98012441 - f-score 0.4450 - acc 0.2862\n",
      "2019-04-18 08:05:36,029 TEST : loss 1.15722930 - f-score 0.3247 - acc 0.1938\n",
      "Epoch   105: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-04-18 08:05:36,039 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:05:36,158 epoch 107 - iter 0/248 - loss 0.81178945\n",
      "2019-04-18 08:05:38,975 epoch 107 - iter 24/248 - loss 0.71272255\n",
      "2019-04-18 08:05:41,757 epoch 107 - iter 48/248 - loss 0.73638476\n",
      "2019-04-18 08:05:44,618 epoch 107 - iter 72/248 - loss 0.75884596\n",
      "2019-04-18 08:05:47,420 epoch 107 - iter 96/248 - loss 0.80216603\n",
      "2019-04-18 08:05:50,253 epoch 107 - iter 120/248 - loss 0.79841724\n",
      "2019-04-18 08:05:53,396 epoch 107 - iter 144/248 - loss 0.80720868\n",
      "2019-04-18 08:05:56,551 epoch 107 - iter 168/248 - loss 0.81211440\n",
      "2019-04-18 08:05:59,677 epoch 107 - iter 192/248 - loss 0.79819899\n",
      "2019-04-18 08:06:02,631 epoch 107 - iter 216/248 - loss 0.78598015\n",
      "2019-04-18 08:06:05,418 epoch 107 - iter 240/248 - loss 0.78867924\n",
      "2019-04-18 08:06:06,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:06:06,381 EPOCH 107 done: loss 0.7883 - lr 0.0031 - bad epochs 0\n",
      "2019-04-18 08:06:08,694 DEV  : loss 0.97951871 - f-score 0.4407 - acc 0.2826\n",
      "2019-04-18 08:06:14,109 TEST : loss 1.15156496 - f-score 0.3228 - acc 0.1925\n",
      "2019-04-18 08:06:14,121 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:06:14,264 epoch 108 - iter 0/248 - loss 1.12065387\n",
      "2019-04-18 08:06:17,091 epoch 108 - iter 24/248 - loss 0.77601136\n",
      "2019-04-18 08:06:19,773 epoch 108 - iter 48/248 - loss 0.75903140\n",
      "2019-04-18 08:06:22,581 epoch 108 - iter 72/248 - loss 0.75782180\n",
      "2019-04-18 08:06:25,445 epoch 108 - iter 96/248 - loss 0.75586477\n",
      "2019-04-18 08:06:28,665 epoch 108 - iter 120/248 - loss 0.75926964\n",
      "2019-04-18 08:06:31,736 epoch 108 - iter 144/248 - loss 0.75595959\n",
      "2019-04-18 08:06:34,595 epoch 108 - iter 168/248 - loss 0.76955245\n",
      "2019-04-18 08:06:37,323 epoch 108 - iter 192/248 - loss 0.79570781\n",
      "2019-04-18 08:06:40,129 epoch 108 - iter 216/248 - loss 0.79066682\n",
      "2019-04-18 08:06:42,845 epoch 108 - iter 240/248 - loss 0.79612054\n",
      "2019-04-18 08:06:43,842 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:06:43,845 EPOCH 108 done: loss 0.7970 - lr 0.0031 - bad epochs 1\n",
      "2019-04-18 08:06:46,128 DEV  : loss 0.97342682 - f-score 0.4278 - acc 0.2721\n",
      "2019-04-18 08:06:51,495 TEST : loss 1.15661883 - f-score 0.3260 - acc 0.1947\n",
      "2019-04-18 08:06:51,509 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:06:51,637 epoch 109 - iter 0/248 - loss 0.53819704\n",
      "2019-04-18 08:06:54,409 epoch 109 - iter 24/248 - loss 0.75520942\n",
      "2019-04-18 08:06:57,212 epoch 109 - iter 48/248 - loss 0.74770104\n",
      "2019-04-18 08:07:00,031 epoch 109 - iter 72/248 - loss 0.75997630\n",
      "2019-04-18 08:07:02,828 epoch 109 - iter 96/248 - loss 0.75600990\n",
      "2019-04-18 08:07:05,519 epoch 109 - iter 120/248 - loss 0.75929864\n",
      "2019-04-18 08:07:08,388 epoch 109 - iter 144/248 - loss 0.77419957\n",
      "2019-04-18 08:07:11,302 epoch 109 - iter 168/248 - loss 0.77916701\n",
      "2019-04-18 08:07:14,334 epoch 109 - iter 192/248 - loss 0.77112514\n",
      "2019-04-18 08:07:17,536 epoch 109 - iter 216/248 - loss 0.77283894\n",
      "2019-04-18 08:07:20,741 epoch 109 - iter 240/248 - loss 0.77868152\n",
      "2019-04-18 08:07:21,868 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:07:21,870 EPOCH 109 done: loss 0.7740 - lr 0.0031 - bad epochs 2\n",
      "2019-04-18 08:07:24,138 DEV  : loss 0.98724097 - f-score 0.4356 - acc 0.2785\n",
      "2019-04-18 08:07:29,528 TEST : loss 1.14478934 - f-score 0.3252 - acc 0.1941\n",
      "2019-04-18 08:07:33,168 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:07:33,339 epoch 110 - iter 0/248 - loss 1.50904489\n",
      "2019-04-18 08:07:36,161 epoch 110 - iter 24/248 - loss 0.75931860\n",
      "2019-04-18 08:07:38,984 epoch 110 - iter 48/248 - loss 0.76761596\n",
      "2019-04-18 08:07:42,074 epoch 110 - iter 72/248 - loss 0.76543668\n",
      "2019-04-18 08:07:44,902 epoch 110 - iter 96/248 - loss 0.76017084\n",
      "2019-04-18 08:07:47,627 epoch 110 - iter 120/248 - loss 0.77845083\n",
      "2019-04-18 08:07:50,459 epoch 110 - iter 144/248 - loss 0.76551080\n",
      "2019-04-18 08:07:53,161 epoch 110 - iter 168/248 - loss 0.77199722\n",
      "2019-04-18 08:07:55,927 epoch 110 - iter 192/248 - loss 0.77789105\n",
      "2019-04-18 08:07:58,802 epoch 110 - iter 216/248 - loss 0.78967520\n",
      "2019-04-18 08:08:01,593 epoch 110 - iter 240/248 - loss 0.77573512\n",
      "2019-04-18 08:08:02,615 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:08:02,617 EPOCH 110 done: loss 0.7792 - lr 0.0031 - bad epochs 0\n",
      "2019-04-18 08:08:04,902 DEV  : loss 0.98140049 - f-score 0.4425 - acc 0.2841\n",
      "2019-04-18 08:08:10,258 TEST : loss 1.14757347 - f-score 0.3305 - acc 0.1980\n",
      "2019-04-18 08:08:10,269 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:08:10,418 epoch 111 - iter 0/248 - loss 1.76563179\n",
      "2019-04-18 08:08:13,591 epoch 111 - iter 24/248 - loss 0.88246565\n",
      "2019-04-18 08:08:16,842 epoch 111 - iter 48/248 - loss 0.88375715\n",
      "2019-04-18 08:08:20,103 epoch 111 - iter 72/248 - loss 0.82667384\n",
      "2019-04-18 08:08:23,045 epoch 111 - iter 96/248 - loss 0.80330039\n",
      "2019-04-18 08:08:25,763 epoch 111 - iter 120/248 - loss 0.78197569\n",
      "2019-04-18 08:08:28,536 epoch 111 - iter 144/248 - loss 0.77458328\n",
      "2019-04-18 08:08:31,336 epoch 111 - iter 168/248 - loss 0.77923175\n",
      "2019-04-18 08:08:34,527 epoch 111 - iter 192/248 - loss 0.79226820\n",
      "2019-04-18 08:08:37,745 epoch 111 - iter 216/248 - loss 0.77269272\n",
      "2019-04-18 08:08:40,870 epoch 111 - iter 240/248 - loss 0.77597884\n",
      "2019-04-18 08:08:42,023 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:08:42,025 EPOCH 111 done: loss 0.7756 - lr 0.0031 - bad epochs 1\n",
      "2019-04-18 08:08:44,300 DEV  : loss 0.99063319 - f-score 0.4221 - acc 0.2676\n",
      "2019-04-18 08:08:49,694 TEST : loss 1.14594102 - f-score 0.3352 - acc 0.2013\n",
      "2019-04-18 08:08:49,705 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:08:49,829 epoch 112 - iter 0/248 - loss 0.52708125\n",
      "2019-04-18 08:08:52,634 epoch 112 - iter 24/248 - loss 0.84062184\n",
      "2019-04-18 08:08:55,395 epoch 112 - iter 48/248 - loss 0.75068019\n",
      "2019-04-18 08:08:58,254 epoch 112 - iter 72/248 - loss 0.78430324\n",
      "2019-04-18 08:09:01,040 epoch 112 - iter 96/248 - loss 0.76115580\n",
      "2019-04-18 08:09:03,936 epoch 112 - iter 120/248 - loss 0.75962510\n",
      "2019-04-18 08:09:06,813 epoch 112 - iter 144/248 - loss 0.76534088\n",
      "2019-04-18 08:09:09,582 epoch 112 - iter 168/248 - loss 0.76776210\n",
      "2019-04-18 08:09:12,345 epoch 112 - iter 192/248 - loss 0.77822889\n",
      "2019-04-18 08:09:15,162 epoch 112 - iter 216/248 - loss 0.77711052\n",
      "2019-04-18 08:09:17,953 epoch 112 - iter 240/248 - loss 0.77001763\n",
      "2019-04-18 08:09:18,914 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:09:18,919 EPOCH 112 done: loss 0.7744 - lr 0.0031 - bad epochs 2\n",
      "2019-04-18 08:09:21,190 DEV  : loss 0.99107569 - f-score 0.4498 - acc 0.2902\n",
      "2019-04-18 08:09:26,571 TEST : loss 1.13797939 - f-score 0.3313 - acc 0.1985\n",
      "2019-04-18 08:09:26,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:09:26,722 epoch 113 - iter 0/248 - loss 0.46102130\n",
      "2019-04-18 08:09:29,523 epoch 113 - iter 24/248 - loss 0.77445351\n",
      "2019-04-18 08:09:32,336 epoch 113 - iter 48/248 - loss 0.77742402\n",
      "2019-04-18 08:09:35,180 epoch 113 - iter 72/248 - loss 0.77732812\n",
      "2019-04-18 08:09:38,019 epoch 113 - iter 96/248 - loss 0.76077501\n",
      "2019-04-18 08:09:40,774 epoch 113 - iter 120/248 - loss 0.76811354\n",
      "2019-04-18 08:09:43,653 epoch 113 - iter 144/248 - loss 0.76301104\n",
      "2019-04-18 08:09:46,515 epoch 113 - iter 168/248 - loss 0.76553622\n",
      "2019-04-18 08:09:49,300 epoch 113 - iter 192/248 - loss 0.77274368\n",
      "2019-04-18 08:09:52,061 epoch 113 - iter 216/248 - loss 0.78391271\n",
      "2019-04-18 08:09:55,163 epoch 113 - iter 240/248 - loss 0.77878285\n",
      "2019-04-18 08:09:56,249 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:09:56,250 EPOCH 113 done: loss 0.7727 - lr 0.0031 - bad epochs 3\n",
      "2019-04-18 08:09:58,882 DEV  : loss 0.98483890 - f-score 0.4241 - acc 0.2691\n",
      "2019-04-18 08:10:04,756 TEST : loss 1.14710796 - f-score 0.3318 - acc 0.1989\n",
      "2019-04-18 08:10:08,399 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:10:08,563 epoch 114 - iter 0/248 - loss 0.48291868\n",
      "2019-04-18 08:10:11,426 epoch 114 - iter 24/248 - loss 0.76392096\n",
      "2019-04-18 08:10:14,176 epoch 114 - iter 48/248 - loss 0.75479956\n",
      "2019-04-18 08:10:17,338 epoch 114 - iter 72/248 - loss 0.78768899\n",
      "2019-04-18 08:10:20,144 epoch 114 - iter 96/248 - loss 0.76936653\n",
      "2019-04-18 08:10:23,033 epoch 114 - iter 120/248 - loss 0.78859131\n",
      "2019-04-18 08:10:25,828 epoch 114 - iter 144/248 - loss 0.79593723\n",
      "2019-04-18 08:10:28,680 epoch 114 - iter 168/248 - loss 0.80047029\n",
      "2019-04-18 08:10:31,524 epoch 114 - iter 192/248 - loss 0.78956088\n",
      "2019-04-18 08:10:34,340 epoch 114 - iter 216/248 - loss 0.78379171\n",
      "2019-04-18 08:10:37,292 epoch 114 - iter 240/248 - loss 0.77579008\n",
      "2019-04-18 08:10:38,266 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:10:38,267 EPOCH 114 done: loss 0.7744 - lr 0.0031 - bad epochs 0\n",
      "2019-04-18 08:10:40,569 DEV  : loss 0.99216318 - f-score 0.4399 - acc 0.2820\n",
      "2019-04-18 08:10:45,971 TEST : loss 1.14329457 - f-score 0.3272 - acc 0.1956\n",
      "2019-04-18 08:10:45,982 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:10:46,093 epoch 115 - iter 0/248 - loss 0.84683269\n",
      "2019-04-18 08:10:48,858 epoch 115 - iter 24/248 - loss 0.74661756\n",
      "2019-04-18 08:10:51,568 epoch 115 - iter 48/248 - loss 0.80211225\n",
      "2019-04-18 08:10:54,374 epoch 115 - iter 72/248 - loss 0.79314537\n",
      "2019-04-18 08:10:57,205 epoch 115 - iter 96/248 - loss 0.77461029\n",
      "2019-04-18 08:11:00,021 epoch 115 - iter 120/248 - loss 0.78354766\n",
      "2019-04-18 08:11:02,953 epoch 115 - iter 144/248 - loss 0.77683871\n",
      "2019-04-18 08:11:05,772 epoch 115 - iter 168/248 - loss 0.77705886\n",
      "2019-04-18 08:11:08,582 epoch 115 - iter 192/248 - loss 0.77791279\n",
      "2019-04-18 08:11:11,383 epoch 115 - iter 216/248 - loss 0.78519479\n",
      "2019-04-18 08:11:14,344 epoch 115 - iter 240/248 - loss 0.77996208\n",
      "2019-04-18 08:11:15,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:11:15,476 EPOCH 115 done: loss 0.7767 - lr 0.0031 - bad epochs 1\n",
      "2019-04-18 08:11:18,091 DEV  : loss 0.98593122 - f-score 0.4288 - acc 0.2729\n",
      "2019-04-18 08:11:24,122 TEST : loss 1.14030397 - f-score 0.3290 - acc 0.1969\n",
      "2019-04-18 08:11:24,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:11:24,246 epoch 116 - iter 0/248 - loss 0.94350517\n",
      "2019-04-18 08:11:27,116 epoch 116 - iter 24/248 - loss 0.77384541\n",
      "2019-04-18 08:11:29,900 epoch 116 - iter 48/248 - loss 0.74718183\n",
      "2019-04-18 08:11:32,976 epoch 116 - iter 72/248 - loss 0.74978114\n",
      "2019-04-18 08:11:36,170 epoch 116 - iter 96/248 - loss 0.74651343\n",
      "2019-04-18 08:11:38,926 epoch 116 - iter 120/248 - loss 0.75924293\n",
      "2019-04-18 08:11:41,686 epoch 116 - iter 144/248 - loss 0.75618753\n",
      "2019-04-18 08:11:44,574 epoch 116 - iter 168/248 - loss 0.75973097\n",
      "2019-04-18 08:11:47,319 epoch 116 - iter 192/248 - loss 0.75222698\n",
      "2019-04-18 08:11:50,141 epoch 116 - iter 216/248 - loss 0.75851104\n",
      "2019-04-18 08:11:53,007 epoch 116 - iter 240/248 - loss 0.76543143\n",
      "2019-04-18 08:11:53,977 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:11:53,981 EPOCH 116 done: loss 0.7596 - lr 0.0031 - bad epochs 2\n",
      "2019-04-18 08:11:56,291 DEV  : loss 0.98948997 - f-score 0.4311 - acc 0.2748\n",
      "2019-04-18 08:12:01,724 TEST : loss 1.13915431 - f-score 0.3315 - acc 0.1987\n",
      "2019-04-18 08:12:05,404 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:12:05,522 epoch 117 - iter 0/248 - loss 0.40181482\n",
      "2019-04-18 08:12:08,416 epoch 117 - iter 24/248 - loss 0.78388857\n",
      "2019-04-18 08:12:11,237 epoch 117 - iter 48/248 - loss 0.74478191\n",
      "2019-04-18 08:12:14,000 epoch 117 - iter 72/248 - loss 0.73409848\n",
      "2019-04-18 08:12:17,255 epoch 117 - iter 96/248 - loss 0.74892722\n",
      "2019-04-18 08:12:20,017 epoch 117 - iter 120/248 - loss 0.77181052\n",
      "2019-04-18 08:12:22,803 epoch 117 - iter 144/248 - loss 0.76673068\n",
      "2019-04-18 08:12:25,702 epoch 117 - iter 168/248 - loss 0.77994361\n",
      "2019-04-18 08:12:28,568 epoch 117 - iter 192/248 - loss 0.78902231\n",
      "2019-04-18 08:12:31,400 epoch 117 - iter 216/248 - loss 0.77915977\n",
      "2019-04-18 08:12:34,271 epoch 117 - iter 240/248 - loss 0.77711752\n",
      "2019-04-18 08:12:35,363 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:12:35,365 EPOCH 117 done: loss 0.7768 - lr 0.0031 - bad epochs 0\n",
      "2019-04-18 08:12:38,009 DEV  : loss 0.99016243 - f-score 0.4438 - acc 0.2851\n",
      "2019-04-18 08:12:44,080 TEST : loss 1.13548946 - f-score 0.3333 - acc 0.2000\n",
      "2019-04-18 08:12:44,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:12:44,217 epoch 118 - iter 0/248 - loss 1.48912418\n",
      "2019-04-18 08:12:47,065 epoch 118 - iter 24/248 - loss 0.81349441\n",
      "2019-04-18 08:12:49,814 epoch 118 - iter 48/248 - loss 0.76743773\n",
      "2019-04-18 08:12:52,582 epoch 118 - iter 72/248 - loss 0.79005484\n",
      "2019-04-18 08:12:55,369 epoch 118 - iter 96/248 - loss 0.79582541\n",
      "2019-04-18 08:12:58,155 epoch 118 - iter 120/248 - loss 0.80268152\n",
      "2019-04-18 08:13:01,052 epoch 118 - iter 144/248 - loss 0.79120393\n",
      "2019-04-18 08:13:03,920 epoch 118 - iter 168/248 - loss 0.78935944\n",
      "2019-04-18 08:13:06,753 epoch 118 - iter 192/248 - loss 0.77661958\n",
      "2019-04-18 08:13:09,611 epoch 118 - iter 216/248 - loss 0.77645834\n",
      "2019-04-18 08:13:12,434 epoch 118 - iter 240/248 - loss 0.77595395\n",
      "2019-04-18 08:13:13,433 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:13:13,435 EPOCH 118 done: loss 0.7758 - lr 0.0031 - bad epochs 1\n",
      "2019-04-18 08:13:15,726 DEV  : loss 0.98572612 - f-score 0.4508 - acc 0.2910\n",
      "2019-04-18 08:13:21,128 TEST : loss 1.13858962 - f-score 0.3305 - acc 0.1980\n",
      "2019-04-18 08:13:21,140 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:13:21,254 epoch 119 - iter 0/248 - loss 0.66920257\n",
      "2019-04-18 08:13:24,406 epoch 119 - iter 24/248 - loss 0.76957206\n",
      "2019-04-18 08:13:27,695 epoch 119 - iter 48/248 - loss 0.79131581\n",
      "2019-04-18 08:13:30,962 epoch 119 - iter 72/248 - loss 0.74452812\n",
      "2019-04-18 08:13:34,017 epoch 119 - iter 96/248 - loss 0.74175342\n",
      "2019-04-18 08:13:36,863 epoch 119 - iter 120/248 - loss 0.76688136\n",
      "2019-04-18 08:13:39,725 epoch 119 - iter 144/248 - loss 0.77169220\n",
      "2019-04-18 08:13:42,505 epoch 119 - iter 168/248 - loss 0.77057674\n",
      "2019-04-18 08:13:45,367 epoch 119 - iter 192/248 - loss 0.76782234\n",
      "2019-04-18 08:13:48,205 epoch 119 - iter 216/248 - loss 0.77435361\n",
      "2019-04-18 08:13:51,042 epoch 119 - iter 240/248 - loss 0.77006504\n",
      "2019-04-18 08:13:52,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:13:52,053 EPOCH 119 done: loss 0.7668 - lr 0.0031 - bad epochs 2\n",
      "2019-04-18 08:13:54,429 DEV  : loss 0.99436086 - f-score 0.4403 - acc 0.2823\n",
      "2019-04-18 08:14:00,653 TEST : loss 1.13175070 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:14:00,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:14:00,790 epoch 120 - iter 0/248 - loss 0.63374549\n",
      "2019-04-18 08:14:03,926 epoch 120 - iter 24/248 - loss 0.82748463\n",
      "2019-04-18 08:14:06,734 epoch 120 - iter 48/248 - loss 0.78237076\n",
      "2019-04-18 08:14:09,601 epoch 120 - iter 72/248 - loss 0.75960263\n",
      "2019-04-18 08:14:12,497 epoch 120 - iter 96/248 - loss 0.73999533\n",
      "2019-04-18 08:14:15,361 epoch 120 - iter 120/248 - loss 0.73515032\n",
      "2019-04-18 08:14:18,126 epoch 120 - iter 144/248 - loss 0.75849044\n",
      "2019-04-18 08:14:20,953 epoch 120 - iter 168/248 - loss 0.77202983\n",
      "2019-04-18 08:14:23,698 epoch 120 - iter 192/248 - loss 0.77489153\n",
      "2019-04-18 08:14:26,551 epoch 120 - iter 216/248 - loss 0.77281103\n",
      "2019-04-18 08:14:29,287 epoch 120 - iter 240/248 - loss 0.77777273\n",
      "2019-04-18 08:14:30,322 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:14:30,325 EPOCH 120 done: loss 0.7773 - lr 0.0031 - bad epochs 3\n",
      "2019-04-18 08:14:32,617 DEV  : loss 0.99064517 - f-score 0.4241 - acc 0.2691\n",
      "2019-04-18 08:14:38,652 TEST : loss 1.13995707 - f-score 0.3339 - acc 0.2004\n",
      "Epoch   119: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-04-18 08:14:38,662 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:14:38,789 epoch 121 - iter 0/248 - loss 0.86727411\n",
      "2019-04-18 08:14:41,622 epoch 121 - iter 24/248 - loss 0.77576664\n",
      "2019-04-18 08:14:44,432 epoch 121 - iter 48/248 - loss 0.71864577\n",
      "2019-04-18 08:14:47,231 epoch 121 - iter 72/248 - loss 0.76993113\n",
      "2019-04-18 08:14:50,007 epoch 121 - iter 96/248 - loss 0.76748829\n",
      "2019-04-18 08:14:52,777 epoch 121 - iter 120/248 - loss 0.75920032\n",
      "2019-04-18 08:14:55,667 epoch 121 - iter 144/248 - loss 0.76069906\n",
      "2019-04-18 08:14:58,519 epoch 121 - iter 168/248 - loss 0.76451580\n",
      "2019-04-18 08:15:01,446 epoch 121 - iter 192/248 - loss 0.77305082\n",
      "2019-04-18 08:15:04,262 epoch 121 - iter 216/248 - loss 0.76515029\n",
      "2019-04-18 08:15:07,135 epoch 121 - iter 240/248 - loss 0.77104034\n",
      "2019-04-18 08:15:08,166 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:15:08,170 EPOCH 121 done: loss 0.7700 - lr 0.0016 - bad epochs 0\n",
      "2019-04-18 08:15:10,458 DEV  : loss 0.98599893 - f-score 0.4284 - acc 0.2726\n",
      "2019-04-18 08:15:16,079 TEST : loss 1.13652170 - f-score 0.3320 - acc 0.1991\n",
      "2019-04-18 08:15:16,092 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:15:16,217 epoch 122 - iter 0/248 - loss 0.62763107\n",
      "2019-04-18 08:15:19,513 epoch 122 - iter 24/248 - loss 0.75299765\n",
      "2019-04-18 08:15:22,632 epoch 122 - iter 48/248 - loss 0.80834329\n",
      "2019-04-18 08:15:25,646 epoch 122 - iter 72/248 - loss 0.80362677\n",
      "2019-04-18 08:15:28,453 epoch 122 - iter 96/248 - loss 0.79017649\n",
      "2019-04-18 08:15:31,256 epoch 122 - iter 120/248 - loss 0.80928959\n",
      "2019-04-18 08:15:34,075 epoch 122 - iter 144/248 - loss 0.78906278\n",
      "2019-04-18 08:15:36,964 epoch 122 - iter 168/248 - loss 0.78631411\n",
      "2019-04-18 08:15:39,808 epoch 122 - iter 192/248 - loss 0.77465334\n",
      "2019-04-18 08:15:42,738 epoch 122 - iter 216/248 - loss 0.77506340\n",
      "2019-04-18 08:15:45,554 epoch 122 - iter 240/248 - loss 0.77571267\n",
      "2019-04-18 08:15:46,526 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:15:46,528 EPOCH 122 done: loss 0.7778 - lr 0.0016 - bad epochs 1\n",
      "2019-04-18 08:15:48,817 DEV  : loss 0.98535013 - f-score 0.4334 - acc 0.2767\n",
      "2019-04-18 08:15:54,241 TEST : loss 1.13566768 - f-score 0.3315 - acc 0.1987\n",
      "2019-04-18 08:15:54,253 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:15:54,375 epoch 123 - iter 0/248 - loss 0.90300918\n",
      "2019-04-18 08:15:57,222 epoch 123 - iter 24/248 - loss 0.76832394\n",
      "2019-04-18 08:16:00,007 epoch 123 - iter 48/248 - loss 0.74085820\n",
      "2019-04-18 08:16:02,832 epoch 123 - iter 72/248 - loss 0.77841001\n",
      "2019-04-18 08:16:05,663 epoch 123 - iter 96/248 - loss 0.76718577\n",
      "2019-04-18 08:16:08,496 epoch 123 - iter 120/248 - loss 0.75871405\n",
      "2019-04-18 08:16:11,326 epoch 123 - iter 144/248 - loss 0.77597324\n",
      "2019-04-18 08:16:14,197 epoch 123 - iter 168/248 - loss 0.77683318\n",
      "2019-04-18 08:16:17,061 epoch 123 - iter 192/248 - loss 0.77096486\n",
      "2019-04-18 08:16:19,913 epoch 123 - iter 216/248 - loss 0.77341988\n",
      "2019-04-18 08:16:22,720 epoch 123 - iter 240/248 - loss 0.77617867\n",
      "2019-04-18 08:16:23,750 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:16:23,757 EPOCH 123 done: loss 0.7816 - lr 0.0016 - bad epochs 2\n",
      "2019-04-18 08:16:26,063 DEV  : loss 0.98584455 - f-score 0.4489 - acc 0.2894\n",
      "2019-04-18 08:16:31,458 TEST : loss 1.13695550 - f-score 0.3303 - acc 0.1978\n",
      "2019-04-18 08:16:31,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:16:31,590 epoch 124 - iter 0/248 - loss 0.42564356\n",
      "2019-04-18 08:16:34,409 epoch 124 - iter 24/248 - loss 0.76767671\n",
      "2019-04-18 08:16:37,641 epoch 124 - iter 48/248 - loss 0.74108832\n",
      "2019-04-18 08:16:40,853 epoch 124 - iter 72/248 - loss 0.77389041\n",
      "2019-04-18 08:16:43,994 epoch 124 - iter 96/248 - loss 0.75465343\n",
      "2019-04-18 08:16:46,864 epoch 124 - iter 120/248 - loss 0.76222649\n",
      "2019-04-18 08:16:49,678 epoch 124 - iter 144/248 - loss 0.76562199\n",
      "2019-04-18 08:16:52,525 epoch 124 - iter 168/248 - loss 0.76314034\n",
      "2019-04-18 08:16:55,376 epoch 124 - iter 192/248 - loss 0.76149317\n",
      "2019-04-18 08:16:58,311 epoch 124 - iter 216/248 - loss 0.76945707\n",
      "2019-04-18 08:17:01,211 epoch 124 - iter 240/248 - loss 0.76924417\n",
      "2019-04-18 08:17:02,261 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:17:02,265 EPOCH 124 done: loss 0.7685 - lr 0.0016 - bad epochs 3\n",
      "2019-04-18 08:17:04,593 DEV  : loss 0.97768074 - f-score 0.4373 - acc 0.2798\n",
      "2019-04-18 08:17:10,046 TEST : loss 1.14475298 - f-score 0.3303 - acc 0.1978\n",
      "Epoch   123: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-04-18 08:17:10,057 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:17:10,165 epoch 125 - iter 0/248 - loss 0.38497907\n",
      "2019-04-18 08:17:13,005 epoch 125 - iter 24/248 - loss 0.83068525\n",
      "2019-04-18 08:17:15,850 epoch 125 - iter 48/248 - loss 0.76125604\n",
      "2019-04-18 08:17:18,644 epoch 125 - iter 72/248 - loss 0.77580293\n",
      "2019-04-18 08:17:21,491 epoch 125 - iter 96/248 - loss 0.77259017\n",
      "2019-04-18 08:17:24,287 epoch 125 - iter 120/248 - loss 0.77677563\n",
      "2019-04-18 08:17:27,086 epoch 125 - iter 144/248 - loss 0.76676137\n",
      "2019-04-18 08:17:30,071 epoch 125 - iter 168/248 - loss 0.77498098\n",
      "2019-04-18 08:17:32,908 epoch 125 - iter 192/248 - loss 0.77216430\n",
      "2019-04-18 08:17:35,701 epoch 125 - iter 216/248 - loss 0.77599449\n",
      "2019-04-18 08:17:38,635 epoch 125 - iter 240/248 - loss 0.77528484\n",
      "2019-04-18 08:17:39,633 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:17:39,635 EPOCH 125 done: loss 0.7730 - lr 0.0008 - bad epochs 0\n",
      "2019-04-18 08:17:41,948 DEV  : loss 0.98349404 - f-score 0.4511 - acc 0.2912\n",
      "2019-04-18 08:17:47,422 TEST : loss 1.14110041 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:17:47,433 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:17:47,571 epoch 126 - iter 0/248 - loss 1.06038499\n",
      "2019-04-18 08:17:50,468 epoch 126 - iter 24/248 - loss 0.69867732\n",
      "2019-04-18 08:17:53,214 epoch 126 - iter 48/248 - loss 0.77024658\n",
      "2019-04-18 08:17:56,220 epoch 126 - iter 72/248 - loss 0.76271013\n",
      "2019-04-18 08:17:59,537 epoch 126 - iter 96/248 - loss 0.77010961\n",
      "2019-04-18 08:18:02,748 epoch 126 - iter 120/248 - loss 0.77311422\n",
      "2019-04-18 08:18:05,855 epoch 126 - iter 144/248 - loss 0.76645259\n",
      "2019-04-18 08:18:08,623 epoch 126 - iter 168/248 - loss 0.77455702\n",
      "2019-04-18 08:18:11,414 epoch 126 - iter 192/248 - loss 0.77600876\n",
      "2019-04-18 08:18:14,218 epoch 126 - iter 216/248 - loss 0.77780557\n",
      "2019-04-18 08:18:17,028 epoch 126 - iter 240/248 - loss 0.77240954\n",
      "2019-04-18 08:18:18,036 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:18:18,038 EPOCH 126 done: loss 0.7794 - lr 0.0008 - bad epochs 1\n",
      "2019-04-18 08:18:20,341 DEV  : loss 0.97712290 - f-score 0.4482 - acc 0.2888\n",
      "2019-04-18 08:18:25,780 TEST : loss 1.14775920 - f-score 0.3286 - acc 0.1966\n",
      "2019-04-18 08:18:25,795 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:18:25,935 epoch 127 - iter 0/248 - loss 1.11568427\n",
      "2019-04-18 08:18:28,820 epoch 127 - iter 24/248 - loss 0.72340684\n",
      "2019-04-18 08:18:31,670 epoch 127 - iter 48/248 - loss 0.74570254\n",
      "2019-04-18 08:18:34,831 epoch 127 - iter 72/248 - loss 0.72344603\n",
      "2019-04-18 08:18:38,198 epoch 127 - iter 96/248 - loss 0.73646829\n",
      "2019-04-18 08:18:41,563 epoch 127 - iter 120/248 - loss 0.74154752\n",
      "2019-04-18 08:18:44,612 epoch 127 - iter 144/248 - loss 0.74398005\n",
      "2019-04-18 08:18:47,421 epoch 127 - iter 168/248 - loss 0.75557816\n",
      "2019-04-18 08:18:50,151 epoch 127 - iter 192/248 - loss 0.76150375\n",
      "2019-04-18 08:18:52,923 epoch 127 - iter 216/248 - loss 0.75688887\n",
      "2019-04-18 08:18:55,808 epoch 127 - iter 240/248 - loss 0.76993447\n",
      "2019-04-18 08:18:56,816 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:18:56,818 EPOCH 127 done: loss 0.7680 - lr 0.0008 - bad epochs 2\n",
      "2019-04-18 08:18:59,136 DEV  : loss 0.98058844 - f-score 0.4485 - acc 0.2891\n",
      "2019-04-18 08:19:04,607 TEST : loss 1.14403820 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:19:04,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:19:04,739 epoch 128 - iter 0/248 - loss 0.50641775\n",
      "2019-04-18 08:19:07,541 epoch 128 - iter 24/248 - loss 0.72399430\n",
      "2019-04-18 08:19:10,396 epoch 128 - iter 48/248 - loss 0.76194962\n",
      "2019-04-18 08:19:13,208 epoch 128 - iter 72/248 - loss 0.76855856\n",
      "2019-04-18 08:19:16,090 epoch 128 - iter 96/248 - loss 0.73433944\n",
      "2019-04-18 08:19:19,306 epoch 128 - iter 120/248 - loss 0.75620537\n",
      "2019-04-18 08:19:22,465 epoch 128 - iter 144/248 - loss 0.75126469\n",
      "2019-04-18 08:19:25,635 epoch 128 - iter 168/248 - loss 0.76636666\n",
      "2019-04-18 08:19:28,520 epoch 128 - iter 192/248 - loss 0.77064251\n",
      "2019-04-18 08:19:31,440 epoch 128 - iter 216/248 - loss 0.76770834\n",
      "2019-04-18 08:19:34,269 epoch 128 - iter 240/248 - loss 0.75709798\n",
      "2019-04-18 08:19:35,292 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:19:35,294 EPOCH 128 done: loss 0.7568 - lr 0.0008 - bad epochs 3\n",
      "2019-04-18 08:19:37,603 DEV  : loss 0.98358631 - f-score 0.4407 - acc 0.2826\n",
      "2019-04-18 08:19:43,081 TEST : loss 1.14176798 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:19:46,778 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:19:46,906 epoch 129 - iter 0/248 - loss 0.79936779\n",
      "2019-04-18 08:19:49,792 epoch 129 - iter 24/248 - loss 0.92529171\n",
      "2019-04-18 08:19:52,649 epoch 129 - iter 48/248 - loss 0.87441042\n",
      "2019-04-18 08:19:55,565 epoch 129 - iter 72/248 - loss 0.83439743\n",
      "2019-04-18 08:19:58,591 epoch 129 - iter 96/248 - loss 0.78589136\n",
      "2019-04-18 08:20:01,390 epoch 129 - iter 120/248 - loss 0.77077993\n",
      "2019-04-18 08:20:04,174 epoch 129 - iter 144/248 - loss 0.77654818\n",
      "2019-04-18 08:20:06,982 epoch 129 - iter 168/248 - loss 0.76624661\n",
      "2019-04-18 08:20:09,787 epoch 129 - iter 192/248 - loss 0.76764001\n",
      "2019-04-18 08:20:12,676 epoch 129 - iter 216/248 - loss 0.76029747\n",
      "2019-04-18 08:20:15,583 epoch 129 - iter 240/248 - loss 0.76233706\n",
      "2019-04-18 08:20:16,579 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:20:16,581 EPOCH 129 done: loss 0.7619 - lr 0.0008 - bad epochs 0\n",
      "2019-04-18 08:20:18,888 DEV  : loss 0.98184377 - f-score 0.4407 - acc 0.2826\n",
      "2019-04-18 08:20:24,307 TEST : loss 1.14083791 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:20:24,317 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:20:24,435 epoch 130 - iter 0/248 - loss 0.27195743\n",
      "2019-04-18 08:20:27,283 epoch 130 - iter 24/248 - loss 0.73686831\n",
      "2019-04-18 08:20:30,102 epoch 130 - iter 48/248 - loss 0.76802291\n",
      "2019-04-18 08:20:32,972 epoch 130 - iter 72/248 - loss 0.75602622\n",
      "2019-04-18 08:20:35,811 epoch 130 - iter 96/248 - loss 0.76588016\n",
      "2019-04-18 08:20:38,958 epoch 130 - iter 120/248 - loss 0.77490084\n",
      "2019-04-18 08:20:42,135 epoch 130 - iter 144/248 - loss 0.78275779\n",
      "2019-04-18 08:20:45,313 epoch 130 - iter 168/248 - loss 0.76872021\n",
      "2019-04-18 08:20:48,234 epoch 130 - iter 192/248 - loss 0.76926969\n",
      "2019-04-18 08:20:51,030 epoch 130 - iter 216/248 - loss 0.77654527\n",
      "2019-04-18 08:20:53,929 epoch 130 - iter 240/248 - loss 0.78086888\n",
      "2019-04-18 08:20:54,984 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:20:54,986 EPOCH 130 done: loss 0.7745 - lr 0.0008 - bad epochs 1\n",
      "2019-04-18 08:20:57,265 DEV  : loss 0.98118073 - f-score 0.4407 - acc 0.2826\n",
      "2019-04-18 08:21:02,722 TEST : loss 1.14199603 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:21:02,733 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:21:02,846 epoch 131 - iter 0/248 - loss 0.53854012\n",
      "2019-04-18 08:21:05,797 epoch 131 - iter 24/248 - loss 0.86481460\n",
      "2019-04-18 08:21:08,538 epoch 131 - iter 48/248 - loss 0.81166340\n",
      "2019-04-18 08:21:11,271 epoch 131 - iter 72/248 - loss 0.77493079\n",
      "2019-04-18 08:21:14,014 epoch 131 - iter 96/248 - loss 0.75210372\n",
      "2019-04-18 08:21:16,881 epoch 131 - iter 120/248 - loss 0.76667554\n",
      "2019-04-18 08:21:19,793 epoch 131 - iter 144/248 - loss 0.75867523\n",
      "2019-04-18 08:21:22,574 epoch 131 - iter 168/248 - loss 0.75517239\n",
      "2019-04-18 08:21:25,292 epoch 131 - iter 192/248 - loss 0.76464181\n",
      "2019-04-18 08:21:28,120 epoch 131 - iter 216/248 - loss 0.76566617\n",
      "2019-04-18 08:21:30,921 epoch 131 - iter 240/248 - loss 0.76730215\n",
      "2019-04-18 08:21:31,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:21:31,961 EPOCH 131 done: loss 0.7729 - lr 0.0008 - bad epochs 2\n",
      "2019-04-18 08:21:34,233 DEV  : loss 0.98144919 - f-score 0.4477 - acc 0.2884\n",
      "2019-04-18 08:21:39,624 TEST : loss 1.14268100 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:21:39,635 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:21:39,776 epoch 132 - iter 0/248 - loss 0.68284488\n",
      "2019-04-18 08:21:42,789 epoch 132 - iter 24/248 - loss 0.83268174\n",
      "2019-04-18 08:21:45,971 epoch 132 - iter 48/248 - loss 0.80963034\n",
      "2019-04-18 08:21:48,881 epoch 132 - iter 72/248 - loss 0.80530785\n",
      "2019-04-18 08:21:51,701 epoch 132 - iter 96/248 - loss 0.78971249\n",
      "2019-04-18 08:21:54,493 epoch 132 - iter 120/248 - loss 0.79909831\n",
      "2019-04-18 08:21:57,252 epoch 132 - iter 144/248 - loss 0.78612617\n",
      "2019-04-18 08:22:00,403 epoch 132 - iter 168/248 - loss 0.78249213\n",
      "2019-04-18 08:22:03,653 epoch 132 - iter 192/248 - loss 0.78301395\n",
      "2019-04-18 08:22:06,705 epoch 132 - iter 216/248 - loss 0.76759544\n",
      "2019-04-18 08:22:09,625 epoch 132 - iter 240/248 - loss 0.77499078\n",
      "2019-04-18 08:22:10,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:22:10,648 EPOCH 132 done: loss 0.7714 - lr 0.0008 - bad epochs 3\n",
      "2019-04-18 08:22:12,904 DEV  : loss 0.98510534 - f-score 0.4284 - acc 0.2725\n",
      "2019-04-18 08:22:18,269 TEST : loss 1.14231050 - f-score 0.3369 - acc 0.2026\n",
      "Epoch   131: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-04-18 08:22:18,282 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:22:18,409 epoch 133 - iter 0/248 - loss 0.76289356\n",
      "2019-04-18 08:22:21,227 epoch 133 - iter 24/248 - loss 0.75945423\n",
      "2019-04-18 08:22:24,058 epoch 133 - iter 48/248 - loss 0.76057565\n",
      "2019-04-18 08:22:26,769 epoch 133 - iter 72/248 - loss 0.76597467\n",
      "2019-04-18 08:22:29,478 epoch 133 - iter 96/248 - loss 0.76211468\n",
      "2019-04-18 08:22:32,245 epoch 133 - iter 120/248 - loss 0.77510123\n",
      "2019-04-18 08:22:35,051 epoch 133 - iter 144/248 - loss 0.76024584\n",
      "2019-04-18 08:22:37,839 epoch 133 - iter 168/248 - loss 0.78074146\n",
      "2019-04-18 08:22:40,649 epoch 133 - iter 192/248 - loss 0.77657116\n",
      "2019-04-18 08:22:43,539 epoch 133 - iter 216/248 - loss 0.77484273\n",
      "2019-04-18 08:22:46,328 epoch 133 - iter 240/248 - loss 0.78556087\n",
      "2019-04-18 08:22:47,352 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:22:47,357 EPOCH 133 done: loss 0.7837 - lr 0.0004 - bad epochs 0\n",
      "2019-04-18 08:22:49,635 DEV  : loss 0.98084575 - f-score 0.4489 - acc 0.2894\n",
      "2019-04-18 08:22:55,033 TEST : loss 1.14368713 - f-score 0.3369 - acc 0.2026\n",
      "2019-04-18 08:22:55,043 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:22:55,158 epoch 134 - iter 0/248 - loss 0.88755918\n",
      "2019-04-18 08:22:57,977 epoch 134 - iter 24/248 - loss 0.83379693\n",
      "2019-04-18 08:23:00,904 epoch 134 - iter 48/248 - loss 0.82287932\n",
      "2019-04-18 08:23:03,744 epoch 134 - iter 72/248 - loss 0.79327376\n",
      "2019-04-18 08:23:06,523 epoch 134 - iter 96/248 - loss 0.78455254\n",
      "2019-04-18 08:23:09,309 epoch 134 - iter 120/248 - loss 0.78013828\n",
      "2019-04-18 08:23:11,963 epoch 134 - iter 144/248 - loss 0.76217528\n",
      "2019-04-18 08:23:14,748 epoch 134 - iter 168/248 - loss 0.75991872\n",
      "2019-04-18 08:23:17,529 epoch 134 - iter 192/248 - loss 0.77177335\n",
      "2019-04-18 08:23:20,689 epoch 134 - iter 216/248 - loss 0.77481095\n",
      "2019-04-18 08:23:23,891 epoch 134 - iter 240/248 - loss 0.76637163\n",
      "2019-04-18 08:23:25,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:23:25,042 EPOCH 134 done: loss 0.7633 - lr 0.0004 - bad epochs 1\n",
      "2019-04-18 08:23:27,604 DEV  : loss 0.98024189 - f-score 0.4438 - acc 0.2851\n",
      "2019-04-18 08:23:32,980 TEST : loss 1.14194179 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:23:32,991 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:23:33,112 epoch 135 - iter 0/248 - loss 1.00654650\n",
      "2019-04-18 08:23:35,886 epoch 135 - iter 24/248 - loss 0.75928528\n",
      "2019-04-18 08:23:38,775 epoch 135 - iter 48/248 - loss 0.80173126\n",
      "2019-04-18 08:23:41,496 epoch 135 - iter 72/248 - loss 0.74272132\n",
      "2019-04-18 08:23:44,635 epoch 135 - iter 96/248 - loss 0.73964582\n",
      "2019-04-18 08:23:47,980 epoch 135 - iter 120/248 - loss 0.74433695\n",
      "2019-04-18 08:23:51,238 epoch 135 - iter 144/248 - loss 0.75232676\n",
      "2019-04-18 08:23:54,311 epoch 135 - iter 168/248 - loss 0.75380958\n",
      "2019-04-18 08:23:57,104 epoch 135 - iter 192/248 - loss 0.76124146\n",
      "2019-04-18 08:23:59,809 epoch 135 - iter 216/248 - loss 0.76805471\n",
      "2019-04-18 08:24:02,589 epoch 135 - iter 240/248 - loss 0.76089183\n",
      "2019-04-18 08:24:03,539 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:24:03,540 EPOCH 135 done: loss 0.7607 - lr 0.0004 - bad epochs 2\n",
      "2019-04-18 08:24:05,836 DEV  : loss 0.98044044 - f-score 0.4477 - acc 0.2884\n",
      "2019-04-18 08:24:11,182 TEST : loss 1.14282000 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:24:11,193 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:24:11,295 epoch 136 - iter 0/248 - loss 1.21067595\n",
      "2019-04-18 08:24:14,070 epoch 136 - iter 24/248 - loss 0.78663443\n",
      "2019-04-18 08:24:16,866 epoch 136 - iter 48/248 - loss 0.75804198\n",
      "2019-04-18 08:24:19,686 epoch 136 - iter 72/248 - loss 0.75220780\n",
      "2019-04-18 08:24:22,466 epoch 136 - iter 96/248 - loss 0.77673720\n",
      "2019-04-18 08:24:25,287 epoch 136 - iter 120/248 - loss 0.78151168\n",
      "2019-04-18 08:24:28,065 epoch 136 - iter 144/248 - loss 0.79120414\n",
      "2019-04-18 08:24:30,824 epoch 136 - iter 168/248 - loss 0.79643238\n",
      "2019-04-18 08:24:33,602 epoch 136 - iter 192/248 - loss 0.77848723\n",
      "2019-04-18 08:24:36,420 epoch 136 - iter 216/248 - loss 0.77775493\n",
      "2019-04-18 08:24:39,400 epoch 136 - iter 240/248 - loss 0.77054730\n",
      "2019-04-18 08:24:40,523 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:24:40,526 EPOCH 136 done: loss 0.7662 - lr 0.0004 - bad epochs 3\n",
      "2019-04-18 08:24:43,153 DEV  : loss 0.98053336 - f-score 0.4477 - acc 0.2884\n",
      "2019-04-18 08:24:49,110 TEST : loss 1.14227021 - f-score 0.3323 - acc 0.1993\n",
      "Epoch   135: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-04-18 08:24:49,121 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:24:49,275 epoch 137 - iter 0/248 - loss 1.37722468\n",
      "2019-04-18 08:24:52,129 epoch 137 - iter 24/248 - loss 0.76279047\n",
      "2019-04-18 08:24:54,841 epoch 137 - iter 48/248 - loss 0.75283874\n",
      "2019-04-18 08:24:57,614 epoch 137 - iter 72/248 - loss 0.76712719\n",
      "2019-04-18 08:25:00,384 epoch 137 - iter 96/248 - loss 0.76263625\n",
      "2019-04-18 08:25:03,191 epoch 137 - iter 120/248 - loss 0.75486864\n",
      "2019-04-18 08:25:06,026 epoch 137 - iter 144/248 - loss 0.76860292\n",
      "2019-04-18 08:25:08,763 epoch 137 - iter 168/248 - loss 0.76830203\n",
      "2019-04-18 08:25:11,571 epoch 137 - iter 192/248 - loss 0.76630059\n",
      "2019-04-18 08:25:14,310 epoch 137 - iter 216/248 - loss 0.75102128\n",
      "2019-04-18 08:25:17,170 epoch 137 - iter 240/248 - loss 0.75338501\n",
      "2019-04-18 08:25:18,180 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:25:18,184 EPOCH 137 done: loss 0.7560 - lr 0.0002 - bad epochs 0\n",
      "2019-04-18 08:25:20,457 DEV  : loss 0.97980297 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:25:25,808 TEST : loss 1.14356983 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:25:29,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:25:29,559 epoch 138 - iter 0/248 - loss 0.83700418\n",
      "2019-04-18 08:25:32,505 epoch 138 - iter 24/248 - loss 0.74984026\n",
      "2019-04-18 08:25:35,466 epoch 138 - iter 48/248 - loss 0.74404348\n",
      "2019-04-18 08:25:38,513 epoch 138 - iter 72/248 - loss 0.75528262\n",
      "2019-04-18 08:25:41,266 epoch 138 - iter 96/248 - loss 0.72978945\n",
      "2019-04-18 08:25:44,048 epoch 138 - iter 120/248 - loss 0.73044483\n",
      "2019-04-18 08:25:46,923 epoch 138 - iter 144/248 - loss 0.73087828\n",
      "2019-04-18 08:25:49,741 epoch 138 - iter 168/248 - loss 0.74909133\n",
      "2019-04-18 08:25:52,479 epoch 138 - iter 192/248 - loss 0.75106442\n",
      "2019-04-18 08:25:55,189 epoch 138 - iter 216/248 - loss 0.75931513\n",
      "2019-04-18 08:25:57,967 epoch 138 - iter 240/248 - loss 0.75745558\n",
      "2019-04-18 08:25:59,087 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:25:59,092 EPOCH 138 done: loss 0.7560 - lr 0.0002 - bad epochs 0\n",
      "2019-04-18 08:26:01,725 DEV  : loss 0.97991657 - f-score 0.4451 - acc 0.2863\n",
      "2019-04-18 08:26:07,917 TEST : loss 1.14339733 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:26:07,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:26:08,058 epoch 139 - iter 0/248 - loss 0.23692994\n",
      "2019-04-18 08:26:10,865 epoch 139 - iter 24/248 - loss 0.61680058\n",
      "2019-04-18 08:26:13,628 epoch 139 - iter 48/248 - loss 0.67008035\n",
      "2019-04-18 08:26:16,372 epoch 139 - iter 72/248 - loss 0.69480527\n",
      "2019-04-18 08:26:19,177 epoch 139 - iter 96/248 - loss 0.72961138\n",
      "2019-04-18 08:26:22,020 epoch 139 - iter 120/248 - loss 0.72860633\n",
      "2019-04-18 08:26:24,824 epoch 139 - iter 144/248 - loss 0.74287142\n",
      "2019-04-18 08:26:27,567 epoch 139 - iter 168/248 - loss 0.75952514\n",
      "2019-04-18 08:26:30,299 epoch 139 - iter 192/248 - loss 0.76780283\n",
      "2019-04-18 08:26:33,073 epoch 139 - iter 216/248 - loss 0.76210035\n",
      "2019-04-18 08:26:35,922 epoch 139 - iter 240/248 - loss 0.76371706\n",
      "2019-04-18 08:26:36,922 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:26:36,926 EPOCH 139 done: loss 0.7625 - lr 0.0002 - bad epochs 1\n",
      "2019-04-18 08:26:39,232 DEV  : loss 0.98010129 - f-score 0.4413 - acc 0.2831\n",
      "2019-04-18 08:26:44,670 TEST : loss 1.14284945 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:26:44,682 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:26:44,821 epoch 140 - iter 0/248 - loss 0.76879144\n",
      "2019-04-18 08:26:47,769 epoch 140 - iter 24/248 - loss 0.76940108\n",
      "2019-04-18 08:26:50,957 epoch 140 - iter 48/248 - loss 0.75562983\n",
      "2019-04-18 08:26:53,921 epoch 140 - iter 72/248 - loss 0.83182148\n",
      "2019-04-18 08:26:56,742 epoch 140 - iter 96/248 - loss 0.84395950\n",
      "2019-04-18 08:26:59,572 epoch 140 - iter 120/248 - loss 0.82438661\n",
      "2019-04-18 08:27:02,427 epoch 140 - iter 144/248 - loss 0.80674616\n",
      "2019-04-18 08:27:05,236 epoch 140 - iter 168/248 - loss 0.79761700\n",
      "2019-04-18 08:27:08,001 epoch 140 - iter 192/248 - loss 0.79865727\n",
      "2019-04-18 08:27:10,807 epoch 140 - iter 216/248 - loss 0.79013160\n",
      "2019-04-18 08:27:13,579 epoch 140 - iter 240/248 - loss 0.78596375\n",
      "2019-04-18 08:27:14,556 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:27:14,558 EPOCH 140 done: loss 0.7859 - lr 0.0002 - bad epochs 2\n",
      "2019-04-18 08:27:16,837 DEV  : loss 0.97986525 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:27:22,741 TEST : loss 1.14354730 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:27:22,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:27:22,884 epoch 141 - iter 0/248 - loss 0.88230681\n",
      "2019-04-18 08:27:26,069 epoch 141 - iter 24/248 - loss 0.74687856\n",
      "2019-04-18 08:27:29,148 epoch 141 - iter 48/248 - loss 0.72144395\n",
      "2019-04-18 08:27:31,910 epoch 141 - iter 72/248 - loss 0.75825982\n",
      "2019-04-18 08:27:34,709 epoch 141 - iter 96/248 - loss 0.74086989\n",
      "2019-04-18 08:27:37,450 epoch 141 - iter 120/248 - loss 0.74474202\n",
      "2019-04-18 08:27:40,253 epoch 141 - iter 144/248 - loss 0.74299291\n",
      "2019-04-18 08:27:43,141 epoch 141 - iter 168/248 - loss 0.75788829\n",
      "2019-04-18 08:27:45,987 epoch 141 - iter 192/248 - loss 0.74919185\n",
      "2019-04-18 08:27:48,816 epoch 141 - iter 216/248 - loss 0.75389380\n",
      "2019-04-18 08:27:51,670 epoch 141 - iter 240/248 - loss 0.75272468\n",
      "2019-04-18 08:27:52,675 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:27:52,676 EPOCH 141 done: loss 0.7528 - lr 0.0002 - bad epochs 3\n",
      "2019-04-18 08:27:54,939 DEV  : loss 0.97983289 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:28:00,298 TEST : loss 1.14357424 - f-score 0.3310 - acc 0.1984\n",
      "2019-04-18 08:28:03,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:28:04,087 epoch 142 - iter 0/248 - loss 0.89574981\n",
      "2019-04-18 08:28:06,934 epoch 142 - iter 24/248 - loss 0.73327098\n",
      "2019-04-18 08:28:09,768 epoch 142 - iter 48/248 - loss 0.79385389\n",
      "2019-04-18 08:28:13,091 epoch 142 - iter 72/248 - loss 0.76254993\n",
      "2019-04-18 08:28:15,887 epoch 142 - iter 96/248 - loss 0.76638456\n",
      "2019-04-18 08:28:18,648 epoch 142 - iter 120/248 - loss 0.77263738\n",
      "2019-04-18 08:28:21,406 epoch 142 - iter 144/248 - loss 0.77787086\n",
      "2019-04-18 08:28:24,198 epoch 142 - iter 168/248 - loss 0.77252062\n",
      "2019-04-18 08:28:27,045 epoch 142 - iter 192/248 - loss 0.76731516\n",
      "2019-04-18 08:28:29,878 epoch 142 - iter 216/248 - loss 0.77099742\n",
      "2019-04-18 08:28:32,602 epoch 142 - iter 240/248 - loss 0.76545223\n",
      "2019-04-18 08:28:33,597 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:28:33,598 EPOCH 142 done: loss 0.7654 - lr 0.0002 - bad epochs 0\n",
      "2019-04-18 08:28:35,882 DEV  : loss 0.97981203 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:28:41,547 TEST : loss 1.14367115 - f-score 0.3310 - acc 0.1984\n",
      "2019-04-18 08:28:41,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:28:41,692 epoch 143 - iter 0/248 - loss 0.79797447\n",
      "2019-04-18 08:28:44,960 epoch 143 - iter 24/248 - loss 0.70450321\n",
      "2019-04-18 08:28:48,107 epoch 143 - iter 48/248 - loss 0.73511688\n",
      "2019-04-18 08:28:51,079 epoch 143 - iter 72/248 - loss 0.75186917\n",
      "2019-04-18 08:28:53,920 epoch 143 - iter 96/248 - loss 0.74502688\n",
      "2019-04-18 08:28:57,202 epoch 143 - iter 120/248 - loss 0.74250647\n",
      "2019-04-18 08:29:00,431 epoch 143 - iter 144/248 - loss 0.74289793\n",
      "2019-04-18 08:29:03,736 epoch 143 - iter 168/248 - loss 0.74310265\n",
      "2019-04-18 08:29:06,538 epoch 143 - iter 192/248 - loss 0.74248150\n",
      "2019-04-18 08:29:09,349 epoch 143 - iter 216/248 - loss 0.74052331\n",
      "2019-04-18 08:29:12,149 epoch 143 - iter 240/248 - loss 0.75051445\n",
      "2019-04-18 08:29:13,161 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:29:13,163 EPOCH 143 done: loss 0.7521 - lr 0.0002 - bad epochs 1\n",
      "2019-04-18 08:29:15,445 DEV  : loss 0.98048562 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:29:20,792 TEST : loss 1.14274383 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:29:24,445 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:29:24,576 epoch 144 - iter 0/248 - loss 0.94852817\n",
      "2019-04-18 08:29:27,575 epoch 144 - iter 24/248 - loss 0.75374706\n",
      "2019-04-18 08:29:30,384 epoch 144 - iter 48/248 - loss 0.70896159\n",
      "2019-04-18 08:29:33,451 epoch 144 - iter 72/248 - loss 0.72783454\n",
      "2019-04-18 08:29:36,319 epoch 144 - iter 96/248 - loss 0.74284345\n",
      "2019-04-18 08:29:39,142 epoch 144 - iter 120/248 - loss 0.72935098\n",
      "2019-04-18 08:29:41,940 epoch 144 - iter 144/248 - loss 0.75939459\n",
      "2019-04-18 08:29:44,769 epoch 144 - iter 168/248 - loss 0.75960466\n",
      "2019-04-18 08:29:47,544 epoch 144 - iter 192/248 - loss 0.76498673\n",
      "2019-04-18 08:29:50,297 epoch 144 - iter 216/248 - loss 0.76401235\n",
      "2019-04-18 08:29:53,078 epoch 144 - iter 240/248 - loss 0.76125764\n",
      "2019-04-18 08:29:54,075 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:29:54,077 EPOCH 144 done: loss 0.7644 - lr 0.0002 - bad epochs 0\n",
      "2019-04-18 08:29:56,359 DEV  : loss 0.98056352 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:30:02,063 TEST : loss 1.14309466 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:30:02,074 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:30:02,203 epoch 145 - iter 0/248 - loss 0.88891089\n",
      "2019-04-18 08:30:05,419 epoch 145 - iter 24/248 - loss 0.80591581\n",
      "2019-04-18 08:30:08,655 epoch 145 - iter 48/248 - loss 0.77241467\n",
      "2019-04-18 08:30:11,557 epoch 145 - iter 72/248 - loss 0.73903671\n",
      "2019-04-18 08:30:14,389 epoch 145 - iter 96/248 - loss 0.75174684\n",
      "2019-04-18 08:30:17,176 epoch 145 - iter 120/248 - loss 0.76080557\n",
      "2019-04-18 08:30:19,999 epoch 145 - iter 144/248 - loss 0.76349882\n",
      "2019-04-18 08:30:22,784 epoch 145 - iter 168/248 - loss 0.75795479\n",
      "2019-04-18 08:30:25,474 epoch 145 - iter 192/248 - loss 0.75485076\n",
      "2019-04-18 08:30:28,453 epoch 145 - iter 216/248 - loss 0.75809596\n",
      "2019-04-18 08:30:31,269 epoch 145 - iter 240/248 - loss 0.75068684\n",
      "2019-04-18 08:30:32,253 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:30:32,256 EPOCH 145 done: loss 0.7530 - lr 0.0002 - bad epochs 1\n",
      "2019-04-18 08:30:34,551 DEV  : loss 0.98122084 - f-score 0.4451 - acc 0.2863\n",
      "2019-04-18 08:30:39,952 TEST : loss 1.14265966 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:30:39,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:30:40,089 epoch 146 - iter 0/248 - loss 1.13219965\n",
      "2019-04-18 08:30:42,881 epoch 146 - iter 24/248 - loss 0.73545832\n",
      "2019-04-18 08:30:45,750 epoch 146 - iter 48/248 - loss 0.74050568\n",
      "2019-04-18 08:30:48,597 epoch 146 - iter 72/248 - loss 0.68225323\n",
      "2019-04-18 08:30:51,389 epoch 146 - iter 96/248 - loss 0.73634069\n",
      "2019-04-18 08:30:54,224 epoch 146 - iter 120/248 - loss 0.74391161\n",
      "2019-04-18 08:30:56,942 epoch 146 - iter 144/248 - loss 0.72980517\n",
      "2019-04-18 08:30:59,847 epoch 146 - iter 168/248 - loss 0.75009342\n",
      "2019-04-18 08:31:02,665 epoch 146 - iter 192/248 - loss 0.75852353\n",
      "2019-04-18 08:31:05,420 epoch 146 - iter 216/248 - loss 0.76137397\n",
      "2019-04-18 08:31:08,214 epoch 146 - iter 240/248 - loss 0.76597886\n",
      "2019-04-18 08:31:09,211 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:09,213 EPOCH 146 done: loss 0.7725 - lr 0.0002 - bad epochs 2\n",
      "2019-04-18 08:31:11,504 DEV  : loss 0.98068732 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:31:16,920 TEST : loss 1.14392650 - f-score 0.3323 - acc 0.1993\n",
      "2019-04-18 08:31:16,932 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:17,046 epoch 147 - iter 0/248 - loss 1.38510799\n",
      "2019-04-18 08:31:19,907 epoch 147 - iter 24/248 - loss 0.85928190\n",
      "2019-04-18 08:31:22,979 epoch 147 - iter 48/248 - loss 0.79829613\n",
      "2019-04-18 08:31:26,151 epoch 147 - iter 72/248 - loss 0.76417523\n",
      "2019-04-18 08:31:29,392 epoch 147 - iter 96/248 - loss 0.76634249\n",
      "2019-04-18 08:31:32,259 epoch 147 - iter 120/248 - loss 0.75068102\n",
      "2019-04-18 08:31:34,997 epoch 147 - iter 144/248 - loss 0.73795383\n",
      "2019-04-18 08:31:37,886 epoch 147 - iter 168/248 - loss 0.75217176\n",
      "2019-04-18 08:31:40,723 epoch 147 - iter 192/248 - loss 0.75407294\n",
      "2019-04-18 08:31:43,555 epoch 147 - iter 216/248 - loss 0.76295118\n",
      "2019-04-18 08:31:46,385 epoch 147 - iter 240/248 - loss 0.76063658\n",
      "2019-04-18 08:31:47,378 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:47,382 EPOCH 147 done: loss 0.7609 - lr 0.0002 - bad epochs 3\n",
      "2019-04-18 08:31:49,657 DEV  : loss 0.98130643 - f-score 0.4464 - acc 0.2873\n",
      "2019-04-18 08:31:55,548 TEST : loss 1.14354038 - f-score 0.3323 - acc 0.1993\n",
      "Epoch   146: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-04-18 08:31:55,570 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:55,575 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:55,579 learning rate too small - quitting training!\n",
      "2019-04-18 08:31:55,580 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:59,389 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-18 08:31:59,398 Testing using best model ...\n",
      "2019-04-18 08:31:59,400 loading file resources/taggers/example-ner/best-model.pt\n",
      "2019-04-18 08:32:06,531 MICRO_AVG: acc 0.1993 - f1-score 0.3323\n",
      "2019-04-18 08:32:06,538 MACRO_AVG: acc 0.2097 - f1-score 0.25862702702702706\n",
      "2019-04-18 08:32:06,543 -          tp: 8 - fp: 230 - fn: 53 - tn: 8 - precision: 0.0336 - recall: 0.1311 - accuracy: 0.0275 - f1-score: 0.0535\n",
      "2019-04-18 08:32:06,547 Can        tp: 0 - fp: 0 - fn: 7 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,550 College    tp: 18 - fp: 19 - fn: 2 - tn: 18 - precision: 0.4865 - recall: 0.9000 - accuracy: 0.4615 - f1-score: 0.6316\n",
      "2019-04-18 08:32:06,554 Companies  tp: 9 - fp: 1 - fn: 59 - tn: 9 - precision: 0.9000 - recall: 0.1324 - accuracy: 0.1304 - f1-score: 0.2308\n",
      "2019-04-18 08:32:06,558 Degree     tp: 17 - fp: 4 - fn: 4 - tn: 17 - precision: 0.8095 - recall: 0.8095 - accuracy: 0.6800 - f1-score: 0.8095\n",
      "2019-04-18 08:32:06,560 Designation tp: 12 - fp: 4 - fn: 67 - tn: 12 - precision: 0.7500 - recall: 0.1519 - accuracy: 0.1446 - f1-score: 0.2526\n",
      "2019-04-18 08:32:06,562 Email      tp: 1 - fp: 0 - fn: 3 - tn: 1 - precision: 1.0000 - recall: 0.2500 - accuracy: 0.2500 - f1-score: 0.4000\n",
      "2019-04-18 08:32:06,564 L-Can      tp: 0 - fp: 0 - fn: 7 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,566 L-College  tp: 21 - fp: 16 - fn: 2 - tn: 21 - precision: 0.5676 - recall: 0.9130 - accuracy: 0.5385 - f1-score: 0.7000\n",
      "2019-04-18 08:32:06,568 L-Companies tp: 9 - fp: 1 - fn: 58 - tn: 9 - precision: 0.9000 - recall: 0.1343 - accuracy: 0.1324 - f1-score: 0.2337\n",
      "2019-04-18 08:32:06,570 L-Degree   tp: 17 - fp: 4 - fn: 4 - tn: 17 - precision: 0.8095 - recall: 0.8095 - accuracy: 0.6800 - f1-score: 0.8095\n",
      "2019-04-18 08:32:06,573 L-Designation tp: 13 - fp: 3 - fn: 67 - tn: 13 - precision: 0.8125 - recall: 0.1625 - accuracy: 0.1566 - f1-score: 0.2708\n",
      "2019-04-18 08:32:06,575 L-Email    tp: 0 - fp: 0 - fn: 3 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,576 L-Name     tp: 18 - fp: 3 - fn: 1 - tn: 18 - precision: 0.8571 - recall: 0.9474 - accuracy: 0.8182 - f1-score: 0.9000\n",
      "2019-04-18 08:32:06,578 L-Skills   tp: 1 - fp: 5 - fn: 22 - tn: 1 - precision: 0.1667 - recall: 0.0435 - accuracy: 0.0357 - f1-score: 0.0690\n",
      "2019-04-18 08:32:06,580 L-University tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,581 L-Years    tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,583 L-des      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,584 L-state    tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,587 Name       tp: 18 - fp: 3 - fn: 1 - tn: 18 - precision: 0.8571 - recall: 0.9474 - accuracy: 0.8182 - f1-score: 0.9000\n",
      "2019-04-18 08:32:06,589 Skills     tp: 1 - fp: 16 - fn: 22 - tn: 1 - precision: 0.0588 - recall: 0.0435 - accuracy: 0.0256 - f1-score: 0.0500\n",
      "2019-04-18 08:32:06,590 U-Can      tp: 0 - fp: 0 - fn: 16 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,592 U-College  tp: 1 - fp: 0 - fn: 0 - tn: 1 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "2019-04-18 08:32:06,594 U-Companies tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,596 U-Degree   tp: 4 - fp: 1 - fn: 0 - tn: 4 - precision: 0.8000 - recall: 1.0000 - accuracy: 0.8000 - f1-score: 0.8889\n",
      "2019-04-18 08:32:06,598 U-Designation tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,602 U-Email    tp: 14 - fp: 5 - fn: 0 - tn: 14 - precision: 0.7368 - recall: 1.0000 - accuracy: 0.7368 - f1-score: 0.8485\n",
      "2019-04-18 08:32:06,611 U-Graduation tp: 0 - fp: 28 - fn: 0 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,612 U-Links    tp: 0 - fp: 0 - fn: 4 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,615 U-Location tp: 35 - fp: 61 - fn: 29 - tn: 35 - precision: 0.3646 - recall: 0.5469 - accuracy: 0.2800 - f1-score: 0.4375\n",
      "2019-04-18 08:32:06,617 U-Skills   tp: 1 - fp: 3 - fn: 19 - tn: 1 - precision: 0.2500 - recall: 0.0500 - accuracy: 0.0435 - f1-score: 0.0833\n",
      "2019-04-18 08:32:06,620 U-abc      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,621 U-state    tp: 0 - fp: 0 - fn: 6 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,623 University tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,625 Years      tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,627 des        tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,630 state      tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-18 08:32:06,642 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training and test with all data\n",
    "\n",
    "\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "data_folder = '/content/gdrive/My Drive/NER/'\n",
    "\n",
    "\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                              train_file='train.txt',\n",
    "                                                              test_file='test.txt',\n",
    "                                                              dev_file=None)\n",
    "print(corpus)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)\n",
    "\n",
    "# 8. plot training curves (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves('resources/taggers/example-ner/loss.tsv')\n",
    "plotter.plot_weights('resources/taggers/example-ner/weights.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOtNSVB3Ok9H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GPU_Flair_NER.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
